{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine-tune WangchanBERTa [Exp4: few-shot+MST].ipynb","provenance":[{"file_id":"1VwHo8gTBIwR-EQfMmTCEnzvGpJLTQkCw","timestamp":1635777473931},{"file_id":"10cvKYjXX__tjyByBPQVzyZjm2otyYShy","timestamp":1631707464118},{"file_id":"1gh-cr1UCdC6yAZd1oOxAnMhCUdBFhkB4","timestamp":1630822152939},{"file_id":"1hdFRWS-l9mQmL614VWgsUMw2ln0uuLyh","timestamp":1630690751565},{"file_id":"187rIuGjNJiFqXgLgZg8hbPVspntafDIZ","timestamp":1625408544629},{"file_id":"1PFtJQ_yIxQw_qJXIJhVQ8BdgOFtoVOMN","timestamp":1625391206435},{"file_id":"15eHqe3dQJw63mhVyCoeuhyxrS0eHMagX","timestamp":1624633400803}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ICAWf9vLw2j","executionInfo":{"status":"ok","timestamp":1638891491537,"user_tz":0,"elapsed":173,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"1211296a-4fe9-4d5b-a95a-6be7b88aa83d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"LL80zCUIOxsh"},"source":["# Install libs\n","!pip -q install torch==1.5.0\n","!pip -q install torchtext==0.6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KIzREva71h7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQYCxkCFycRm","executionInfo":{"status":"ok","timestamp":1638880194018,"user_tz":0,"elapsed":113328,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"9c0ace3e-c49d-45ae-cc6a-a5ba1dfbbeb9"},"source":["!pip -q install thai2transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.5 MB/s eta 0:00:33tcmalloc: large alloc 1147494400 bytes == 0x55f8d9826000 @  0x7fdc503b1615 0x55f8d61aa4cc 0x55f8d628a47a 0x55f8d61ad2ed 0x55f8d629ee1d 0x55f8d6220e99 0x55f8d621b9ee 0x55f8d61aebda 0x55f8d6220d00 0x55f8d621b9ee 0x55f8d61aebda 0x55f8d621d737 0x55f8d629fc66 0x55f8d621cdaf 0x55f8d629fc66 0x55f8d621cdaf 0x55f8d629fc66 0x55f8d621cdaf 0x55f8d61af039 0x55f8d61f2409 0x55f8d61adc52 0x55f8d6220c25 0x55f8d621b9ee 0x55f8d61aebda 0x55f8d621d737 0x55f8d621b9ee 0x55f8d61aebda 0x55f8d621c915 0x55f8d61aeafa 0x55f8d621cc0d 0x55f8d621b9ee\n","\u001b[K     |████████████████████████████████| 881.9 MB 20 kB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 34.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 30.9 MB/s \n","\u001b[K     |████████████████████████████████| 170 kB 28.2 MB/s \n","\u001b[K     |████████████████████████████████| 11.0 MB 22.6 MB/s \n","\u001b[K     |████████████████████████████████| 298 kB 30.7 MB/s \n","\u001b[K     |████████████████████████████████| 8.7 MB 17.0 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[K     |████████████████████████████████| 524 kB 47.2 MB/s \n","\u001b[K     |████████████████████████████████| 10.1 MB 47.2 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 32.2 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 36.6 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 468 kB/s \n","\u001b[K     |████████████████████████████████| 243 kB 45.4 MB/s \n","\u001b[K     |████████████████████████████████| 132 kB 46.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 32.1 MB/s \n","\u001b[K     |████████████████████████████████| 743 kB 38.6 MB/s \n","\u001b[K     |████████████████████████████████| 160 kB 45.4 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 34.2 MB/s \n","\u001b[K     |████████████████████████████████| 192 kB 44.4 MB/s \n","\u001b[K     |████████████████████████████████| 332 kB 48.8 MB/s \n","\u001b[K     |████████████████████████████████| 829 kB 39.1 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 38.2 MB/s \n","\u001b[K     |████████████████████████████████| 321 kB 47.6 MB/s \n","\u001b[?25h  Building wheel for thai2transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"WRBpkHFl3AQV"},"source":["fin = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\")\n","content = []\n","for line in fin:\n","  content.append(line)\n","fin.close()\n","\n","content[39] = \"    SAVE_STATE_WARNING = ''\\n\"\n","\n","fout = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\", \"w\")\n","for line in content:\n","  fout.write(line)\n","fout.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TKD9JcvO4xh"},"source":["# from packaging import version\n","# import torch\n","# if version.parse(torch.__version__) <= version.parse(\"1.4.1\"):\n","#     SAVE_STATE_WARNING = \"\"\n","# else:\n","#     from torch.optim.lr_scheduler import SAVE_STATE_WARNING"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dA0f5_Um2DPf"},"source":["# !pip install -q pytorch-lightning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5f9moE7PHpe"},"source":["# !pip -q install git+https://github.com/PyTorchLightning/pytorch-lightning\n","# import pytorch_lightning as pl\n","# print(pl.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAR-Di_UPKGX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCFx-P4FQUaz"},"source":["# Load Pre-trained Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GUiDe3ye6Ks","executionInfo":{"status":"ok","timestamp":1638891497604,"user_tz":0,"elapsed":214,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"a5f4cb1f-37a5-4d00-956b-5209c91ac35e"},"source":["cd /content/drive/MyDrive/Mispelling/misspelling-semantics/"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Mispelling/misspelling-semantics\n"]}]},{"cell_type":"code","metadata":{"id":"iN9UVXbep4Bx","executionInfo":{"status":"ok","timestamp":1638891497888,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"og7jEc7eL9FJ","executionInfo":{"status":"ok","timestamp":1638891498943,"user_tz":0,"elapsed":211,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["DIR = \"Models/WangchanBERTa-exp4\""],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubHucCA5QW93","executionInfo":{"status":"ok","timestamp":1638891499112,"user_tz":0,"elapsed":3,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["model_idx = 0\n","model_name = \"wangchanberta\"\n","# model_name = \"xlmr\"\n","# model_name = \"mbert\"\n","args_params = f\"{model_name} wisesight_sentiment {DIR}/Outputs/ {DIR}/Logs/ --batch_size 8 --seed {model_idx} --run_name exp1 --num_train_epochs 10\""],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-BVhvmoQXpk","executionInfo":{"status":"ok","timestamp":1638891500758,"user_tz":0,"elapsed":1423,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["import argparse\n","import math\n","import os\n","from functools import partial\n","import urllib.request\n","from tqdm import tqdm\n","from typing import Collection, Callable\n","from pathlib import Path\n","from sklearn import preprocessing\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from transformers import (\n","    AdamW, \n","    get_linear_schedule_with_warmup, \n","    get_constant_schedule, \n","    AutoTokenizer, \n","    AutoModel,\n","    AutoModelForSequenceClassification, \n","    AutoConfig,\n","    Trainer, \n","    TrainingArguments,\n","    CamembertTokenizer,\n","    BertTokenizer,\n","    BertTokenizerFast,\n","    BertConfig,\n","    XLMRobertaTokenizer,\n","    XLMRobertaTokenizerFast,\n","    XLMRobertaConfig,\n","    DataCollatorWithPadding,\n","    default_data_collator\n",")\n","\n","from datasets import load_dataset, list_metrics, load_dataset, Dataset\n","from thai2transformers.datasets import SequenceClassificationDataset\n","from thai2transformers.metrics import classification_metrics, multilabel_classification_metrics\n","from thai2transformers.finetuners import SequenceClassificationFinetuner\n","from thai2transformers.auto import AutoModelForMultiLabelSequenceClassification\n","from thai2transformers.tokenizers import (\n","    ThaiRobertaTokenizer,\n","    ThaiWordsNewmmTokenizer,\n","    ThaiWordsSyllableTokenizer,\n","    FakeSefrCutTokenizer,\n",")\n","from thai2transformers.utils import get_dict_val\n","from thai2transformers.conf import Task\n","from thai2transformers import preprocess\n","\n","CACHE_DIR = f'{str(Path.home())}/.cache/huggingface_datasets'\n","\n","METRICS = {\n","    Task.MULTICLASS_CLS: classification_metrics,\n","    Task.MULTILABEL_CLS: multilabel_classification_metrics\n","}\n","\n","PUBLIC_MODEL = {\n","    # 'mbert': {\n","    #     'name': 'bert-base-multilingual-cased',\n","    #     'tokenizer': BertTokenizerFast.from_pretrained('bert-base-multilingual-cased'),\n","    #     'config': BertConfig.from_pretrained('bert-base-multilingual-cased'),\n","    # },\n","    'xlmr': {\n","        'name': 'xlm-roberta-base',\n","        'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base'),\n","        'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    },\n","    # 'xlmr-large': {\n","    #     'name': 'xlm-roberta-large',\n","    #     'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-large'),\n","    #     'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","    # 'thbert': {\n","    #     'name': 'monsoon-nlp/bert-base-thai',\n","    #     'tokenizer': AutoTokenizer.from_pretrained('monsoon-nlp/bert-base-thai'),\n","    #     'config': AutoConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","}\n","\n","TOKENIZER_CLS = {\n","    'wangchanberta': CamembertTokenizer,\n","    # 'spm': ThaiRobertaTokenizer,\n","    # 'newmm': ThaiWordsNewmmTokenizer,\n","    # 'syllable': ThaiWordsSyllableTokenizer,\n","    # 'sefr_cut': FakeSefrCutTokenizer,\n","}\n","\n","DATASET_METADATA = {\n","    'wisesight_sentiment': {\n","        'huggingface_dataset_name': 'wisesight_sentiment',\n","        'task': Task.MULTICLASS_CLS,\n","        'text_input_col_name': 'texts',\n","        'label_col_name': 'category',\n","        'num_labels': 3,\n","        'split_names': ['train', 'validation', 'test']\n","    }\n","}\n","\n","def init_public_model_tokenizer_for_seq_cls(public_model_name, task, num_labels):\n","    \n","    config = PUBLIC_MODEL[public_model_name]['config']\n","    config.num_labels = num_labels\n","    tokenizer = PUBLIC_MODEL[public_model_name]['tokenizer']\n","    model_name = PUBLIC_MODEL[public_model_name]['name']\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n","                                                                   config=config)\n","    if task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(model_name,\n","                                                                             config=config)\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_model_tokenizer_for_seq_cls(model_dir, tokenizer_cls, tokenizer_dir, task, num_labels):\n","    \n","    config = AutoConfig.from_pretrained(\n","        model_dir,\n","        num_labels=num_labels\n","    );\n","\n","    tokenizer = tokenizer_cls.from_pretrained(\n","        tokenizer_dir,\n","    );\n","\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","    elif task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_trainer(task, model, train_dataset, val_dataset, warmup_steps, args, data_collator=default_data_collator): \n","        \n","    training_args = TrainingArguments(\n","                        num_train_epochs=args.num_train_epochs,\n","                        per_device_train_batch_size=args.batch_size,\n","                        per_device_eval_batch_size=args.batch_size,\n","                        gradient_accumulation_steps=args.gradient_accumulation_steps,\n","                        learning_rate=args.learning_rate,\n","                        warmup_steps=warmup_steps,\n","                        weight_decay=args.weight_decay,\n","                        adam_epsilon=args.adam_epsilon,\n","                        max_grad_norm=args.max_grad_norm,\n","                        #checkpoint\n","                        output_dir=args.output_dir,\n","                        overwrite_output_dir=True,\n","                        #logs\n","                        logging_dir=args.log_dir,\n","                        logging_first_step=False,\n","                        logging_steps=args.logging_steps,\n","                        #eval\n","                        evaluation_strategy='epoch' if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else 'no',\n","                        load_best_model_at_end=True,\n","                        #others\n","                        seed=args.seed,\n","                        fp16=args.fp16,\n","                        fp16_opt_level=args.fp16_opt_level,\n","                        dataloader_drop_last=False,\n","                        no_cuda=args.no_cuda,\n","                        metric_for_best_model=args.metric_for_best_model,\n","                        prediction_loss_only=False,\n","                        run_name=args.run_name\n","                    )\n","    if task == Task.MULTICLASS_CLS:\n","        compute_metrics_fn = METRICS[task]\n","    elif task == Task.MULTILABEL_CLS:\n","        compute_metrics_fn = partial(METRICS[task],n_labels=DATASET_METADATA[args.dataset_name]['num_labels'])\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        compute_metrics=compute_metrics_fn,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        data_collator=data_collator\n","    )\n","    return trainer, training_args\n","\n","# def _process_transformers(\n","#     text: str,\n","#     pre_rules: Collection[Callable] = [\n","#         preprocess.fix_html,\n","#         preprocess.rm_brackets,\n","#         preprocess.replace_newlines,\n","#         preprocess.rm_useless_spaces,\n","#         preprocess.replace_spaces,\n","#         preprocess.replace_rep_after,\n","#     ],\n","#     tok_func: Callable = preprocess.word_tokenize,\n","#     post_rules: Collection[Callable] = [preprocess.ungroup_emoji, preprocess.replace_wrep_post],\n","#     lowercase: bool = False\n","# ) -> str:\n","#     if lowercase:\n","#         text = text.lower()\n","#     for rule in pre_rules:\n","#         text = rule(text)\n","#     toks = tok_func(text)\n","#     for rule in post_rules:\n","#         toks = rule(toks)\n","#     return \"\".join(toks)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anv_bUF0QZL2","executionInfo":{"status":"ok","timestamp":1638891500915,"user_tz":0,"elapsed":159,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"19dea52e-6d5e-4183-acc9-48f8ee9d424f"},"source":["parser = argparse.ArgumentParser()\n","# Required\n","parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","parser.add_argument('output_dir', type=str)\n","parser.add_argument('log_dir', type=str)\n","\n","parser.add_argument('--model_dir', type=str)\n","parser.add_argument('--tokenizer_dir', type=str)\n","parser.add_argument('--prepare_for_tokenization', action='store_true', default=False, help='To replace space with a special token e.g. `<_>`. This may require for some pretrained models.')\n","parser.add_argument('--space_token', type=str, default=' ', help='The special token for space, specify if argumet: prepare_for_tokenization is applied')\n","parser.add_argument('--max_length', type=int, default=None)\n","parser.add_argument('--lowercase', action='store_true', default=False)\n","\n","# Finetuning\n","parser.add_argument('--num_train_epochs', type=int, default=5)\n","parser.add_argument('--learning_rate', type=float, default=1e-05)\n","parser.add_argument('--weight_decay', type=float, default=0.01)\n","parser.add_argument('--warmup_ratio', type=float, default=0.1)\n","parser.add_argument('--batch_size', type=int, default=16)\n","parser.add_argument('--no_cuda', action='store_true', default=False)\n","parser.add_argument('--fp16', action='store_true', default=False)\n","parser.add_argument('--greater_is_better', action='store_true', default=True)\n","parser.add_argument('--metric_for_best_model', type=str, default='f1_micro')\n","parser.add_argument('--logging_steps', type=int, default=10)\n","parser.add_argument('--seed', type=int, default=2020)\n","parser.add_argument('--fp16_opt_level', type=str, default='O1')\n","parser.add_argument('--gradient_accumulation_steps', type=int, default=1)\n","parser.add_argument('--adam_epsilon', type=float, default=1e-08)\n","parser.add_argument('--max_grad_norm', type=float, default=1.0)\n","\n","# wandb\n","parser.add_argument('--run_name', type=str, default=None)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--run_name'], dest='run_name', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help=None, metavar=None)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"qCeYWu0tQauI","executionInfo":{"status":"ok","timestamp":1638891500915,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","# parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","# parser.add_argument('output_dir', type=str)\n","# parser.add_argument('log_dir', type=str)\n","args = parser.parse_args(args_params.split())\n","\n","# Set seed\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrh47k-vQc92","executionInfo":{"status":"ok","timestamp":1638891500916,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"27e5393c-59e4-43b0-aaeb-5d525ab2a282"},"source":["\n","# try:\n","print(f'\\n\\n[INFO] Dataset: {args.dataset_name}')\n","print(f'\\n\\n[INFO] Huggingface\\'s dataset name: {DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"]} ')\n","print(f'[INFO] Task: {DATASET_METADATA[args.dataset_name][\"task\"].value}')\n","print(f'\\n[INFO] space_token: {args.space_token}')\n","print(f'[INFO] prepare_for_tokenization: {args.prepare_for_tokenization}\\n')\n"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","[INFO] Dataset: wisesight_sentiment\n","\n","\n","[INFO] Huggingface's dataset name: wisesight_sentiment \n","[INFO] Task: multiclass_classification\n","\n","[INFO] space_token:  \n","[INFO] prepare_for_tokenization: False\n","\n"]}]},{"cell_type":"code","metadata":{"id":"FmRMfPX7Bcuw","executionInfo":{"status":"ok","timestamp":1638891500916,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"SgzmOBvkQoTB","executionInfo":{"status":"ok","timestamp":1638891500916,"user_tz":0,"elapsed":3,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# dataset = load_dataset(DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"])"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChlS02wkQqRr","executionInfo":{"status":"ok","timestamp":1638891500917,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# labels = {\n","#     \"neg\": 2,\n","#     \"neu\": 1,\n","#     \"pos\": 0,\n","#     \"q\": 3\n","# }\n","# dataset"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8AMunmmXv3V","executionInfo":{"status":"ok","timestamp":1638891500917,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# dataset[\"train\"][0:5]"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nv7ywhlqWau3","executionInfo":{"status":"ok","timestamp":1638891506705,"user_tz":0,"elapsed":5792,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"f3e13e15-d351-4482-8a17-626a7cb9b8b1"},"source":["text_input_col_name = DATASET_METADATA[args.dataset_name]['text_input_col_name']\n","\n","if args.tokenizer_type_or_public_model_name not in list(TOKENIZER_CLS.keys()) \\\n","    and args.tokenizer_type_or_public_model_name not in list(PUBLIC_MODEL.keys()):\n","    raise f\"The tokenizer type or public model name `{args.tokenizer_type_or_public_model_name}`` is not supported\"\n","\n","if args.tokenizer_type_or_public_model_name in list(TOKENIZER_CLS.keys()):\n","    tokenizer_cls = TOKENIZER_CLS[args.tokenizer_type_or_public_model_name]\n","\n","\n","task = DATASET_METADATA[args.dataset_name]['task']\n","if args.tokenizer_type_or_public_model_name in PUBLIC_MODEL.keys():\n","    print(args.tokenizer_type_or_public_model_name)\n","    model, tokenizer, config = init_public_model_tokenizer_for_seq_cls(args.tokenizer_type_or_public_model_name,\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);\n","else:\n","    print(\"WangchanBERTa\")\n","    model, tokenizer, config = init_model_tokenizer_for_seq_cls(\"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        tokenizer_cls,\n","                                                        \"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["WangchanBERTa\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"8dcSKA23WpQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638891506705,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"5aff4261-13f1-48a2-8327-bc271e36ac8b"},"source":["# if args.tokenizer_type_or_public_model_name == 'wangchanberta':\n","#     tokenizer.additional_special_tokens = ['<s>NOTUSED', '</s>NOTUSED', args.space_token]\n","\n","print('\\n[INFO] Preprocess and tokenizing texts in datasets')\n","max_length = args.max_length if args.max_length else config.max_position_embeddings\n","print(f'[INFO] max_length = {max_length} \\n')"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Preprocess and tokenizing texts in datasets\n","[INFO] max_length = 512 \n","\n"]}]},{"cell_type":"code","metadata":{"id":"AfYFfObgad6q","executionInfo":{"status":"ok","timestamp":1638891506705,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# !pip -q install demoji\n","# import demoji\n","# demoji.download_codes()"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqsSdW8KbbFd","executionInfo":{"status":"ok","timestamp":1638891506963,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mTebN_FOhqa"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"rBcBdWSQOjP2","executionInfo":{"status":"ok","timestamp":1638891506963,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["import json\n","import pandas as pd\n","\n","def load_jsonl(fname):\n","    fin = open(fname, encoding=\"utf-8\")\n","    data = []\n","    for line in fin:\n","        d = json.loads(line.strip())\n","        data.append(d)\n","\n","    return data\n","\n","def save_jsonl(data, filename):\n","    with open(filename, \"w\", encoding=\"utf-8\") as fo:\n","        for idx, d in enumerate(data):\n","            fo.write(json.dumps(d, ensure_ascii=False))\n","            fo.write(\"\\n\")"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqL51pAmqAAw","executionInfo":{"status":"ok","timestamp":1638891506963,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"7534fc77-fc2e-4c80-8503-262b64c731c0"},"source":["ls Datasets/WisesightSentiment"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["neg.txt     test-misp.jsonl                  tokenized_valid.jsonl\n","neu.txt     tokenized_test.jsonl             train.jsonl\n","pos.txt     tokenized_test-misp.jsonl        valid.jsonl\n","q.txt       tokenized_train.jsonl\n","test.jsonl  tokenized_train-misp-3000.jsonl\n"]}]},{"cell_type":"code","metadata":{"id":"GOrCSyAzBp_f","executionInfo":{"status":"ok","timestamp":1638891506964,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpjyO0OwOjSW","executionInfo":{"status":"ok","timestamp":1638891508059,"user_tz":0,"elapsed":1098,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["traindata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_train-misp-3000.jsonl\")\n","validdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_valid.jsonl\")\n","testdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_test-misp.jsonl\")"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"CteXhrsSqkC8","executionInfo":{"status":"ok","timestamp":1638891508060,"user_tz":0,"elapsed":31,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# traindata[0][\"segments\"]"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTPLMhBQO4u3","executionInfo":{"status":"ok","timestamp":1638891508061,"user_tz":0,"elapsed":30,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"a0ec2437-ce4e-499c-e81e-d6d357fa4ae8"},"source":["import itertools\n","def filterByMode(data, mode=None):\n","  output = []\n","  for sent in data:\n","    if mode is None:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","    elif mode==\"corr\":\n","      tokenized = [seg[1] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    else:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    \n","    tokenized = list(itertools.chain(*tokenized))\n","  \n","    output.append({\n","        \"category\": sent[\"category\"],\n","        \"text\": sent[\"text\"],\n","        \"tokenized\": tokenized,\n","        \"segments\": sent[\"segments\"]\n","    })\n","\n","  return output\n","\n","traindata\n","validdata\n","allTestdata = filterByMode(testdata)\n","corrTestdata = filterByMode(testdata, \"corr\")\n","mispTestdata = filterByMode(testdata, \"misp\")\n","len(allTestdata), len(corrTestdata), len(mispTestdata)"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2671, 880, 880)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"xflkz27paVDG","executionInfo":{"status":"ok","timestamp":1638891508062,"user_tz":0,"elapsed":27,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ewn4a1gWPCKC","executionInfo":{"status":"ok","timestamp":1638891508063,"user_tz":0,"elapsed":27,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"b7cb22e2-c14f-4123-c246-0a0536e40f57"},"source":["for sent in testdata[1:10]:\n","  print(sent)\n","  # break"],"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["{'category': 'neu', 'text': 'ครับ #phithanbkk', 'misp_tokens': [], 'tokenized': ['ครับ', ' ', '#phithanbkk'], 'segments': [[['ครับ', ' ', '#phithanbkk'], ['ครับ', ' ', '#phithanbkk']]]}\n","{'category': 'neg', 'text': 'การด่าไปเหมือนได้บรรเทาความเครียดเฉยๆ แต่บีทีเอส (รถไฟฟ้า) มันสำนึกมั้ย ก็ไม่อ่ะ 😕', 'misp_tokens': [{'corr': 'ไหม', 'misp': 'มั้ย', 'int': True, 's': 67, 't': 71}], 'tokenized': ['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก', 'มั้ย', ' ', 'ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face'], 'segments': [[['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก'], ['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก']], [['มั้ย'], ['ไหม']], [['ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face'], ['ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face']]]}\n","{'category': 'neu', 'text': 'Cf clarins 5 ขวด 2850', 'misp_tokens': [], 'tokenized': ['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850'], 'segments': [[['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850'], ['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850']]]}\n","{'category': 'neu', 'text': 'ทานได้ค่ะ น้ำซุป MK ต้มมาจากหัวผักกาด ซีอิ้วขาว เกลือ แลน้ำตาลค่ะ', 'misp_tokens': [{'corr': 'และ', 'misp': 'แล', 'int': False, 's': 54, 't': 56}], 'tokenized': ['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ', ' ', 'แล', 'น้ำตาล', 'ค่ะ'], 'segments': [[['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ'], ['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ']], [['แล'], ['และ']], [['น้ำตาล', 'ค่ะ'], ['น้ำตาล', 'ค่ะ']]]}\n","{'category': 'neu', 'text': 'เคล็ดลับที่ขาดไม่ได้ในการป้องกันผิวจากแสงแดด คือการทาครีมกันแดด สาวๆบ้างคนอาจจะคิดว่ามันไม่ใช่เรื่องสำคัญเท่าไหร่ แต่บอกเลยว่า ผิดมาก เพราะแสงแดดสมัยนี้แรงมาก และมีอนุภาพการทำลายผิวสูงมาก ถ้าไม่อยากให้ผิวเราถูกทำร้ายแบบซ้ำๆซาก ควรทาครีมกันแดดที่ดีมีคุณภาพอย่าง Eucerin Sun Age Repair Serum ปัจจุบันครีมกันแดดมีมากมายให้เราเลือกซื้อก็จริง แต่ก็อย่าลืมเลือกสิ่งที่ดีที่สุดให้ตัวเราอย่าง Eucerin Sun Acne oil Control ค่ะ', 'misp_tokens': [], 'tokenized': ['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ'], 'segments': [[['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ'], ['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ']]]}\n","{'category': 'neu', 'text': \"สำหรับสูตรของผม คือ Jack Daniel's หวานซ่อนเปรี้ยวชื่อ Jack Yellow Life ส่วนประกอบ Jack Daniel's 2 ชอท น้ำเก๊กฮวย น้ำมะนาว ใบมิ้นท์ เกลือเล็กน้อย วิธีปรุง นำ JackDaniel's มาเขย่ากับน้ำเก๊กฮวย เจือด้วยน้ำมะนาวบางๆ ตกแต่งด้วยใบมิ้น เสริฟด้วยแก้วที่ทาเกลือไว้ที่ปากแก้ว รสชาติที่จะได้คือหวาน หอม ซ่อนเปรี้ยว ด้วยคอนเซ็ปว่านี่แหละคือชีวิต จะหวานอย่างเดียวก็จะเลี่ยนไป จะเปรี้ยวเกินไปก็ไม่ใช่เรื่อง จึงควรจะมีทั้งเปรี้ยว ทั้งหวานคละเคล้ากันไปครับ\", 'misp_tokens': [], 'tokenized': ['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ'], 'segments': [[['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ'], ['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ']]]}\n","{'category': 'neg', 'text': 'เจ้ว่าการ์นิเย่แอบแรงนิสหน่อย เคยใช้โยเกิร์ตไม๊ พรุ้งนี้ลองพอกหน้าดูทำให้หน้าสบายขึ้น นุ่มขึ้น หายไวไวน๊าาาา', 'misp_tokens': [{'corr': 'นะ', 'misp': 'น๊าาาา', 'int': True, 's': 102, 't': 108}, {'corr': 'นิดหน่อย', 'misp': 'นิสหน่อย', 'int': True, 's': 21, 't': 29}, {'corr': 'ไหม', 'misp': 'ไม๊', 'int': True, 's': 44, 't': 47}], 'tokenized': ['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง', 'นิสหน่อย', ' ', 'เคย', 'ใช้', 'โยเกิร์ต', 'ไม๊', ' ', 'พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไว', 'ไวน๊าาาา'], 'segments': [[['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง'], ['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง']], [['นิสหน่อย'], ['นิดหน่อย']], [['เคย', 'ใช้', 'โยเกิร์ต'], ['เคย', 'ใช้', 'โยเกิร์ต']], [['ไม๊'], ['ไหม']], [['พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไวไว'], ['พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไวไว']], [['น๊าาาา'], ['นะ']], [[], []]]}\n","{'category': 'neu', 'text': 'เอๅจริงๆถ้ๅมันเปิดให้ใช้และถูกกฎหมๅยจริวคงกลัวจะเก็บภๅษียังไงรึป่ๅว', 'misp_tokens': [{'corr': 'เอา', 'misp': 'เอๅ', 'int': False, 's': 0, 't': 3}, {'corr': 'ถ้า', 'misp': 'ถ้ๅ', 'int': False, 's': 8, 't': 11}, {'corr': 'กฎหมาย', 'misp': 'กฎหมๅย', 'int': False, 's': 30, 't': 36}, {'corr': 'จริง', 'misp': 'จริว', 'int': False, 's': 36, 't': 40}, {'corr': 'ฤๅษี', 'misp': 'ภๅษี', 'int': False, 's': 52, 't': 56}, {'corr': 'เปล่า', 'misp': 'ป่ๅว', 'int': False, 's': 63, 't': 67}], 'tokenized': ['เอๅจริง', 'ๆ', 'ถ้ๅ', 'มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก', 'กฎหมๅย', 'จริว', 'คง', 'กลัว', 'จะ', 'เก็บ', 'ภๅษี', 'ยัง', 'ไง', 'รึป่ๅว'], 'segments': [[[], []], [['เอๅ'], ['เอา']], [['จริง', 'ๆ'], ['จริง', 'ๆ']], [['ถ้ๅ'], ['ถ้า']], [['มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก'], ['มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก']], [['กฎหมๅย'], ['กฎหมาย']], [[], []], [['จริว'], ['จริง']], [['คง', 'กลัว', 'จะ', 'เก็บ'], ['คง', 'กลัว', 'จะ', 'เก็บ']], [['ภๅษี'], ['ฤๅษี']], [['ยัง', 'ไง', 'รึ'], ['ยัง', 'ไง', 'รึ']], [['ป่ๅว'], ['เปล่า']], [[], []]]}\n","{'category': 'neg', 'text': 'อิผ้าอนามัยเหิ้ย ติดทุกอย่าง ยกเว้นกางเกงใน', 'misp_tokens': [{'corr': 'อี', 'misp': 'อิ', 'int': True, 's': 0, 't': 2}, {'corr': 'เหี้ย', 'misp': 'เหิ้ย', 'int': False, 's': 11, 't': 16}], 'tokenized': ['อิผ้า', 'อนามัย', 'เหิ้ย', ' ', 'ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน'], 'segments': [[[], []], [['อิ'], ['อี']], [['ผ้า', 'อนามัย'], ['ผ้า', 'อนามัย']], [['เหิ้ย'], ['เหี้ย']], [['ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน'], ['ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน']]]}\n"]}]},{"cell_type":"code","metadata":{"id":"NRWpDhQaitQc","executionInfo":{"status":"ok","timestamp":1638891508063,"user_tz":0,"elapsed":12,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"yceBl7D2jGyv","executionInfo":{"status":"ok","timestamp":1638891508064,"user_tz":0,"elapsed":12,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLTGbmXyf0gp","executionInfo":{"status":"ok","timestamp":1638891508321,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["import glob\n","from torch.utils.data import Dataset as TorchDataset\n","from datasets import Dataset\n","# from thai2transformers.datasets import SequenceClassificationDataset\n","\n","class SequenceClassificationDataset(TorchDataset):\n","    def __init__(\n","        self,\n","        tokenizer,\n","        data_dir,\n","        task=Task.MULTICLASS_CLS,\n","        max_length=128,\n","        ext=\".csv\",\n","        bs=10000,\n","        preprocessor=None,\n","        input_ids=[],\n","        misp_ids=[],\n","        attention_masks=[],\n","        labels=[],\n","        label_encoder=None\n","    ):\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        self.bs = bs\n","        self.preprocessor = preprocessor\n","        self.input_ids = input_ids\n","        self.misp_ids = misp_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","        self.task = task\n","        self.label_encoder = label_encoder\n","        # self._build()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, i):\n","        return {\n","            \"input_ids\": torch.tensor(self.input_ids[i], dtype=torch.long),\n","            \"misp_ids\": torch.tensor(self.misp_ids[i], dtype=torch.long),\n","            \"attention_mask\": torch.tensor(self.attention_masks[i], dtype=torch.long),\n","            \"label\": torch.tensor(self.labels[i], dtype=torch.long),\n","        }\n"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Jqdsd997hev"},"source":["Add additional tokens"]},{"cell_type":"code","metadata":{"id":"7Zxb64qIt674","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638891508575,"user_tz":0,"elapsed":261,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"c7d003cc-874c-426f-961e-ea564644b18e"},"source":["tokenizer.add_tokens([\"<rep>\", \"<int>\", \"<misp>\", \"<lol>\"])\n","model.resize_token_embeddings(len(tokenizer)) "],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(25009, 768)"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"41milBdU7jw_","executionInfo":{"status":"ok","timestamp":1638891508899,"user_tz":0,"elapsed":325,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["MD = load_jsonl(f\"{DIR}/../../train_mispelling_dection.jsonl\")[0]"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhWkQBPE3HDO","executionInfo":{"status":"ok","timestamp":1638891521751,"user_tz":0,"elapsed":12854,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"66f682ad-6f9f-42f3-864e-b71f19ad73db"},"source":["from tqdm import tqdm \n","import itertools\n","from itertools import groupby\n","from collections import defaultdict\n","\n","LABELS = {\n","    \"neg\": 2,\n","    \"neu\": 1,\n","    \"pos\": 0,\n","    \"q\": 1 # used to be 3\n","}\n","\n","class CustomLabelEncoder():\n","    def __init__(self):\n","        pass\n","\n","    def transform(self, labels):\n","        return [LABELS[l] for l in labels]\n","    \n","\n","def remove_starting_marker(t, unk):\n","    if len(t) > 0:\n","      if t[0]=='▁':\n","        t = t[1:]\n","      elif t[0].startswith('▁'):        \n","        if tokenizer.convert_tokens_to_ids([t[0][1:]])[0] != unk:\n","          t[0] = t[0][1:]\n","    return t\n","\n","def norm_word(word, haha=False, notoken=False):\n","    groups = [list(s) for _, s in groupby(word)]\n","    ch = []\n","    extraToken = \"\"\n","    for g in groups:\n","        if len(g)>=3:\n","            if g[0]==\"5\" and haha:\n","              ch.append(\"555\")  \n","              extraToken = \"<lol>\"\n","            else:\n","              extraToken = \"<rep>\"\n","              ch.append(g[0])  \n","        else:\n","            ch += g\n","\n","    word = \"\".join(ch)+extraToken\n","    if notoken:\n","      word = \"\".join(ch)\n","    \n","    return word\n","\n","\n","def preprocessing(d, preSegmented=False, mode=None):\n","    max_length = 400\n","    custom_label_encoder = CustomLabelEncoder()\n","    labels = get_dict_val(d, \"category\")\n","\n","    labels = custom_label_encoder.transform(labels)\n","\n","    input_ids = []\n","    misp_ids = []\n","    attention_masks = []\n","    unk = tokenizer.convert_tokens_to_ids([\"<unk>\"])[0]\n","\n","    cnt = defaultdict(int)\n","    sents = []\n","    if not preSegmented:\n","      texts = get_dict_val(d, \"tokenized\")\n","      for tokens in tqdm(texts):\n","        tokens = [(t, t) for t in tokens]\n","        sents.append(tokens)\n","        \n","    else:\n","      texts = get_dict_val(d, \"segments\")\n","      for segments in tqdm(texts):\n","        s = [list(zip(seg[0], seg[1])) for seg in segments]\n","        tokens = list(itertools.chain(*s))\n","        sents.append(tokens)\n","\n","    for tokens in sents:\n","      # if mode is None, ignore corr\n","      cnt[\"tokens\"] += len(tokens)\n","      misptokens = [t[0] for t in tokens]\n","      corrtokens = [t[0] for t in tokens]\n","      \n","      if mode==\"corr\":\n","        misptokens = [t[1] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      elif mode==\"mae\":\n","        misptokens = [t[0] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      \n","      \n","      midx = tokenizer.convert_tokens_to_ids(misptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(corrtokens)\n","      assert(len(midx)==len(cidx))\n","\n","      newmisptokens = []\n","      newcorrtokens = []\n","      for i in range(len(midx)):\n","          if midx[i]==unk:\n","              t = norm_word(misptokens[i], True, notoken=True)\n","              t = tokenizer.tokenize(t)\n","              t = remove_starting_marker(t, unk)\n","\n","              if misptokens[i]==corrtokens[i]:\n","                newmisptokens += t\n","                newcorrtokens += t\n","              else:\n","                newmisptokens += t\n","                tx = norm_word(corrtokens[i], True, notoken=True)\n","                tx = tokenizer.tokenize(tx)\n","                tx = remove_starting_marker(tx, unk)\n","\n","                if len(tx) > 0:\n","                  newcorrtokens += [tx[0] for j in range(len(t))]\n","                else:\n","                  newcorrtokens += t\n","          else:\n","              t = norm_word(misptokens[i], True, notoken=True)\n","              tx = norm_word(corrtokens[i], True, notoken=True)\n","\n","              newmisptokens.append(t)\n","              newcorrtokens.append(tx)\n","          \n","          norm = norm_word(misptokens[i])\n","          if \"<rep>\" in norm:\n","            n = norm_word(misptokens[i], True)\n","            if \"<rep>\" in n:\n","              newmisptokens.append(\"<rep>\")\n","              newcorrtokens.append(\"<rep>\")\n","              cnt[\"<rep>\"] += 1\n","            elif \"<lol>\" in n:\n","              newmisptokens.append(\"<lol>\")\n","              newcorrtokens.append(\"<lol>\")\n","              cnt[\"<lol>\"] += 1\n","\n","          if norm in MD:\n","            corr, mint = MD[norm]\n","            if mint:\n","              newmisptokens.append(\"<int>\")\n","              newcorrtokens.append(\"<int>\")\n","              cnt[\"<int>\"] += 1\n","            else:\n","              newmisptokens.append(\"<msp>\")\n","              newcorrtokens.append(\"<msp>\")\n","              cnt[\"<misp>\"] += 1\n","\n","      \n","            \n","      \n","      assert(len(newmisptokens)==len(newcorrtokens))\n","      cnt[\"extra\"] += (len(newmisptokens) - len(misptokens))\n","              \n","      # words = newwords\n","      newmisptokens = ['<s>'] + newmisptokens[0:max_length-2] + ['</s>']\n","      newcorrtokens = ['<s>'] + newcorrtokens[0:max_length-2] + ['</s>']\n","    \n","      midx = tokenizer.convert_tokens_to_ids(newmisptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(newcorrtokens)\n","\n","      mask = [1 for i in midx]\n","        \n","      input_ids.append(midx)\n","      misp_ids.append(cidx)\n","      attention_masks.append(mask)\n","\n","    #   if len(input_ids) > 10:\n","    #     break\n","    \n","    # labels = labels[0:10]\n","\n","    for k in cnt:\n","      print(\"Number of\", k, cnt[k])\n","    return SequenceClassificationDataset(\n","        tokenizer=tokenizer,\n","        data_dir=None,\n","        max_length=max_length,\n","        input_ids=input_ids,\n","        misp_ids=misp_ids,\n","        attention_masks=attention_masks,\n","        labels=labels,\n","        task=task\n","    )\n","\n","raw_datasets = {\n","    \"train\": traindata,\n","    \"validation\": validdata,\n","    \"test\": allTestdata,\n","    \"test-corr\": corrTestdata,\n","    \"test-misp\": mispTestdata,\n","    \"test-mae\": mispTestdata,\n","    \"test-all-mae\": allTestdata,\n","}\n","\n","dataset_split = {}\n","for split_name in raw_datasets:\n","    print(\"Tokenizing:\", split_name)\n","    d = pd.DataFrame(raw_datasets[split_name])\n","    d = Dataset.from_pandas(d)\n","    preSegmented = split_name.startswith(\"test\") or split_name.startswith(\"train\")\n","    mode = None\n","    if \"corr\" in split_name:\n","      mode = \"corr\"\n","    elif \"misp\" in split_name:\n","      mode = \"misp\"\n","    elif \"mae\" in split_name:\n","      mode = \"mae\"\n","\n","    dataset_split[split_name] = preprocessing(d, preSegmented=preSegmented, mode=mode)\n","    # break"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing: train\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [00:00<00:00, 99074.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 78468\n","Number of <rep> 669\n","Number of <int> 1126\n","Number of extra 3432\n","Number of <lol> 245\n","Number of <misp> 695\n","Tokenizing: validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2404/2404 [00:00<00:00, 162932.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 67236\n","Number of <rep> 523\n","Number of <int> 441\n","Number of extra 2819\n","Number of <lol> 177\n","Number of <misp> 404\n","Tokenizing: test\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2671/2671 [00:00<00:00, 106592.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 74865\n","Number of <misp> 402\n","Number of extra 4227\n","Number of <int> 646\n","Number of <rep> 600\n","Number of <lol> 221\n","Tokenizing: test-corr\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 103927.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of extra 556\n","Number of <misp> 124\n","Number of <int> 96\n","Number of <rep> 82\n","Number of <lol> 73\n","Tokenizing: test-misp\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 67267.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of <misp> 157\n","Number of extra 1664\n","Number of <int> 485\n","Number of <rep> 324\n","Number of <lol> 72\n","Tokenizing: test-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 105916.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of <misp> 157\n","Number of extra 1664\n","Number of <int> 485\n","Number of <rep> 324\n","Number of <lol> 72\n","Tokenizing: test-all-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2671/2671 [00:00<00:00, 91270.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 74865\n","Number of <misp> 402\n","Number of extra 4227\n","Number of <int> 646\n","Number of <rep> 600\n","Number of <lol> 221\n"]}]},{"cell_type":"code","metadata":{"id":"zTo1InxM7QlH","executionInfo":{"status":"ok","timestamp":1638891521752,"user_tz":0,"elapsed":35,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pVpOylu-CrqE"},"source":["## Custom Classes for Our Experiments"]},{"cell_type":"code","metadata":{"id":"wHqjltTIEdzZ","executionInfo":{"status":"ok","timestamp":1638891521752,"user_tz":0,"elapsed":32,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["from transformers.modeling_roberta import RobertaEmbeddings"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q5iZsOgEd2P","executionInfo":{"status":"ok","timestamp":1638891521753,"user_tz":0,"elapsed":32,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["from torch import nn\n","\n","class CustomRobertaEmbeddings(RobertaEmbeddings):\n","\n","    def __init__(self, ref, config):\n","        super().__init__(config)\n","        self.word_embeddings = ref.word_embeddings\n","\n","    def forward(self, input_ids, misp_ids, token_type_ids=None, position_ids=None, inputs_embeds=None):\n","\n","        input_shape = input_ids.size()\n","        seq_length = input_shape[1]\n","\n","        inputs_embeds = self.word_embeddings(input_ids)\n","        misp_embeds = self.word_embeddings(misp_ids)\n","\n","        embeddings = ((inputs_embeds + misp_embeds)*0.5)\n","        return embeddings\n"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"WL_oBhOdHTjt","executionInfo":{"status":"ok","timestamp":1638891521753,"user_tz":0,"elapsed":31,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["from transformers.modeling_roberta import RobertaModel"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew6s3Y1f1vCa","executionInfo":{"status":"ok","timestamp":1638891521755,"user_tz":0,"elapsed":32,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["from transformers.modeling_camembert import CamembertForSequenceClassification\n","from transformers.modeling_roberta import RobertaForSequenceClassification\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","\n","class CustomSequenceClassification(CamembertForSequenceClassification):\n","    authorized_missing_keys = [r\"position_ids\"]\n","\n","    def __init__(self, config, refmodel=None):\n","        super().__init__(config)\n","        if refmodel is not None:\n","          config = refmodel.config\n","          # self.refmodel = refmodel\n","          self.num_labels = config.num_labels\n","\n","          self.roberta = refmodel.roberta\n","          self.classifier = refmodel.classifier\n","\n","          self.baseEmb = refmodel.roberta.embeddings\n","          self.newEmb = CustomRobertaEmbeddings(self.baseEmb, config)\n","\n","    def forward(self, *args, **kwargs):\n","        # del kwargs[\"misp_ids\"]\n","        # return self.refmodel(**kwargs)\n","\n","        return_dict = self.config.use_return_dict\n","\n","        inputs_embeds = self.newEmb(kwargs[\"input_ids\"], kwargs[\"misp_ids\"])\n","        \n","        # doc: https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaModel.forward\n","        outputs = self.roberta(\n","            input_ids=None,\n","            attention_mask=kwargs[\"attention_mask\"],\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        labels = kwargs[\"labels\"]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"lznRUPu1YJSA","executionInfo":{"status":"ok","timestamp":1638891521755,"user_tz":0,"elapsed":30,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# cusmodel = CustomSequenceClassification(model.config, model)\n","# trainer, training_args = init_trainer(task=task,\n","#                             model=cusmodel,\n","#                             train_dataset=dataset_split['train'],\n","#                             val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","#                             warmup_steps=warmup_steps,\n","#                             args=args,\n","#                             data_collator=data_collator)\n","\n","# p, label_ids, result = trainer.predict(test_dataset=dataset_split['test'])\n","\n","# print(f'Evaluation on test set (dataset: {args.dataset_name})')    \n","\n","# for key, value in result.items():\n","#     print(f'{key} : {value:.4f}')\n","\n","# # Evaluation on test set (dataset: wisesight_sentiment)\n","# # eval_loss : 1.0284\n","# # eval_accuracy : 0.3000\n","# # eval_f1_micro : 0.3000\n","# # eval_precision_micro : 0.3000\n","# # eval_recall_micro : 0.3000\n","# # eval_f1_macro : 0.1667\n","# # eval_precision_macro : 0.1667\n","# # eval_recall_macro : 0.1667\n","# # eval_nb_samples : 10.0000"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDP2AEpDCqXh","executionInfo":{"status":"ok","timestamp":1638891521974,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["from dataclasses import dataclass\n","from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n","from transformers import PreTrainedTokenizerBase\n","\n","@dataclass\n","class CustomDataCollatorWithPadding:\n","  tokenizer: PreTrainedTokenizerBase\n","  padding: Union[bool, str] = True\n","  max_length: Optional[int] = None\n","  pad_to_multiple_of: Optional[int] = None\n","  return_tensors: str = \"pt\"\n","\n","  def __call__(self, features):\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"input_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","\n","    batch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"misp_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","      \n","    mispbatch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    # print(mispbatch[\"input_ids\"])\n","    # print(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][0]))\n","    # print(tokenizer.convert_ids_to_tokens(mispbatch[\"input_ids\"][0]))\n","    batch[\"misp_ids\"] = mispbatch[\"input_ids\"]\n","    assert(batch[\"misp_ids\"].shape==batch[\"input_ids\"].shape)\n","    # assert()\n","    if \"label\" in batch:\n","        batch[\"labels\"] = batch[\"label\"]\n","        del batch[\"label\"]\n","    if \"label_ids\" in batch:\n","        batch[\"labels\"] = batch[\"label_ids\"]\n","        del batch[\"label_ids\"]\n","    return batch"],"execution_count":68,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_D7scYkC0Jg"},"source":["# Model Training "]},{"cell_type":"code","metadata":{"id":"Dx6AsnFmeQlM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638891525127,"user_tz":0,"elapsed":3155,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"10484e5c-2c48-4b17-dfb8-e129a8b1ed79"},"source":["warmup_steps = math.ceil(len(dataset_split['train']) / args.batch_size * args.warmup_ratio * args.num_train_epochs)\n","\n","print(f'\\n[INFO] Number of train examples = {len(raw_datasets[\"train\"])}')\n","print(f'[INFO] Number of batches per epoch (training set) = {math.ceil(len(dataset_split[\"train\"]) / args.batch_size)}')\n","\n","print(f'[INFO] Warmup ratio = {args.warmup_ratio}')\n","print(f'[INFO] Warmup steps = {warmup_steps}')\n","print(f'[INFO] Learning rate: {args.learning_rate}')\n","print(f'[INFO] Logging steps: {args.logging_steps}')\n","print(f'[INFO] FP16 training: {args.fp16}\\n')\n","\n","# if 'validation' in DATASET_METADATA[args.dataset_name]['split_names']:\n","print(f'[INFO] Number of validation examples = {len(raw_datasets[\"validation\"])}')\n","print(f'[INFO] Number of batches per epoch (validation set) = {math.ceil(len(dataset_split[\"validation\"]))}')\n","\n","data_collator = CustomDataCollatorWithPadding(tokenizer,\n","                                        padding=True,\n","                                        pad_to_multiple_of=8 if args.fp16 else None)\n","\n","cusmodel = CustomSequenceClassification(model.config, model)\n","trainer, training_args = init_trainer(task=task,\n","                            model=cusmodel,\n","                            train_dataset=dataset_split['train'],\n","                            val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","                            warmup_steps=warmup_steps,\n","                            args=args,\n","                            data_collator=data_collator)\n","\n","print('[INFO] TrainingArguments:')\n","print(training_args)\n","print('\\n')"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Number of train examples = 3000\n","[INFO] Number of batches per epoch (training set) = 375\n","[INFO] Warmup ratio = 0.1\n","[INFO] Warmup steps = 375\n","[INFO] Learning rate: 1e-05\n","[INFO] Logging steps: 10\n","[INFO] FP16 training: False\n","\n","[INFO] Number of validation examples = 2404\n","[INFO] Number of batches per epoch (validation set) = 2404\n","[INFO] TrainingArguments:\n","TrainingArguments(output_dir='Models/WangchanBERTa-exp4/Outputs/', overwrite_output_dir=True, do_train=False, do_eval=None, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, warmup_steps=375, logging_dir='Models/WangchanBERTa-exp4/Logs/', logging_first_step=False, logging_steps=10, save_steps=500, save_total_limit=None, no_cuda=False, seed=0, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name='exp1', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='f1_micro', greater_is_better=True)\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"O8TTQ7VmQGhS","executionInfo":{"status":"ok","timestamp":1638893520649,"user_tz":0,"elapsed":1995525,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"6862f9ab-afc3-4c1b-9dc3-939065fb5c58"},"source":["print('\\nBegin model finetuning.')\n","trainer.train()\n","print('Done.\\n')"],"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Begin model finetuning.\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3750/3750 33:15, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Micro</th>\n","      <th>Precision Micro</th>\n","      <th>Recall Micro</th>\n","      <th>F1 Macro</th>\n","      <th>Precision Macro</th>\n","      <th>Recall Macro</th>\n","      <th>Nb Samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.979016</td>\n","      <td>0.935150</td>\n","      <td>0.555740</td>\n","      <td>0.555740</td>\n","      <td>0.555740</td>\n","      <td>0.555740</td>\n","      <td>0.507539</td>\n","      <td>0.504584</td>\n","      <td>0.530383</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.916223</td>\n","      <td>0.846718</td>\n","      <td>0.576123</td>\n","      <td>0.576123</td>\n","      <td>0.576123</td>\n","      <td>0.576123</td>\n","      <td>0.577391</td>\n","      <td>0.607450</td>\n","      <td>0.645955</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.734912</td>\n","      <td>0.850426</td>\n","      <td>0.611065</td>\n","      <td>0.611065</td>\n","      <td>0.611065</td>\n","      <td>0.611065</td>\n","      <td>0.591297</td>\n","      <td>0.596512</td>\n","      <td>0.642996</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.595203</td>\n","      <td>0.817019</td>\n","      <td>0.634359</td>\n","      <td>0.634359</td>\n","      <td>0.634359</td>\n","      <td>0.634359</td>\n","      <td>0.628073</td>\n","      <td>0.636871</td>\n","      <td>0.683007</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.646594</td>\n","      <td>0.784293</td>\n","      <td>0.664725</td>\n","      <td>0.664725</td>\n","      <td>0.664725</td>\n","      <td>0.664725</td>\n","      <td>0.644470</td>\n","      <td>0.636201</td>\n","      <td>0.676973</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.528430</td>\n","      <td>0.781751</td>\n","      <td>0.668885</td>\n","      <td>0.668885</td>\n","      <td>0.668885</td>\n","      <td>0.668885</td>\n","      <td>0.649781</td>\n","      <td>0.644296</td>\n","      <td>0.680282</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.476794</td>\n","      <td>0.837725</td>\n","      <td>0.665141</td>\n","      <td>0.665141</td>\n","      <td>0.665141</td>\n","      <td>0.665141</td>\n","      <td>0.649830</td>\n","      <td>0.644305</td>\n","      <td>0.689222</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.549316</td>\n","      <td>0.890759</td>\n","      <td>0.652246</td>\n","      <td>0.652246</td>\n","      <td>0.652246</td>\n","      <td>0.652246</td>\n","      <td>0.639569</td>\n","      <td>0.638745</td>\n","      <td>0.680537</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.428149</td>\n","      <td>0.931990</td>\n","      <td>0.642679</td>\n","      <td>0.642679</td>\n","      <td>0.642679</td>\n","      <td>0.642679</td>\n","      <td>0.633422</td>\n","      <td>0.636639</td>\n","      <td>0.679965</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.401685</td>\n","      <td>0.921691</td>\n","      <td>0.652662</td>\n","      <td>0.652662</td>\n","      <td>0.652662</td>\n","      <td>0.652662</td>\n","      <td>0.641077</td>\n","      <td>0.641050</td>\n","      <td>0.683075</td>\n","      <td>2404</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at Models/WangchanBERTa-exp4/Outputs/checkpoint-2250 were not used when initializing CustomSequenceClassification: ['baseEmb.position_ids', 'baseEmb.word_embeddings.weight', 'baseEmb.position_embeddings.weight', 'baseEmb.token_type_embeddings.weight', 'baseEmb.LayerNorm.weight', 'baseEmb.LayerNorm.bias', 'newEmb.position_ids', 'newEmb.word_embeddings.weight', 'newEmb.position_embeddings.weight', 'newEmb.token_type_embeddings.weight', 'newEmb.LayerNorm.weight', 'newEmb.LayerNorm.bias']\n","- This IS expected if you are initializing CustomSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CustomSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Done.\n","\n"]}]},{"cell_type":"code","metadata":{"id":"K63mJONBgbiB","executionInfo":{"status":"ok","timestamp":1638893527688,"user_tz":0,"elapsed":7074,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["trainer.save_model(f\"{DIR}/fine-tune-Exp4\")"],"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIwrxhH2cLsR"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"lRczslIwcNmh","executionInfo":{"status":"ok","timestamp":1638893527689,"user_tz":0,"elapsed":31,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jqZS4kR_1lM","executionInfo":{"status":"ok","timestamp":1638893527690,"user_tz":0,"elapsed":28,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# (model.classifier.dense.weight.shape-trainer.model.classifier.dense.weight.shape).sum()"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-iWxTbYZKh4","executionInfo":{"status":"ok","timestamp":1638893530905,"user_tz":0,"elapsed":3241,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["# assert(torch.equal(model.classifier.dense.weight, trainer.model.classifier.dense.weight))\n","trainer.model = CustomSequenceClassification(model.config, model)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjcp02iSgYgC","executionInfo":{"status":"ok","timestamp":1638893530907,"user_tz":0,"elapsed":20,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":["trainer.model.eval();"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lAOts0QgwKba","executionInfo":{"status":"ok","timestamp":1638893683797,"user_tz":0,"elapsed":152908,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}},"outputId":"0ba33354-1a70-448c-c618-bc81f88689e1"},"source":["\n","for split_name in dataset_split:\n","  if split_name.startswith(\"train\"):\n","    continue\n","\n","  p, label_ids, result = trainer.predict(test_dataset=dataset_split[split_name])\n","  print(f'Evaluation on {split_name}:')    \n","\n","  for key, value in result.items():\n","      print(f'{key} : {value:.4f}')\n","  \n","  print(\"*\"*40)\n","  print()"],"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1299' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [301/301 02:32]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation on validation:\n","eval_loss : 0.9217\n","eval_accuracy : 0.6527\n","eval_f1_micro : 0.6527\n","eval_precision_micro : 0.6527\n","eval_recall_micro : 0.6527\n","eval_f1_macro : 0.6411\n","eval_precision_macro : 0.6410\n","eval_recall_macro : 0.6831\n","eval_nb_samples : 2404.0000\n","****************************************\n","\n","Evaluation on test:\n","eval_loss : 0.8919\n","eval_accuracy : 0.6593\n","eval_f1_micro : 0.6593\n","eval_precision_micro : 0.6593\n","eval_recall_micro : 0.6593\n","eval_f1_macro : 0.6453\n","eval_precision_macro : 0.6419\n","eval_recall_macro : 0.6875\n","eval_nb_samples : 2671.0000\n","****************************************\n","\n","Evaluation on test-corr:\n","eval_loss : 0.9176\n","eval_accuracy : 0.6670\n","eval_f1_micro : 0.6670\n","eval_precision_micro : 0.6670\n","eval_recall_micro : 0.6670\n","eval_f1_macro : 0.6650\n","eval_precision_macro : 0.6684\n","eval_recall_macro : 0.7027\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-misp:\n","eval_loss : 0.9588\n","eval_accuracy : 0.6432\n","eval_f1_micro : 0.6432\n","eval_precision_micro : 0.6432\n","eval_recall_micro : 0.6432\n","eval_f1_macro : 0.6421\n","eval_precision_macro : 0.6509\n","eval_recall_macro : 0.6858\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-mae:\n","eval_loss : 0.9426\n","eval_accuracy : 0.6614\n","eval_f1_micro : 0.6614\n","eval_precision_micro : 0.6614\n","eval_recall_micro : 0.6614\n","eval_f1_macro : 0.6604\n","eval_precision_macro : 0.6652\n","eval_recall_macro : 0.7022\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-all-mae:\n","eval_loss : 0.8866\n","eval_accuracy : 0.6653\n","eval_f1_micro : 0.6653\n","eval_precision_micro : 0.6653\n","eval_recall_micro : 0.6653\n","eval_f1_macro : 0.6510\n","eval_precision_macro : 0.6466\n","eval_recall_macro : 0.6929\n","eval_nb_samples : 2671.0000\n","****************************************\n","\n"]}]},{"cell_type":"code","metadata":{"id":"UZv8Xs1F674m","executionInfo":{"status":"ok","timestamp":1638893683798,"user_tz":0,"elapsed":39,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"bo7F93aYDNUQ","executionInfo":{"status":"ok","timestamp":1638888666243,"user_tz":0,"elapsed":303,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz1tosO6ue4YIwI_BWdWqU-R0kipZPrUw2DtS0=s64","userId":"14261168557301921642"}}},"source":[""],"execution_count":38,"outputs":[]}]}