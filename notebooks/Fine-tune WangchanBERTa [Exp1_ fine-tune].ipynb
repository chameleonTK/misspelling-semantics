{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine-tune WangchanBERTa [Exp1: fine-tune].ipynb","provenance":[{"file_id":"1VwHo8gTBIwR-EQfMmTCEnzvGpJLTQkCw","timestamp":1635777473931},{"file_id":"10cvKYjXX__tjyByBPQVzyZjm2otyYShy","timestamp":1631707464118},{"file_id":"1gh-cr1UCdC6yAZd1oOxAnMhCUdBFhkB4","timestamp":1630822152939},{"file_id":"1hdFRWS-l9mQmL614VWgsUMw2ln0uuLyh","timestamp":1630690751565},{"file_id":"187rIuGjNJiFqXgLgZg8hbPVspntafDIZ","timestamp":1625408544629},{"file_id":"1PFtJQ_yIxQw_qJXIJhVQ8BdgOFtoVOMN","timestamp":1625391206435},{"file_id":"15eHqe3dQJw63mhVyCoeuhyxrS0eHMagX","timestamp":1624633400803}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ICAWf9vLw2j","executionInfo":{"status":"ok","timestamp":1638885817024,"user_tz":0,"elapsed":278,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"95b455e4-9825-4517-c575-3719caaaea48"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LL80zCUIOxsh","executionInfo":{"status":"ok","timestamp":1638883399783,"user_tz":0,"elapsed":184165,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"69e72dd2-7ed1-497d-f71d-409aa4a2f4a4"},"source":["# Install libs\n","!pip -q install torch==1.5.0\n","!pip -q install torchtext==0.6"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 752.0 MB 9.2 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\u001b[0m\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64 kB 2.4 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 26.3 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"3KIzREva71h7","executionInfo":{"status":"ok","timestamp":1638883399784,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQYCxkCFycRm","executionInfo":{"status":"ok","timestamp":1638883511018,"user_tz":0,"elapsed":111240,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"47d38e82-34de-4019-acca-3702b8fbab20"},"source":["!pip -q install thai2transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 17.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 38.4 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170 kB 52.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.0 MB 13.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298 kB 43.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.7 MB 19.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43 kB 2.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524 kB 38.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.1 MB 50.6 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9 MB 40.4 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 40.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 36.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 243 kB 52.7 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132 kB 49.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61 kB 267 kB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 743 kB 35.8 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271 kB 45.8 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160 kB 52.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 192 kB 53.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 332 kB 37.8 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 829 kB 54.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 41.6 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 834.1 MB 1.4 MB/s eta 0:00:34tcmalloc: large alloc 1147494400 bytes == 0x557026b80000 @  0x7feaab24a615 0x5570210ae4cc 0x55702118e47a 0x5570210b12ed 0x5570211a2e1d 0x557021124e99 0x55702111f9ee 0x5570210b2bda 0x557021124d00 0x55702111f9ee 0x5570210b2bda 0x557021121737 0x5570211a3c66 0x557021120daf 0x5570211a3c66 0x557021120daf 0x5570211a3c66 0x557021120daf 0x5570210b3039 0x5570210f6409 0x5570210b1c52 0x557021124c25 0x55702111f9ee 0x5570210b2bda 0x557021121737 0x55702111f9ee 0x5570210b2bda 0x557021120915 0x5570210b2afa 0x557021120c0d 0x55702111f9ee\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 881.9 MB 19 kB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321 kB 33.8 MB/s \n","\u001b[?25h  Building wheel for thai2transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"WRBpkHFl3AQV","executionInfo":{"status":"ok","timestamp":1638883511018,"user_tz":0,"elapsed":24,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["fin = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\")\n","content = []\n","for line in fin:\n","  content.append(line)\n","fin.close()\n","\n","content[39] = \"    SAVE_STATE_WARNING = ''\\n\"\n","\n","fout = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\", \"w\")\n","for line in content:\n","  fout.write(line)\n","fout.close()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TKD9JcvO4xh","executionInfo":{"status":"ok","timestamp":1638883511019,"user_tz":0,"elapsed":19,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# from packaging import version\n","# import torch\n","# if version.parse(torch.__version__) <= version.parse(\"1.4.1\"):\n","#     SAVE_STATE_WARNING = \"\"\n","# else:\n","#     from torch.optim.lr_scheduler import SAVE_STATE_WARNING"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"dA0f5_Um2DPf","executionInfo":{"status":"ok","timestamp":1638883511019,"user_tz":0,"elapsed":17,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip install -q pytorch-lightning"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5f9moE7PHpe","executionInfo":{"status":"ok","timestamp":1638883511020,"user_tz":0,"elapsed":17,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip -q install git+https://github.com/PyTorchLightning/pytorch-lightning\n","# import pytorch_lightning as pl\n","# print(pl.__version__)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAR-Di_UPKGX","executionInfo":{"status":"ok","timestamp":1638883511020,"user_tz":0,"elapsed":17,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCFx-P4FQUaz"},"source":["# Load Pre-trained Model"]},{"cell_type":"code","metadata":{"id":"QDRhumG6NRoO","executionInfo":{"status":"ok","timestamp":1638885857852,"user_tz":0,"elapsed":365,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GUiDe3ye6Ks","executionInfo":{"status":"ok","timestamp":1638885855532,"user_tz":0,"elapsed":280,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"ec8d9330-3f13-4093-bb48-8e2f3d68257b"},"source":["cd /content/drive/MyDrive/Mispelling/misspelling-semantics/"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Mispelling/misspelling-semantics\n"]}]},{"cell_type":"code","metadata":{"id":"og7jEc7eL9FJ","executionInfo":{"status":"ok","timestamp":1638885860755,"user_tz":0,"elapsed":268,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["DIR = \"Models/WangchanBERTa-exp1\""],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubHucCA5QW93","executionInfo":{"status":"ok","timestamp":1638885861285,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["model_idx = 0\n","model_name = \"wangchanberta\"\n","# model_name = \"xlmr\"\n","# model_name = \"mbert\"\n","args_params = f\"{model_name} wisesight_sentiment {DIR}/Outputs/ {DIR}/Logs/ --batch_size 8 --seed {model_idx} --run_name exp1 --num_train_epochs 10\""],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-BVhvmoQXpk","executionInfo":{"status":"ok","timestamp":1638885864401,"user_tz":0,"elapsed":2461,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import argparse\n","import math\n","import os\n","from functools import partial\n","import urllib.request\n","from tqdm import tqdm\n","from typing import Collection, Callable\n","from pathlib import Path\n","from sklearn import preprocessing\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from transformers import (\n","    AdamW, \n","    get_linear_schedule_with_warmup, \n","    get_constant_schedule, \n","    AutoTokenizer, \n","    AutoModel,\n","    AutoModelForSequenceClassification, \n","    AutoConfig,\n","    Trainer, \n","    TrainingArguments,\n","    CamembertTokenizer,\n","    BertTokenizer,\n","    BertTokenizerFast,\n","    BertConfig,\n","    XLMRobertaTokenizer,\n","    XLMRobertaTokenizerFast,\n","    XLMRobertaConfig,\n","    DataCollatorWithPadding,\n","    default_data_collator\n",")\n","\n","from datasets import load_dataset, list_metrics, load_dataset, Dataset\n","from thai2transformers.datasets import SequenceClassificationDataset\n","from thai2transformers.metrics import classification_metrics, multilabel_classification_metrics\n","from thai2transformers.finetuners import SequenceClassificationFinetuner\n","from thai2transformers.auto import AutoModelForMultiLabelSequenceClassification\n","from thai2transformers.tokenizers import (\n","    ThaiRobertaTokenizer,\n","    ThaiWordsNewmmTokenizer,\n","    ThaiWordsSyllableTokenizer,\n","    FakeSefrCutTokenizer,\n",")\n","from thai2transformers.utils import get_dict_val\n","from thai2transformers.conf import Task\n","from thai2transformers import preprocess\n","\n","CACHE_DIR = f'{str(Path.home())}/.cache/huggingface_datasets'\n","\n","METRICS = {\n","    Task.MULTICLASS_CLS: classification_metrics,\n","    Task.MULTILABEL_CLS: multilabel_classification_metrics\n","}\n","\n","PUBLIC_MODEL = {\n","    # 'mbert': {\n","    #     'name': 'bert-base-multilingual-cased',\n","    #     'tokenizer': BertTokenizerFast.from_pretrained('bert-base-multilingual-cased'),\n","    #     'config': BertConfig.from_pretrained('bert-base-multilingual-cased'),\n","    # },\n","    'xlmr': {\n","        'name': 'xlm-roberta-base',\n","        'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base'),\n","        'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    },\n","    # 'xlmr-large': {\n","    #     'name': 'xlm-roberta-large',\n","    #     'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-large'),\n","    #     'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","    # 'thbert': {\n","    #     'name': 'monsoon-nlp/bert-base-thai',\n","    #     'tokenizer': AutoTokenizer.from_pretrained('monsoon-nlp/bert-base-thai'),\n","    #     'config': AutoConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","}\n","\n","TOKENIZER_CLS = {\n","    'wangchanberta': CamembertTokenizer,\n","    # 'spm': ThaiRobertaTokenizer,\n","    # 'newmm': ThaiWordsNewmmTokenizer,\n","    # 'syllable': ThaiWordsSyllableTokenizer,\n","    # 'sefr_cut': FakeSefrCutTokenizer,\n","}\n","\n","DATASET_METADATA = {\n","    'wisesight_sentiment': {\n","        'huggingface_dataset_name': 'wisesight_sentiment',\n","        'task': Task.MULTICLASS_CLS,\n","        'text_input_col_name': 'texts',\n","        'label_col_name': 'category',\n","        'num_labels': 3,\n","        'split_names': ['train', 'validation', 'test']\n","    }\n","}\n","\n","def init_public_model_tokenizer_for_seq_cls(public_model_name, task, num_labels):\n","    \n","    config = PUBLIC_MODEL[public_model_name]['config']\n","    config.num_labels = num_labels\n","    tokenizer = PUBLIC_MODEL[public_model_name]['tokenizer']\n","    model_name = PUBLIC_MODEL[public_model_name]['name']\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n","                                                                   config=config)\n","    if task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(model_name,\n","                                                                             config=config)\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_model_tokenizer_for_seq_cls(model_dir, tokenizer_cls, tokenizer_dir, task, num_labels):\n","    \n","    config = AutoConfig.from_pretrained(\n","        model_dir,\n","        num_labels=num_labels\n","    );\n","\n","    tokenizer = tokenizer_cls.from_pretrained(\n","        tokenizer_dir,\n","    );\n","\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","    elif task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_trainer(task, model, train_dataset, val_dataset, warmup_steps, args, data_collator=default_data_collator): \n","        \n","    training_args = TrainingArguments(\n","                        num_train_epochs=args.num_train_epochs,\n","                        per_device_train_batch_size=args.batch_size,\n","                        per_device_eval_batch_size=args.batch_size,\n","                        gradient_accumulation_steps=args.gradient_accumulation_steps,\n","                        learning_rate=args.learning_rate,\n","                        warmup_steps=warmup_steps,\n","                        weight_decay=args.weight_decay,\n","                        adam_epsilon=args.adam_epsilon,\n","                        max_grad_norm=args.max_grad_norm,\n","                        #checkpoint\n","                        output_dir=args.output_dir,\n","                        overwrite_output_dir=True,\n","                        #logs\n","                        logging_dir=args.log_dir,\n","                        logging_first_step=False,\n","                        logging_steps=args.logging_steps,\n","                        #eval\n","                        evaluation_strategy='epoch' if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else 'no',\n","                        load_best_model_at_end=True,\n","                        #others\n","                        seed=args.seed,\n","                        fp16=args.fp16,\n","                        fp16_opt_level=args.fp16_opt_level,\n","                        dataloader_drop_last=False,\n","                        no_cuda=args.no_cuda,\n","                        metric_for_best_model=args.metric_for_best_model,\n","                        prediction_loss_only=False,\n","                        run_name=args.run_name\n","                    )\n","    if task == Task.MULTICLASS_CLS:\n","        compute_metrics_fn = METRICS[task]\n","    elif task == Task.MULTILABEL_CLS:\n","        compute_metrics_fn = partial(METRICS[task],n_labels=DATASET_METADATA[args.dataset_name]['num_labels'])\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        compute_metrics=compute_metrics_fn,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        data_collator=data_collator\n","    )\n","    return trainer, training_args\n","\n","# def _process_transformers(\n","#     text: str,\n","#     pre_rules: Collection[Callable] = [\n","#         preprocess.fix_html,\n","#         preprocess.rm_brackets,\n","#         preprocess.replace_newlines,\n","#         preprocess.rm_useless_spaces,\n","#         preprocess.replace_spaces,\n","#         preprocess.replace_rep_after,\n","#     ],\n","#     tok_func: Callable = preprocess.word_tokenize,\n","#     post_rules: Collection[Callable] = [preprocess.ungroup_emoji, preprocess.replace_wrep_post],\n","#     lowercase: bool = False\n","# ) -> str:\n","#     if lowercase:\n","#         text = text.lower()\n","#     for rule in pre_rules:\n","#         text = rule(text)\n","#     toks = tok_func(text)\n","#     for rule in post_rules:\n","#         toks = rule(toks)\n","#     return \"\".join(toks)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anv_bUF0QZL2","executionInfo":{"status":"ok","timestamp":1638885864401,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"29da6c2f-84a8-48a3-c846-9b2358376eee"},"source":["parser = argparse.ArgumentParser()\n","# Required\n","parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","parser.add_argument('output_dir', type=str)\n","parser.add_argument('log_dir', type=str)\n","\n","parser.add_argument('--model_dir', type=str)\n","parser.add_argument('--tokenizer_dir', type=str)\n","parser.add_argument('--prepare_for_tokenization', action='store_true', default=False, help='To replace space with a special token e.g. `<_>`. This may require for some pretrained models.')\n","parser.add_argument('--space_token', type=str, default=' ', help='The special token for space, specify if argumet: prepare_for_tokenization is applied')\n","parser.add_argument('--max_length', type=int, default=None)\n","parser.add_argument('--lowercase', action='store_true', default=False)\n","\n","# Finetuning\n","parser.add_argument('--num_train_epochs', type=int, default=5)\n","parser.add_argument('--learning_rate', type=float, default=1e-05)\n","parser.add_argument('--weight_decay', type=float, default=0.01)\n","parser.add_argument('--warmup_ratio', type=float, default=0.1)\n","parser.add_argument('--batch_size', type=int, default=16)\n","parser.add_argument('--no_cuda', action='store_true', default=False)\n","parser.add_argument('--fp16', action='store_true', default=False)\n","parser.add_argument('--greater_is_better', action='store_true', default=True)\n","parser.add_argument('--metric_for_best_model', type=str, default='f1_micro')\n","parser.add_argument('--logging_steps', type=int, default=10)\n","parser.add_argument('--seed', type=int, default=2020)\n","parser.add_argument('--fp16_opt_level', type=str, default='O1')\n","parser.add_argument('--gradient_accumulation_steps', type=int, default=1)\n","parser.add_argument('--adam_epsilon', type=float, default=1e-08)\n","parser.add_argument('--max_grad_norm', type=float, default=1.0)\n","\n","# wandb\n","parser.add_argument('--run_name', type=str, default=None)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--run_name'], dest='run_name', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help=None, metavar=None)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"qCeYWu0tQauI","executionInfo":{"status":"ok","timestamp":1638885864402,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","# parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","# parser.add_argument('output_dir', type=str)\n","# parser.add_argument('log_dir', type=str)\n","args = parser.parse_args(args_params.split())\n","\n","# Set seed\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrh47k-vQc92","executionInfo":{"status":"ok","timestamp":1638885864402,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"9faa7ffb-e41f-4087-82a8-7c73470b71e8"},"source":["\n","# try:\n","print(f'\\n\\n[INFO] Dataset: {args.dataset_name}')\n","print(f'\\n\\n[INFO] Huggingface\\'s dataset name: {DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"]} ')\n","print(f'[INFO] Task: {DATASET_METADATA[args.dataset_name][\"task\"].value}')\n","print(f'\\n[INFO] space_token: {args.space_token}')\n","print(f'[INFO] prepare_for_tokenization: {args.prepare_for_tokenization}\\n')\n"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","[INFO] Dataset: wisesight_sentiment\n","\n","\n","[INFO] Huggingface's dataset name: wisesight_sentiment \n","[INFO] Task: multiclass_classification\n","\n","[INFO] space_token:  \n","[INFO] prepare_for_tokenization: False\n","\n"]}]},{"cell_type":"code","metadata":{"id":"SgzmOBvkQoTB","executionInfo":{"status":"ok","timestamp":1638885864402,"user_tz":0,"elapsed":4,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# dataset = load_dataset(DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"])"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChlS02wkQqRr","executionInfo":{"status":"ok","timestamp":1638885864403,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# labels = {\n","#     \"neg\": 2,\n","#     \"neu\": 1,\n","#     \"pos\": 0,\n","#     \"q\": 3\n","# }\n","# dataset"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8AMunmmXv3V","executionInfo":{"status":"ok","timestamp":1638885864403,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# dataset[\"train\"][0:5]"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nv7ywhlqWau3","executionInfo":{"status":"ok","timestamp":1638885870055,"user_tz":0,"elapsed":5657,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"c9e02531-f0a3-440d-8bd7-a66df1ebf850"},"source":["text_input_col_name = DATASET_METADATA[args.dataset_name]['text_input_col_name']\n","\n","if args.tokenizer_type_or_public_model_name not in list(TOKENIZER_CLS.keys()) \\\n","    and args.tokenizer_type_or_public_model_name not in list(PUBLIC_MODEL.keys()):\n","    raise f\"The tokenizer type or public model name `{args.tokenizer_type_or_public_model_name}`` is not supported\"\n","\n","if args.tokenizer_type_or_public_model_name in list(TOKENIZER_CLS.keys()):\n","    tokenizer_cls = TOKENIZER_CLS[args.tokenizer_type_or_public_model_name]\n","\n","\n","task = DATASET_METADATA[args.dataset_name]['task']\n","if args.tokenizer_type_or_public_model_name in PUBLIC_MODEL.keys():\n","    print(args.tokenizer_type_or_public_model_name)\n","    model, tokenizer, config = init_public_model_tokenizer_for_seq_cls(args.tokenizer_type_or_public_model_name,\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);\n","else:\n","    print(\"WangchanBERTa\")\n","    model, tokenizer, config = init_model_tokenizer_for_seq_cls(\"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        tokenizer_cls,\n","                                                        \"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["WangchanBERTa\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"8dcSKA23WpQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638885870056,"user_tz":0,"elapsed":15,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"decfdb1e-127a-46b8-8d8f-6554815c5a92"},"source":["# if args.tokenizer_type_or_public_model_name == 'wangchanberta':\n","#     tokenizer.additional_special_tokens = ['<s>NOTUSED', '</s>NOTUSED', args.space_token]\n","\n","print('\\n[INFO] Preprocess and tokenizing texts in datasets')\n","max_length = args.max_length if args.max_length else config.max_position_embeddings\n","print(f'[INFO] max_length = {max_length} \\n')"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Preprocess and tokenizing texts in datasets\n","[INFO] max_length = 512 \n","\n"]}]},{"cell_type":"code","metadata":{"id":"AfYFfObgad6q","executionInfo":{"status":"ok","timestamp":1638885870056,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip -q install demoji\n","# import demoji\n","# demoji.download_codes()"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqsSdW8KbbFd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638885870056,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"e97259e7-b187-4890-c806-5d1c05758c9f"},"source":["ls"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":[" \u001b[0m\u001b[01;34mDatasets\u001b[0m/\n","'Fine-tune WangchanBERTa [Exp1: fine-tune].ipynb'\n","'Fine-tune WangchanBERTa [Exp2: MST].ipynb'\n","'Fine-tune WangchanBERTa [Exp3: few-shot].ipynb'\n","'Fine-tune WangchanBERTa [Exp4: few-shot+MST].ipynb'\n","'Misspelling Patterns.ipynb'\n"," \u001b[01;34mModels\u001b[0m/\n"," test_mispelling_correction.jsonl\n","'Tokenize Wisesight Data.ipynb'\n","'Train FastText.ipynb'\n","'Train LSTM on FastText [Exp1: FT].ipynb'\n","'Train LSTM on FastText [Exp2: VEC].ipynb'\n","'Train LSTM on FastText [Exp3: VEC+MST].ipynb'\n","'Train LSTM on FastText [Exp4: VEC-corr].ipynb'\n"," train_mispelling_dection.jsonl\n"]}]},{"cell_type":"markdown","metadata":{"id":"2mTebN_FOhqa"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"rBcBdWSQOjP2","executionInfo":{"status":"ok","timestamp":1638885870563,"user_tz":0,"elapsed":3,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import json\n","import pandas as pd\n","\n","def load_jsonl(fname):\n","    fin = open(fname, encoding=\"utf-8\")\n","    data = []\n","    for line in fin:\n","        d = json.loads(line.strip())\n","        data.append(d)\n","\n","    return data\n","\n","def save_jsonl(data, filename):\n","    with open(filename, \"w\", encoding=\"utf-8\") as fo:\n","        for idx, d in enumerate(data):\n","            fo.write(json.dumps(d, ensure_ascii=False))\n","            fo.write(\"\\n\")"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpjyO0OwOjSW","executionInfo":{"status":"ok","timestamp":1638885873785,"user_tz":0,"elapsed":3225,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["traindata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_train.jsonl\")\n","validdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_valid.jsonl\")\n","testdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_test-misp.jsonl\")"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTPLMhBQO4u3","executionInfo":{"status":"ok","timestamp":1638885873785,"user_tz":0,"elapsed":29,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"988f0bd5-d9e5-4c0b-f57b-31c22086c41e"},"source":["import itertools\n","def filterByMode(data, mode=None):\n","  output = []\n","  for sent in data:\n","    if mode is None:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","    elif mode==\"corr\":\n","      tokenized = [seg[1] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    else:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    \n","    tokenized = list(itertools.chain(*tokenized))\n","  \n","    output.append({\n","        \"category\": sent[\"category\"],\n","        \"text\": sent[\"text\"],\n","        \"tokenized\": tokenized,\n","        \"segments\": sent[\"segments\"]\n","    })\n","\n","  return output\n","\n","traindata\n","validdata\n","allTestdata = filterByMode(testdata)\n","corrTestdata = filterByMode(testdata, \"corr\")\n","mispTestdata = filterByMode(testdata, \"misp\")\n","len(allTestdata), len(corrTestdata), len(mispTestdata)"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2671, 880, 880)"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"xflkz27paVDG","executionInfo":{"status":"ok","timestamp":1638885873786,"user_tz":0,"elapsed":21,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ewn4a1gWPCKC","executionInfo":{"status":"ok","timestamp":1638885873786,"user_tz":0,"elapsed":20,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"a2f2632b-0c4b-4b43-8df2-9a0f4fdcaed6"},"source":["for sent in testdata[1:10]:\n","  print(sent)\n","  # break"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["{'category': 'neu', 'text': '‡∏Ñ‡∏£‡∏±‡∏ö #phithanbkk', 'misp_tokens': [], 'tokenized': ['‡∏Ñ‡∏£‡∏±‡∏ö', ' ', '#phithanbkk'], 'segments': [[['‡∏Ñ‡∏£‡∏±‡∏ö', ' ', '#phithanbkk'], ['‡∏Ñ‡∏£‡∏±‡∏ö', ' ', '#phithanbkk']]]}\n","{'category': 'neg', 'text': '‡∏Å‡∏≤‡∏£‡∏î‡πà‡∏≤‡πÑ‡∏õ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÄ‡∏â‡∏¢‡πÜ ‡πÅ‡∏ï‡πà‡∏ö‡∏µ‡∏ó‡∏µ‡πÄ‡∏≠‡∏™ (‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤) ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏ô‡∏∂‡∏Å‡∏°‡∏±‡πâ‡∏¢ ‡∏Å‡πá‡πÑ‡∏°‡πà‡∏≠‡πà‡∏∞ üòï', 'misp_tokens': [{'corr': '‡πÑ‡∏´‡∏°', 'misp': '‡∏°‡∏±‡πâ‡∏¢', 'int': True, 's': 67, 't': 71}], 'tokenized': ['‡∏Å‡∏≤‡∏£', '‡∏î‡πà‡∏≤', '‡πÑ‡∏õ', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤', '‡∏Ñ‡∏ß‡∏≤‡∏°', '‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î', '‡πÄ‡∏â‡∏¢', '‡πÜ', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏µ‡∏ó‡∏µ‡πÄ‡∏≠‡∏™', ' ', '(', '‡∏£‡∏ñ', '‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', ')', ' ', '‡∏°‡∏±‡∏ô', '‡∏™‡∏≥‡∏ô‡∏∂‡∏Å', '‡∏°‡∏±‡πâ‡∏¢', ' ', '‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡∏≠‡πà‡∏∞', ' ', 'confused', ' ', 'face'], 'segments': [[['‡∏Å‡∏≤‡∏£', '‡∏î‡πà‡∏≤', '‡πÑ‡∏õ', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤', '‡∏Ñ‡∏ß‡∏≤‡∏°', '‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î', '‡πÄ‡∏â‡∏¢', '‡πÜ', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏µ‡∏ó‡∏µ‡πÄ‡∏≠‡∏™', ' ', '(', '‡∏£‡∏ñ', '‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', ')', ' ', '‡∏°‡∏±‡∏ô', '‡∏™‡∏≥‡∏ô‡∏∂‡∏Å'], ['‡∏Å‡∏≤‡∏£', '‡∏î‡πà‡∏≤', '‡πÑ‡∏õ', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤', '‡∏Ñ‡∏ß‡∏≤‡∏°', '‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î', '‡πÄ‡∏â‡∏¢', '‡πÜ', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏µ‡∏ó‡∏µ‡πÄ‡∏≠‡∏™', ' ', '(', '‡∏£‡∏ñ', '‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', ')', ' ', '‡∏°‡∏±‡∏ô', '‡∏™‡∏≥‡∏ô‡∏∂‡∏Å']], [['‡∏°‡∏±‡πâ‡∏¢'], ['‡πÑ‡∏´‡∏°']], [['‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡∏≠‡πà‡∏∞', ' ', 'confused', ' ', 'face'], ['‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡∏≠‡πà‡∏∞', ' ', 'confused', ' ', 'face']]]}\n","{'category': 'neu', 'text': 'Cf clarins 5 ‡∏Ç‡∏ß‡∏î 2850', 'misp_tokens': [], 'tokenized': ['Cf', ' ', 'clarins', ' ', '5', ' ', '‡∏Ç‡∏ß‡∏î', ' ', '2850'], 'segments': [[['Cf', ' ', 'clarins', ' ', '5', ' ', '‡∏Ç‡∏ß‡∏î', ' ', '2850'], ['Cf', ' ', 'clarins', ' ', '5', ' ', '‡∏Ç‡∏ß‡∏î', ' ', '2850']]]}\n","{'category': 'neu', 'text': '‡∏ó‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏∞ ‡∏ô‡πâ‡∏≥‡∏ã‡∏∏‡∏õ MK ‡∏ï‡πâ‡∏°‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏±‡∏ß‡∏ú‡∏±‡∏Å‡∏Å‡∏≤‡∏î ‡∏ã‡∏µ‡∏≠‡∏¥‡πâ‡∏ß‡∏Ç‡∏≤‡∏ß ‡πÄ‡∏Å‡∏•‡∏∑‡∏≠ ‡πÅ‡∏•‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡∏Ñ‡πà‡∏∞', 'misp_tokens': [{'corr': '‡πÅ‡∏•‡∏∞', 'misp': '‡πÅ‡∏•', 'int': False, 's': 54, 't': 56}], 'tokenized': ['‡∏ó‡∏≤‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡πà‡∏∞', ' ', '‡∏ô‡πâ‡∏≥', '‡∏ã‡∏∏‡∏õ', ' ', 'MK', ' ', '‡∏ï‡πâ‡∏°', '‡∏°‡∏≤', '‡∏à‡∏≤‡∏Å', '‡∏´‡∏±‡∏ß', '‡∏ú‡∏±‡∏Å‡∏Å‡∏≤‡∏î', ' ', '‡∏ã‡∏µ‡∏≠‡∏¥‡πâ‡∏ß‡∏Ç‡∏≤‡∏ß', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', ' ', '‡πÅ‡∏•', '‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•', '‡∏Ñ‡πà‡∏∞'], 'segments': [[['‡∏ó‡∏≤‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡πà‡∏∞', ' ', '‡∏ô‡πâ‡∏≥', '‡∏ã‡∏∏‡∏õ', ' ', 'MK', ' ', '‡∏ï‡πâ‡∏°', '‡∏°‡∏≤', '‡∏à‡∏≤‡∏Å', '‡∏´‡∏±‡∏ß', '‡∏ú‡∏±‡∏Å‡∏Å‡∏≤‡∏î', ' ', '‡∏ã‡∏µ‡∏≠‡∏¥‡πâ‡∏ß‡∏Ç‡∏≤‡∏ß', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠'], ['‡∏ó‡∏≤‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡πà‡∏∞', ' ', '‡∏ô‡πâ‡∏≥', '‡∏ã‡∏∏‡∏õ', ' ', 'MK', ' ', '‡∏ï‡πâ‡∏°', '‡∏°‡∏≤', '‡∏à‡∏≤‡∏Å', '‡∏´‡∏±‡∏ß', '‡∏ú‡∏±‡∏Å‡∏Å‡∏≤‡∏î', ' ', '‡∏ã‡∏µ‡∏≠‡∏¥‡πâ‡∏ß‡∏Ç‡∏≤‡∏ß', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠']], [['‡πÅ‡∏•'], ['‡πÅ‡∏•‡∏∞']], [['‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•', '‡∏Ñ‡πà‡∏∞'], ['‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•', '‡∏Ñ‡πà‡∏∞']]]}\n","{'category': 'neu', 'text': '‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ú‡∏¥‡∏ß‡∏à‡∏≤‡∏Å‡πÅ‡∏™‡∏á‡πÅ‡∏î‡∏î ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏Ñ‡∏£‡∏µ‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏î‡∏î ‡∏™‡∏≤‡∏ß‡πÜ‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà ‡πÅ‡∏ï‡πà‡∏ö‡∏≠‡∏Å‡πÄ‡∏•‡∏¢‡∏ß‡πà‡∏≤ ‡∏ú‡∏¥‡∏î‡∏°‡∏≤‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏™‡∏á‡πÅ‡∏î‡∏î‡∏™‡∏°‡∏±‡∏¢‡∏ô‡∏µ‡πâ‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏≠‡∏ô‡∏∏‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏•‡∏≤‡∏¢‡∏ú‡∏¥‡∏ß‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏ß‡πÄ‡∏£‡∏≤‡∏ñ‡∏π‡∏Å‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏ã‡πâ‡∏≥‡πÜ‡∏ã‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≤‡∏Ñ‡∏£‡∏µ‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏î‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á Eucerin Sun Age Repair Serum ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ñ‡∏£‡∏µ‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏î‡∏î‡∏°‡∏µ‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ã‡∏∑‡πâ‡∏≠‡∏Å‡πá‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á Eucerin Sun Acne oil Control ‡∏Ñ‡πà‡∏∞', 'misp_tokens': [], 'tokenized': ['‡πÄ‡∏Ñ‡∏•‡πá‡∏î', '‡∏•‡∏±‡∏ö', '‡∏ó‡∏µ‡πà', '‡∏Ç‡∏≤‡∏î', '‡πÑ‡∏°‡πà', '‡πÑ‡∏î‡πâ', '‡πÉ‡∏ô', '‡∏Å‡∏≤‡∏£', '‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô', '‡∏ú‡∏¥‡∏ß', '‡∏à‡∏≤‡∏Å', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', ' ', '‡∏Ñ‡∏∑‡∏≠', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', ' ', '‡∏™‡∏≤‡∏ß', '‡πÜ', '‡∏ö‡πâ‡∏≤‡∏á', '‡∏Ñ‡∏ô', '‡∏≠‡∏≤‡∏à', '‡∏à‡∏∞', '‡∏Ñ‡∏¥‡∏î', '‡∏ß‡πà‡∏≤', '‡∏°‡∏±‡∏ô', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡πÄ‡∏ó‡πà‡∏≤', '‡πÑ‡∏´‡∏£‡πà', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏≠‡∏Å', '‡πÄ‡∏•‡∏¢', '‡∏ß‡πà‡∏≤', ' ', '‡∏ú‡∏¥‡∏î', '‡∏°‡∏≤‡∏Å', ' ', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', '‡∏™‡∏°‡∏±‡∏¢', '‡∏ô‡∏µ‡πâ', '‡πÅ‡∏£‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡πÅ‡∏•‡∏∞', '‡∏°‡∏µ', '‡∏≠‡∏ô‡∏∏‡∏†‡∏≤‡∏û', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≥‡∏•‡∏≤‡∏¢', '‡∏ú‡∏¥‡∏ß', '‡∏™‡∏π‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡∏ñ‡πâ‡∏≤', '‡πÑ‡∏°‡πà', '‡∏≠‡∏¢‡∏≤‡∏Å', '‡πÉ‡∏´‡πâ', '‡∏ú‡∏¥‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏ñ‡∏π‡∏Å', '‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢', '‡πÅ‡∏ö‡∏ö', '‡∏ã‡πâ‡∏≥', '‡πÜ', '‡∏ã‡∏≤‡∏Å', ' ', '‡∏Ñ‡∏ß‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏°‡∏µ', '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', '‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏°‡∏µ', '‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢', '‡πÉ‡∏´‡πâ', '‡πÄ‡∏£‡∏≤', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Å‡πá', '‡∏à‡∏£‡∏¥‡∏á', ' ', '‡πÅ‡∏ï‡πà', '‡∏Å‡πá', '‡∏≠‡∏¢‡πà‡∏≤', '‡∏•‡∏∑‡∏°', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏™‡∏¥‡πà‡∏á', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î', '‡πÉ‡∏´‡πâ', '‡∏ï‡∏±‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', '‡∏Ñ‡πà‡∏∞'], 'segments': [[['‡πÄ‡∏Ñ‡∏•‡πá‡∏î', '‡∏•‡∏±‡∏ö', '‡∏ó‡∏µ‡πà', '‡∏Ç‡∏≤‡∏î', '‡πÑ‡∏°‡πà', '‡πÑ‡∏î‡πâ', '‡πÉ‡∏ô', '‡∏Å‡∏≤‡∏£', '‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô', '‡∏ú‡∏¥‡∏ß', '‡∏à‡∏≤‡∏Å', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', ' ', '‡∏Ñ‡∏∑‡∏≠', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', ' ', '‡∏™‡∏≤‡∏ß', '‡πÜ', '‡∏ö‡πâ‡∏≤‡∏á', '‡∏Ñ‡∏ô', '‡∏≠‡∏≤‡∏à', '‡∏à‡∏∞', '‡∏Ñ‡∏¥‡∏î', '‡∏ß‡πà‡∏≤', '‡∏°‡∏±‡∏ô', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡πÄ‡∏ó‡πà‡∏≤', '‡πÑ‡∏´‡∏£‡πà', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏≠‡∏Å', '‡πÄ‡∏•‡∏¢', '‡∏ß‡πà‡∏≤', ' ', '‡∏ú‡∏¥‡∏î', '‡∏°‡∏≤‡∏Å', ' ', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', '‡∏™‡∏°‡∏±‡∏¢', '‡∏ô‡∏µ‡πâ', '‡πÅ‡∏£‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡πÅ‡∏•‡∏∞', '‡∏°‡∏µ', '‡∏≠‡∏ô‡∏∏‡∏†‡∏≤‡∏û', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≥‡∏•‡∏≤‡∏¢', '‡∏ú‡∏¥‡∏ß', '‡∏™‡∏π‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡∏ñ‡πâ‡∏≤', '‡πÑ‡∏°‡πà', '‡∏≠‡∏¢‡∏≤‡∏Å', '‡πÉ‡∏´‡πâ', '‡∏ú‡∏¥‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏ñ‡∏π‡∏Å', '‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢', '‡πÅ‡∏ö‡∏ö', '‡∏ã‡πâ‡∏≥', '‡πÜ', '‡∏ã‡∏≤‡∏Å', ' ', '‡∏Ñ‡∏ß‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏°‡∏µ', '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', '‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏°‡∏µ', '‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢', '‡πÉ‡∏´‡πâ', '‡πÄ‡∏£‡∏≤', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Å‡πá', '‡∏à‡∏£‡∏¥‡∏á', ' ', '‡πÅ‡∏ï‡πà', '‡∏Å‡πá', '‡∏≠‡∏¢‡πà‡∏≤', '‡∏•‡∏∑‡∏°', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏™‡∏¥‡πà‡∏á', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î', '‡πÉ‡∏´‡πâ', '‡∏ï‡∏±‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', '‡∏Ñ‡πà‡∏∞'], ['‡πÄ‡∏Ñ‡∏•‡πá‡∏î', '‡∏•‡∏±‡∏ö', '‡∏ó‡∏µ‡πà', '‡∏Ç‡∏≤‡∏î', '‡πÑ‡∏°‡πà', '‡πÑ‡∏î‡πâ', '‡πÉ‡∏ô', '‡∏Å‡∏≤‡∏£', '‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô', '‡∏ú‡∏¥‡∏ß', '‡∏à‡∏≤‡∏Å', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', ' ', '‡∏Ñ‡∏∑‡∏≠', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', ' ', '‡∏™‡∏≤‡∏ß', '‡πÜ', '‡∏ö‡πâ‡∏≤‡∏á', '‡∏Ñ‡∏ô', '‡∏≠‡∏≤‡∏à', '‡∏à‡∏∞', '‡∏Ñ‡∏¥‡∏î', '‡∏ß‡πà‡∏≤', '‡∏°‡∏±‡∏ô', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡πÄ‡∏ó‡πà‡∏≤', '‡πÑ‡∏´‡∏£‡πà', ' ', '‡πÅ‡∏ï‡πà', '‡∏ö‡∏≠‡∏Å', '‡πÄ‡∏•‡∏¢', '‡∏ß‡πà‡∏≤', ' ', '‡∏ú‡∏¥‡∏î', '‡∏°‡∏≤‡∏Å', ' ', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡πÅ‡∏™‡∏á', '‡πÅ‡∏î‡∏î', '‡∏™‡∏°‡∏±‡∏¢', '‡∏ô‡∏µ‡πâ', '‡πÅ‡∏£‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡πÅ‡∏•‡∏∞', '‡∏°‡∏µ', '‡∏≠‡∏ô‡∏∏‡∏†‡∏≤‡∏û', '‡∏Å‡∏≤‡∏£', '‡∏ó‡∏≥‡∏•‡∏≤‡∏¢', '‡∏ú‡∏¥‡∏ß', '‡∏™‡∏π‡∏á', '‡∏°‡∏≤‡∏Å', ' ', '‡∏ñ‡πâ‡∏≤', '‡πÑ‡∏°‡πà', '‡∏≠‡∏¢‡∏≤‡∏Å', '‡πÉ‡∏´‡πâ', '‡∏ú‡∏¥‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏ñ‡∏π‡∏Å', '‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢', '‡πÅ‡∏ö‡∏ö', '‡∏ã‡πâ‡∏≥', '‡πÜ', '‡∏ã‡∏≤‡∏Å', ' ', '‡∏Ñ‡∏ß‡∏£', '‡∏ó‡∏≤', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏°‡∏µ', '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', '‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô', '‡∏Ñ‡∏£‡∏µ‡∏°', '‡∏Å‡∏±‡∏ô', '‡πÅ‡∏î‡∏î', '‡∏°‡∏µ', '‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢', '‡πÉ‡∏´‡πâ', '‡πÄ‡∏£‡∏≤', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Å‡πá', '‡∏à‡∏£‡∏¥‡∏á', ' ', '‡πÅ‡∏ï‡πà', '‡∏Å‡πá', '‡∏≠‡∏¢‡πà‡∏≤', '‡∏•‡∏∑‡∏°', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å', '‡∏™‡∏¥‡πà‡∏á', '‡∏ó‡∏µ‡πà', '‡∏î‡∏µ', '‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î', '‡πÉ‡∏´‡πâ', '‡∏ï‡∏±‡∏ß', '‡πÄ‡∏£‡∏≤', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', '‡∏Ñ‡πà‡∏∞']]]}\n","{'category': 'neu', 'text': \"‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏π‡∏ï‡∏£‡∏Ç‡∏≠‡∏á‡∏ú‡∏° ‡∏Ñ‡∏∑‡∏≠ Jack Daniel's ‡∏´‡∏ß‡∏≤‡∏ô‡∏ã‡πà‡∏≠‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß‡∏ä‡∏∑‡πà‡∏≠ Jack Yellow Life ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö Jack Daniel's 2 ‡∏ä‡∏≠‡∏ó ‡∏ô‡πâ‡∏≥‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢ ‡∏ô‡πâ‡∏≥‡∏°‡∏∞‡∏ô‡∏≤‡∏ß ‡πÉ‡∏ö‡∏°‡∏¥‡πâ‡∏ô‡∏ó‡πå ‡πÄ‡∏Å‡∏•‡∏∑‡∏≠‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∏‡∏á ‡∏ô‡∏≥ JackDaniel's ‡∏°‡∏≤‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢ ‡πÄ‡∏à‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡πâ‡∏≥‡∏°‡∏∞‡∏ô‡∏≤‡∏ß‡∏ö‡∏≤‡∏á‡πÜ ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÉ‡∏ö‡∏°‡∏¥‡πâ‡∏ô ‡πÄ‡∏™‡∏£‡∏¥‡∏ü‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡πÄ‡∏Å‡∏•‡∏∑‡∏≠‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏õ‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏ß ‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏ß‡∏≤‡∏ô ‡∏´‡∏≠‡∏° ‡∏ã‡πà‡∏≠‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡πá‡∏õ‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï ‡∏à‡∏∞‡∏´‡∏ß‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ ‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏Å‡πá‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏à‡∏∂‡∏á‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ß‡∏≤‡∏ô‡∏Ñ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏£‡∏±‡∏ö\", 'misp_tokens': [], 'tokenized': ['‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö', '‡∏™‡∏π‡∏ï‡∏£', '‡∏Ç‡∏≠‡∏á', '‡∏ú‡∏°', ' ', '‡∏Ñ‡∏∑‡∏≠', ' ', 'Jack Daniel', \"'\", 's', ' ', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡∏ä‡∏∑‡πà‡∏≠', ' ', 'Jack Yellow', ' ', 'Life', ' ', '‡∏™‡πà‡∏ß‡∏ô', '‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', '‡∏ä‡∏≠‡∏ó', ' ', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', ' ', '‡πÉ‡∏ö', '‡∏°‡∏¥‡πâ‡∏ô‡∏ó‡πå', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢', ' ', '‡∏ß‡∏¥‡∏ò‡∏µ', '‡∏õ‡∏£‡∏∏‡∏á', ' ', '‡∏ô‡∏≥', ' ', 'JackDaniel', \"'\", 's', ' ', '‡∏°‡∏≤', '‡πÄ‡∏Ç‡∏¢‡πà‡∏≤', '‡∏Å‡∏±‡∏ö', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡πÄ‡∏à‡∏∑‡∏≠', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', '‡∏ö‡∏≤‡∏á', '‡πÜ', ' ', '‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÉ‡∏ö‡∏°‡∏¥‡πâ‡∏ô', ' ', '‡πÄ‡∏™‡∏£‡∏¥‡∏ü', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÅ‡∏Å‡πâ‡∏ß', '‡∏ó‡∏µ‡πà', '‡∏ó‡∏≤‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÑ‡∏ß‡πâ', '‡∏ó‡∏µ‡πà', '‡∏õ‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏ß', ' ', '‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥', '‡∏ó‡∏µ‡πà', '‡∏à‡∏∞', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡∏∑‡∏≠', '‡∏´‡∏ß‡∏≤‡∏ô', ' ', '‡∏´‡∏≠‡∏°', ' ', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡πá‡∏õ', '‡∏ß‡πà‡∏≤', '‡∏ô‡∏µ‡πà', '‡πÅ‡∏´‡∏•‡∏∞', '‡∏Ñ‡∏∑‡∏≠', '‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï', ' ', '‡∏à‡∏∞', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß', '‡∏Å‡πá', '‡∏à‡∏∞', '‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏ô', '‡πÑ‡∏õ', ' ', '‡∏à‡∏∞', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡πÄ‡∏Å‡∏¥‡∏ô', '‡πÑ‡∏õ', '‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', ' ', '‡∏à‡∏∂‡∏á', '‡∏Ñ‡∏ß‡∏£', '‡∏à‡∏∞', '‡∏°‡∏µ', '‡∏ó‡∏±‡πâ‡∏á', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ß‡∏≤‡∏ô', '‡∏Ñ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡πâ‡∏≤', '‡∏Å‡∏±‡∏ô', '‡πÑ‡∏õ', '‡∏Ñ‡∏£‡∏±‡∏ö'], 'segments': [[['‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö', '‡∏™‡∏π‡∏ï‡∏£', '‡∏Ç‡∏≠‡∏á', '‡∏ú‡∏°', ' ', '‡∏Ñ‡∏∑‡∏≠', ' ', 'Jack Daniel', \"'\", 's', ' ', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡∏ä‡∏∑‡πà‡∏≠', ' ', 'Jack Yellow', ' ', 'Life', ' ', '‡∏™‡πà‡∏ß‡∏ô', '‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', '‡∏ä‡∏≠‡∏ó', ' ', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', ' ', '‡πÉ‡∏ö', '‡∏°‡∏¥‡πâ‡∏ô‡∏ó‡πå', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢', ' ', '‡∏ß‡∏¥‡∏ò‡∏µ', '‡∏õ‡∏£‡∏∏‡∏á', ' ', '‡∏ô‡∏≥', ' ', 'JackDaniel', \"'\", 's', ' ', '‡∏°‡∏≤', '‡πÄ‡∏Ç‡∏¢‡πà‡∏≤', '‡∏Å‡∏±‡∏ö', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡πÄ‡∏à‡∏∑‡∏≠', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', '‡∏ö‡∏≤‡∏á', '‡πÜ', ' ', '‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÉ‡∏ö‡∏°‡∏¥‡πâ‡∏ô', ' ', '‡πÄ‡∏™‡∏£‡∏¥‡∏ü', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÅ‡∏Å‡πâ‡∏ß', '‡∏ó‡∏µ‡πà', '‡∏ó‡∏≤‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÑ‡∏ß‡πâ', '‡∏ó‡∏µ‡πà', '‡∏õ‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏ß', ' ', '‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥', '‡∏ó‡∏µ‡πà', '‡∏à‡∏∞', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡∏∑‡∏≠', '‡∏´‡∏ß‡∏≤‡∏ô', ' ', '‡∏´‡∏≠‡∏°', ' ', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡πá‡∏õ', '‡∏ß‡πà‡∏≤', '‡∏ô‡∏µ‡πà', '‡πÅ‡∏´‡∏•‡∏∞', '‡∏Ñ‡∏∑‡∏≠', '‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï', ' ', '‡∏à‡∏∞', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß', '‡∏Å‡πá', '‡∏à‡∏∞', '‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏ô', '‡πÑ‡∏õ', ' ', '‡∏à‡∏∞', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡πÄ‡∏Å‡∏¥‡∏ô', '‡πÑ‡∏õ', '‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', ' ', '‡∏à‡∏∂‡∏á', '‡∏Ñ‡∏ß‡∏£', '‡∏à‡∏∞', '‡∏°‡∏µ', '‡∏ó‡∏±‡πâ‡∏á', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ß‡∏≤‡∏ô', '‡∏Ñ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡πâ‡∏≤', '‡∏Å‡∏±‡∏ô', '‡πÑ‡∏õ', '‡∏Ñ‡∏£‡∏±‡∏ö'], ['‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö', '‡∏™‡∏π‡∏ï‡∏£', '‡∏Ç‡∏≠‡∏á', '‡∏ú‡∏°', ' ', '‡∏Ñ‡∏∑‡∏≠', ' ', 'Jack Daniel', \"'\", 's', ' ', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡∏ä‡∏∑‡πà‡∏≠', ' ', 'Jack Yellow', ' ', 'Life', ' ', '‡∏™‡πà‡∏ß‡∏ô', '‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', '‡∏ä‡∏≠‡∏ó', ' ', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', ' ', '‡πÉ‡∏ö', '‡∏°‡∏¥‡πâ‡∏ô‡∏ó‡πå', ' ', '‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢', ' ', '‡∏ß‡∏¥‡∏ò‡∏µ', '‡∏õ‡∏£‡∏∏‡∏á', ' ', '‡∏ô‡∏≥', ' ', 'JackDaniel', \"'\", 's', ' ', '‡∏°‡∏≤', '‡πÄ‡∏Ç‡∏¢‡πà‡∏≤', '‡∏Å‡∏±‡∏ö', '‡∏ô‡πâ‡∏≥', '‡πÄ‡∏Å‡πä‡∏Å‡∏Æ‡∏ß‡∏¢', ' ', '‡πÄ‡∏à‡∏∑‡∏≠', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏ô‡πâ‡∏≥', '‡∏°‡∏∞‡∏ô‡∏≤‡∏ß', '‡∏ö‡∏≤‡∏á', '‡πÜ', ' ', '‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÉ‡∏ö‡∏°‡∏¥‡πâ‡∏ô', ' ', '‡πÄ‡∏™‡∏£‡∏¥‡∏ü', '‡∏î‡πâ‡∏ß‡∏¢', '‡πÅ‡∏Å‡πâ‡∏ß', '‡∏ó‡∏µ‡πà', '‡∏ó‡∏≤‡πÄ‡∏Å‡∏•‡∏∑‡∏≠', '‡πÑ‡∏ß‡πâ', '‡∏ó‡∏µ‡πà', '‡∏õ‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏ß', ' ', '‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥', '‡∏ó‡∏µ‡πà', '‡∏à‡∏∞', '‡πÑ‡∏î‡πâ', '‡∏Ñ‡∏∑‡∏≠', '‡∏´‡∏ß‡∏≤‡∏ô', ' ', '‡∏´‡∏≠‡∏°', ' ', '‡∏ã‡πà‡∏≠‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏î‡πâ‡∏ß‡∏¢', '‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡πá‡∏õ', '‡∏ß‡πà‡∏≤', '‡∏ô‡∏µ‡πà', '‡πÅ‡∏´‡∏•‡∏∞', '‡∏Ñ‡∏∑‡∏≠', '‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï', ' ', '‡∏à‡∏∞', '‡∏´‡∏ß‡∏≤‡∏ô', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß', '‡∏Å‡πá', '‡∏à‡∏∞', '‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏ô', '‡πÑ‡∏õ', ' ', '‡∏à‡∏∞', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', '‡πÄ‡∏Å‡∏¥‡∏ô', '‡πÑ‡∏õ', '‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡πÉ‡∏ä‡πà', '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', ' ', '‡∏à‡∏∂‡∏á', '‡∏Ñ‡∏ß‡∏£', '‡∏à‡∏∞', '‡∏°‡∏µ', '‡∏ó‡∏±‡πâ‡∏á', '‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß', ' ', '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ß‡∏≤‡∏ô', '‡∏Ñ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡πâ‡∏≤', '‡∏Å‡∏±‡∏ô', '‡πÑ‡∏õ', '‡∏Ñ‡∏£‡∏±‡∏ö']]]}\n","{'category': 'neg', 'text': '‡πÄ‡∏à‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πå‡∏ô‡∏¥‡πÄ‡∏¢‡πà‡πÅ‡∏≠‡∏ö‡πÅ‡∏£‡∏á‡∏ô‡∏¥‡∏™‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏¢‡πÄ‡∏Å‡∏¥‡∏£‡πå‡∏ï‡πÑ‡∏°‡πä ‡∏û‡∏£‡∏∏‡πâ‡∏á‡∏ô‡∏µ‡πâ‡∏•‡∏≠‡∏á‡∏û‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏î‡∏π‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏ö‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ‡∏ô‡∏∏‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ‡∏´‡∏≤‡∏¢‡πÑ‡∏ß‡πÑ‡∏ß‡∏ô‡πä‡∏≤‡∏≤‡∏≤‡∏≤', 'misp_tokens': [{'corr': '‡∏ô‡∏∞', 'misp': '‡∏ô‡πä‡∏≤‡∏≤‡∏≤‡∏≤', 'int': True, 's': 102, 't': 108}, {'corr': '‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢', 'misp': '‡∏ô‡∏¥‡∏™‡∏´‡∏ô‡πà‡∏≠‡∏¢', 'int': True, 's': 21, 't': 29}, {'corr': '‡πÑ‡∏´‡∏°', 'misp': '‡πÑ‡∏°‡πä', 'int': True, 's': 44, 't': 47}], 'tokenized': ['‡πÄ‡∏à‡πâ‡∏ß‡πà‡∏≤', '‡∏Å‡∏≤‡∏£‡πå‡∏ô‡∏¥‡πÄ‡∏¢‡πà', '‡πÅ‡∏≠‡∏ö', '‡πÅ‡∏£‡∏á', '‡∏ô‡∏¥‡∏™‡∏´‡∏ô‡πà‡∏≠‡∏¢', ' ', '‡πÄ‡∏Ñ‡∏¢', '‡πÉ‡∏ä‡πâ', '‡πÇ‡∏¢‡πÄ‡∏Å‡∏¥‡∏£‡πå‡∏ï', '‡πÑ‡∏°‡πä', ' ', '‡∏û‡∏£‡∏∏‡πâ‡∏á', '‡∏ô‡∏µ‡πâ', '‡∏•‡∏≠‡∏á', '‡∏û‡∏≠‡∏Å', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏î‡∏π', '‡∏ó‡∏≥', '‡πÉ‡∏´‡πâ', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏™‡∏ö‡∏≤‡∏¢', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏ô‡∏∏‡πà‡∏°', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏´‡∏≤‡∏¢', '‡πÑ‡∏ß', '‡πÑ‡∏ß‡∏ô‡πä‡∏≤‡∏≤‡∏≤‡∏≤'], 'segments': [[['‡πÄ‡∏à‡πâ‡∏ß‡πà‡∏≤', '‡∏Å‡∏≤‡∏£‡πå‡∏ô‡∏¥‡πÄ‡∏¢‡πà', '‡πÅ‡∏≠‡∏ö', '‡πÅ‡∏£‡∏á'], ['‡πÄ‡∏à‡πâ‡∏ß‡πà‡∏≤', '‡∏Å‡∏≤‡∏£‡πå‡∏ô‡∏¥‡πÄ‡∏¢‡πà', '‡πÅ‡∏≠‡∏ö', '‡πÅ‡∏£‡∏á']], [['‡∏ô‡∏¥‡∏™‡∏´‡∏ô‡πà‡∏≠‡∏¢'], ['‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢']], [['‡πÄ‡∏Ñ‡∏¢', '‡πÉ‡∏ä‡πâ', '‡πÇ‡∏¢‡πÄ‡∏Å‡∏¥‡∏£‡πå‡∏ï'], ['‡πÄ‡∏Ñ‡∏¢', '‡πÉ‡∏ä‡πâ', '‡πÇ‡∏¢‡πÄ‡∏Å‡∏¥‡∏£‡πå‡∏ï']], [['‡πÑ‡∏°‡πä'], ['‡πÑ‡∏´‡∏°']], [['‡∏û‡∏£‡∏∏‡πâ‡∏á', '‡∏ô‡∏µ‡πâ', '‡∏•‡∏≠‡∏á', '‡∏û‡∏≠‡∏Å', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏î‡∏π', '‡∏ó‡∏≥', '‡πÉ‡∏´‡πâ', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏™‡∏ö‡∏≤‡∏¢', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏ô‡∏∏‡πà‡∏°', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏´‡∏≤‡∏¢', '‡πÑ‡∏ß‡πÑ‡∏ß'], ['‡∏û‡∏£‡∏∏‡πâ‡∏á', '‡∏ô‡∏µ‡πâ', '‡∏•‡∏≠‡∏á', '‡∏û‡∏≠‡∏Å', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏î‡∏π', '‡∏ó‡∏≥', '‡πÉ‡∏´‡πâ', '‡∏´‡∏ô‡πâ‡∏≤', '‡∏™‡∏ö‡∏≤‡∏¢', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏ô‡∏∏‡πà‡∏°', '‡∏Ç‡∏∂‡πâ‡∏ô', ' ', '‡∏´‡∏≤‡∏¢', '‡πÑ‡∏ß‡πÑ‡∏ß']], [['‡∏ô‡πä‡∏≤‡∏≤‡∏≤‡∏≤'], ['‡∏ô‡∏∞']], [[], []]]}\n","{'category': 'neu', 'text': '‡πÄ‡∏≠‡πÖ‡∏à‡∏£‡∏¥‡∏á‡πÜ‡∏ñ‡πâ‡πÖ‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏ñ‡∏π‡∏Å‡∏Å‡∏é‡∏´‡∏°‡πÖ‡∏¢‡∏à‡∏£‡∏¥‡∏ß‡∏Ñ‡∏á‡∏Å‡∏•‡∏±‡∏ß‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏†‡πÖ‡∏©‡∏µ‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏£‡∏∂‡∏õ‡πà‡πÖ‡∏ß', 'misp_tokens': [{'corr': '‡πÄ‡∏≠‡∏≤', 'misp': '‡πÄ‡∏≠‡πÖ', 'int': False, 's': 0, 't': 3}, {'corr': '‡∏ñ‡πâ‡∏≤', 'misp': '‡∏ñ‡πâ‡πÖ', 'int': False, 's': 8, 't': 11}, {'corr': '‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢', 'misp': '‡∏Å‡∏é‡∏´‡∏°‡πÖ‡∏¢', 'int': False, 's': 30, 't': 36}, {'corr': '‡∏à‡∏£‡∏¥‡∏á', 'misp': '‡∏à‡∏£‡∏¥‡∏ß', 'int': False, 's': 36, 't': 40}, {'corr': '‡∏§‡πÖ‡∏©‡∏µ', 'misp': '‡∏†‡πÖ‡∏©‡∏µ', 'int': False, 's': 52, 't': 56}, {'corr': '‡πÄ‡∏õ‡∏•‡πà‡∏≤', 'misp': '‡∏õ‡πà‡πÖ‡∏ß', 'int': False, 's': 63, 't': 67}], 'tokenized': ['‡πÄ‡∏≠‡πÖ‡∏à‡∏£‡∏¥‡∏á', '‡πÜ', '‡∏ñ‡πâ‡πÖ', '‡∏°‡∏±‡∏ô', '‡πÄ‡∏õ‡∏¥‡∏î', '‡πÉ‡∏´‡πâ', '‡πÉ‡∏ä‡πâ', '‡πÅ‡∏•‡∏∞', '‡∏ñ‡∏π‡∏Å', '‡∏Å‡∏é‡∏´‡∏°‡πÖ‡∏¢', '‡∏à‡∏£‡∏¥‡∏ß', '‡∏Ñ‡∏á', '‡∏Å‡∏•‡∏±‡∏ß', '‡∏à‡∏∞', '‡πÄ‡∏Å‡πá‡∏ö', '‡∏†‡πÖ‡∏©‡∏µ', '‡∏¢‡∏±‡∏á', '‡πÑ‡∏á', '‡∏£‡∏∂‡∏õ‡πà‡πÖ‡∏ß'], 'segments': [[[], []], [['‡πÄ‡∏≠‡πÖ'], ['‡πÄ‡∏≠‡∏≤']], [['‡∏à‡∏£‡∏¥‡∏á', '‡πÜ'], ['‡∏à‡∏£‡∏¥‡∏á', '‡πÜ']], [['‡∏ñ‡πâ‡πÖ'], ['‡∏ñ‡πâ‡∏≤']], [['‡∏°‡∏±‡∏ô', '‡πÄ‡∏õ‡∏¥‡∏î', '‡πÉ‡∏´‡πâ', '‡πÉ‡∏ä‡πâ', '‡πÅ‡∏•‡∏∞', '‡∏ñ‡∏π‡∏Å'], ['‡∏°‡∏±‡∏ô', '‡πÄ‡∏õ‡∏¥‡∏î', '‡πÉ‡∏´‡πâ', '‡πÉ‡∏ä‡πâ', '‡πÅ‡∏•‡∏∞', '‡∏ñ‡∏π‡∏Å']], [['‡∏Å‡∏é‡∏´‡∏°‡πÖ‡∏¢'], ['‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢']], [[], []], [['‡∏à‡∏£‡∏¥‡∏ß'], ['‡∏à‡∏£‡∏¥‡∏á']], [['‡∏Ñ‡∏á', '‡∏Å‡∏•‡∏±‡∏ß', '‡∏à‡∏∞', '‡πÄ‡∏Å‡πá‡∏ö'], ['‡∏Ñ‡∏á', '‡∏Å‡∏•‡∏±‡∏ß', '‡∏à‡∏∞', '‡πÄ‡∏Å‡πá‡∏ö']], [['‡∏†‡πÖ‡∏©‡∏µ'], ['‡∏§‡πÖ‡∏©‡∏µ']], [['‡∏¢‡∏±‡∏á', '‡πÑ‡∏á', '‡∏£‡∏∂'], ['‡∏¢‡∏±‡∏á', '‡πÑ‡∏á', '‡∏£‡∏∂']], [['‡∏õ‡πà‡πÖ‡∏ß'], ['‡πÄ‡∏õ‡∏•‡πà‡∏≤']], [[], []]]}\n","{'category': 'neg', 'text': '‡∏≠‡∏¥‡∏ú‡πâ‡∏≤‡∏≠‡∏ô‡∏≤‡∏°‡∏±‡∏¢‡πÄ‡∏´‡∏¥‡πâ‡∏¢ ‡∏ï‡∏¥‡∏î‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á‡πÉ‡∏ô', 'misp_tokens': [{'corr': '‡∏≠‡∏µ', 'misp': '‡∏≠‡∏¥', 'int': True, 's': 0, 't': 2}, {'corr': '‡πÄ‡∏´‡∏µ‡πâ‡∏¢', 'misp': '‡πÄ‡∏´‡∏¥‡πâ‡∏¢', 'int': False, 's': 11, 't': 16}], 'tokenized': ['‡∏≠‡∏¥‡∏ú‡πâ‡∏≤', '‡∏≠‡∏ô‡∏≤‡∏°‡∏±‡∏¢', '‡πÄ‡∏´‡∏¥‡πâ‡∏¢', ' ', '‡∏ï‡∏¥‡∏î', '‡∏ó‡∏∏‡∏Å', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', '‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô', '‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á', '‡πÉ‡∏ô'], 'segments': [[[], []], [['‡∏≠‡∏¥'], ['‡∏≠‡∏µ']], [['‡∏ú‡πâ‡∏≤', '‡∏≠‡∏ô‡∏≤‡∏°‡∏±‡∏¢'], ['‡∏ú‡πâ‡∏≤', '‡∏≠‡∏ô‡∏≤‡∏°‡∏±‡∏¢']], [['‡πÄ‡∏´‡∏¥‡πâ‡∏¢'], ['‡πÄ‡∏´‡∏µ‡πâ‡∏¢']], [['‡∏ï‡∏¥‡∏î', '‡∏ó‡∏∏‡∏Å', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', '‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô', '‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á', '‡πÉ‡∏ô'], ['‡∏ï‡∏¥‡∏î', '‡∏ó‡∏∏‡∏Å', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', ' ', '‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô', '‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á', '‡πÉ‡∏ô']]]}\n"]}]},{"cell_type":"code","metadata":{"id":"NRWpDhQaitQc","executionInfo":{"status":"ok","timestamp":1638885873787,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"yceBl7D2jGyv","executionInfo":{"status":"ok","timestamp":1638885873787,"user_tz":0,"elapsed":9,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLTGbmXyf0gp","executionInfo":{"status":"ok","timestamp":1638885873788,"user_tz":0,"elapsed":9,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import glob\n","from torch.utils.data import Dataset as TorchDataset\n","from datasets import Dataset\n","# from thai2transformers.datasets import SequenceClassificationDataset\n","\n","class SequenceClassificationDataset(TorchDataset):\n","    def __init__(\n","        self,\n","        tokenizer,\n","        data_dir,\n","        task=Task.MULTICLASS_CLS,\n","        max_length=128,\n","        ext=\".csv\",\n","        bs=10000,\n","        preprocessor=None,\n","        input_ids=[],\n","        misp_ids=[],\n","        attention_masks=[],\n","        labels=[],\n","        label_encoder=None\n","    ):\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        self.bs = bs\n","        self.preprocessor = preprocessor\n","        self.input_ids = input_ids\n","        self.misp_ids = misp_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","        self.task = task\n","        self.label_encoder = label_encoder\n","        # self._build()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, i):\n","        return {\n","            \"input_ids\": torch.tensor(self.input_ids[i], dtype=torch.long),\n","            \"misp_ids\": torch.tensor(self.misp_ids[i], dtype=torch.long),\n","            \"attention_mask\": torch.tensor(self.attention_masks[i], dtype=torch.long),\n","            \"label\": torch.tensor(self.labels[i], dtype=torch.long),\n","        }\n"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Zxb64qIt674","executionInfo":{"status":"ok","timestamp":1638885873788,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxC53Pw1zQ-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638885893792,"user_tz":0,"elapsed":20012,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"af0bbeeb-da4d-4bbe-b446-a7778b6f155b"},"source":["from tqdm import tqdm \n","import itertools\n","\n","LABELS = {\n","    \"neg\": 2,\n","    \"neu\": 1,\n","    \"pos\": 0,\n","    \"q\": 1 # used to be 3\n","}\n","\n","class CustomLabelEncoder():\n","    def __init__(self):\n","        pass\n","\n","    def transform(self, labels):\n","        return [LABELS[l] for l in labels]\n","    \n","\n","def remove_starting_marker(t, unk):\n","    if len(t) > 0:\n","      if t[0]=='‚ñÅ':\n","        t = t[1:]\n","      elif t[0].startswith('‚ñÅ'):        \n","        if tokenizer.convert_tokens_to_ids([t[0][1:]])[0] != unk:\n","          t[0] = t[0][1:]\n","    return t\n","\n","def preprocessing(d, preSegmented=False, mode=None):\n","    max_length = 400\n","    custom_label_encoder = CustomLabelEncoder()\n","    labels = get_dict_val(d, \"category\")\n","\n","    labels = custom_label_encoder.transform(labels)\n","\n","    input_ids = []\n","    misp_ids = []\n","    attention_masks = []\n","    unk = tokenizer.convert_tokens_to_ids([\"<unk>\"])[0]\n","\n","    sents = []\n","    if not preSegmented:\n","      texts = get_dict_val(d, \"tokenized\")\n","      for tokens in tqdm(texts):\n","        tokens = [(t, t) for t in tokens]\n","        sents.append(tokens)\n","        \n","    else:\n","      texts = get_dict_val(d, \"segments\")\n","      for segments in tqdm(texts):\n","        s = [list(zip(seg[0], seg[1])) for seg in segments]\n","        tokens = list(itertools.chain(*s))\n","        sents.append(tokens)\n","\n","    for tokens in sents:\n","      # if mode is None, ignore corr\n","      misptokens = [t[0] for t in tokens]\n","      corrtokens = [t[0] for t in tokens]\n","      \n","      if mode==\"corr\":\n","        misptokens = [t[1] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      elif mode==\"mae\":\n","        misptokens = [t[0] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      \n","      \n","      midx = tokenizer.convert_tokens_to_ids(misptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(corrtokens)\n","      assert(len(midx)==len(cidx))\n","\n","      newmisptokens = []\n","      newcorrtokens = []\n","      for i in range(len(midx)):\n","          if midx[i]==unk:\n","              t = tokenizer.tokenize(misptokens[i])\n","              t = remove_starting_marker(t, unk)\n","\n","              if misptokens[i]==corrtokens[i]:\n","                newmisptokens += t\n","                newcorrtokens += t\n","              else:\n","                newmisptokens += t\n","                tx = tokenizer.tokenize(corrtokens[i])\n","                tx = remove_starting_marker(tx, unk)\n","\n","                if len(tx) > 0:\n","                  newcorrtokens += [tx[0] for j in range(len(t))]\n","                else:\n","                  newcorrtokens += t\n","          else:\n","              newmisptokens.append(misptokens[i])\n","              newcorrtokens.append(corrtokens[i])\n","\n","      assert(len(newmisptokens)==len(newcorrtokens))\n","              \n","      # words = newwords\n","      newmisptokens = ['<s>'] + newmisptokens[0:max_length-2] + ['</s>']\n","      newcorrtokens = ['<s>'] + newcorrtokens[0:max_length-2] + ['</s>']\n","    \n","      midx = tokenizer.convert_tokens_to_ids(newmisptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(newcorrtokens)\n","\n","      mask = [1 for i in midx]\n","        \n","      input_ids.append(midx)\n","      misp_ids.append(cidx)\n","      attention_masks.append(mask)\n","\n","    #   if len(input_ids) > 10:\n","    #     break\n","    \n","    # labels = labels[0:10]\n","\n","    return SequenceClassificationDataset(\n","        tokenizer=tokenizer,\n","        data_dir=None,\n","        max_length=max_length,\n","        input_ids=input_ids,\n","        misp_ids=misp_ids,\n","        attention_masks=attention_masks,\n","        labels=labels,\n","        task=task\n","    )\n","\n","raw_datasets = {\n","    \"train\": traindata,\n","    \"validation\": validdata,\n","    \"test\": allTestdata,\n","    \"test-corr\": corrTestdata,\n","    \"test-misp\": mispTestdata,\n","    \"test-mae\": mispTestdata,\n","    \"test-all-mae\": allTestdata,\n","}\n","\n","dataset_split = {}\n","for split_name in raw_datasets:\n","    print(\"Tokenizing:\", split_name)\n","    d = pd.DataFrame(raw_datasets[split_name])\n","    d = Dataset.from_pandas(d)\n","    preSegmented = split_name.startswith(\"test\")\n","    mode = None\n","    if \"corr\" in split_name:\n","      mode = \"corr\"\n","    elif \"misp\" in split_name:\n","      mode = \"misp\"\n","    elif \"mae\" in split_name:\n","      mode = \"mae\"\n","\n","    dataset_split[split_name] = preprocessing(d, preSegmented=preSegmented, mode=mode)\n","    # break"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing: train\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21628/21628 [00:00<00:00, 140195.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2404/2404 [00:00<00:00, 119246.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: test\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2671/2671 [00:00<00:00, 108279.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: test-corr\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880/880 [00:00<00:00, 60197.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: test-misp\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880/880 [00:00<00:00, 111385.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: test-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880/880 [00:00<00:00, 72355.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing: test-all-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2671/2671 [00:00<00:00, 106898.72it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"zTo1InxM7QlH","executionInfo":{"status":"ok","timestamp":1638885893793,"user_tz":0,"elapsed":43,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pVpOylu-CrqE"},"source":["## Custom Classes for Our Experiments"]},{"cell_type":"code","metadata":{"id":"wHqjltTIEdzZ","executionInfo":{"status":"ok","timestamp":1638885893793,"user_tz":0,"elapsed":41,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_roberta import RobertaEmbeddings"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q5iZsOgEd2P","executionInfo":{"status":"ok","timestamp":1638885893794,"user_tz":0,"elapsed":41,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from torch import nn\n","\n","class CustomRobertaEmbeddings(RobertaEmbeddings):\n","\n","    def __init__(self, ref, config):\n","        super().__init__(config)\n","        self.word_embeddings = ref.word_embeddings\n","\n","    def forward(self, input_ids, misp_ids, token_type_ids=None, position_ids=None, inputs_embeds=None):\n","\n","        input_shape = input_ids.size()\n","        seq_length = input_shape[1]\n","\n","        inputs_embeds = self.word_embeddings(input_ids)\n","        misp_embeds = self.word_embeddings(misp_ids)\n","\n","        embeddings = ((inputs_embeds + misp_embeds)*0.5)\n","        return embeddings\n"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"WL_oBhOdHTjt","executionInfo":{"status":"ok","timestamp":1638885893794,"user_tz":0,"elapsed":40,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_roberta import RobertaModel"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew6s3Y1f1vCa","executionInfo":{"status":"ok","timestamp":1638885893795,"user_tz":0,"elapsed":40,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_camembert import CamembertForSequenceClassification\n","from transformers.modeling_roberta import RobertaForSequenceClassification\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","\n","class CustomSequenceClassification(CamembertForSequenceClassification):\n","    authorized_missing_keys = [r\"position_ids\"]\n","\n","    def __init__(self, config, refmodel=None):\n","        super().__init__(config)\n","        if refmodel is not None:\n","          config = refmodel.config\n","          # self.refmodel = refmodel\n","          self.num_labels = config.num_labels\n","\n","          self.roberta = refmodel.roberta\n","          self.classifier = refmodel.classifier\n","\n","          self.baseEmb = refmodel.roberta.embeddings\n","          self.newEmb = CustomRobertaEmbeddings(self.baseEmb, config)\n","\n","    def forward(self, *args, **kwargs):\n","        # del kwargs[\"misp_ids\"]\n","        # return self.refmodel(**kwargs)\n","\n","        return_dict = self.config.use_return_dict\n","\n","        inputs_embeds = self.newEmb(kwargs[\"input_ids\"], kwargs[\"misp_ids\"])\n","        \n","        # doc: https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaModel.forward\n","        outputs = self.roberta(\n","            input_ids=None,\n","            attention_mask=kwargs[\"attention_mask\"],\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        labels = kwargs[\"labels\"]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"lznRUPu1YJSA","executionInfo":{"status":"ok","timestamp":1638885893795,"user_tz":0,"elapsed":37,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# cusmodel = CustomSequenceClassification(model.config, model)\n","# trainer, training_args = init_trainer(task=task,\n","#                             model=cusmodel,\n","#                             train_dataset=dataset_split['train'],\n","#                             val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","#                             warmup_steps=warmup_steps,\n","#                             args=args,\n","#                             data_collator=data_collator)\n","\n","# p, label_ids, result = trainer.predict(test_dataset=dataset_split['test'])\n","\n","# print(f'Evaluation on test set (dataset: {args.dataset_name})')    \n","\n","# for key, value in result.items():\n","#     print(f'{key} : {value:.4f}')\n","\n","# # Evaluation on test set (dataset: wisesight_sentiment)\n","# # eval_loss : 1.0284\n","# # eval_accuracy : 0.3000\n","# # eval_f1_micro : 0.3000\n","# # eval_precision_micro : 0.3000\n","# # eval_recall_micro : 0.3000\n","# # eval_f1_macro : 0.1667\n","# # eval_precision_macro : 0.1667\n","# # eval_recall_macro : 0.1667\n","# # eval_nb_samples : 10.0000"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDP2AEpDCqXh","executionInfo":{"status":"ok","timestamp":1638885893795,"user_tz":0,"elapsed":36,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from dataclasses import dataclass\n","from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n","from transformers import PreTrainedTokenizerBase\n","\n","@dataclass\n","class CustomDataCollatorWithPadding:\n","  tokenizer: PreTrainedTokenizerBase\n","  padding: Union[bool, str] = True\n","  max_length: Optional[int] = None\n","  pad_to_multiple_of: Optional[int] = None\n","  return_tensors: str = \"pt\"\n","\n","  def __call__(self, features):\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"input_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","\n","    batch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"misp_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","      \n","    mispbatch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    # print(mispbatch[\"input_ids\"])\n","    # print(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][0]))\n","    # print(tokenizer.convert_ids_to_tokens(mispbatch[\"input_ids\"][0]))\n","    batch[\"misp_ids\"] = mispbatch[\"input_ids\"]\n","    assert(batch[\"misp_ids\"].shape==batch[\"input_ids\"].shape)\n","    # assert()\n","    if \"label\" in batch:\n","        batch[\"labels\"] = batch[\"label\"]\n","        del batch[\"label\"]\n","    if \"label_ids\" in batch:\n","        batch[\"labels\"] = batch[\"label_ids\"]\n","        del batch[\"label_ids\"]\n","    return batch"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_D7scYkC0Jg"},"source":["# Model Training "]},{"cell_type":"code","metadata":{"id":"Dx6AsnFmeQlM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638885899380,"user_tz":0,"elapsed":5620,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"729ec92f-4ddb-4e62-ea06-0e8dce9050da"},"source":["warmup_steps = math.ceil(len(dataset_split['train']) / args.batch_size * args.warmup_ratio * args.num_train_epochs)\n","\n","print(f'\\n[INFO] Number of train examples = {len(raw_datasets[\"train\"])}')\n","print(f'[INFO] Number of batches per epoch (training set) = {math.ceil(len(dataset_split[\"train\"]) / args.batch_size)}')\n","\n","print(f'[INFO] Warmup ratio = {args.warmup_ratio}')\n","print(f'[INFO] Warmup steps = {warmup_steps}')\n","print(f'[INFO] Learning rate: {args.learning_rate}')\n","print(f'[INFO] Logging steps: {args.logging_steps}')\n","print(f'[INFO] FP16 training: {args.fp16}\\n')\n","\n","# if 'validation' in DATASET_METADATA[args.dataset_name]['split_names']:\n","print(f'[INFO] Number of validation examples = {len(raw_datasets[\"validation\"])}')\n","print(f'[INFO] Number of batches per epoch (validation set) = {math.ceil(len(dataset_split[\"validation\"]))}')\n","\n","data_collator = CustomDataCollatorWithPadding(tokenizer,\n","                                        padding=True,\n","                                        pad_to_multiple_of=8 if args.fp16 else None)\n","\n","cusmodel = CustomSequenceClassification(model.config, model)\n","trainer, training_args = init_trainer(task=task,\n","                            model=cusmodel,\n","                            train_dataset=dataset_split['train'],\n","                            val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","                            warmup_steps=warmup_steps,\n","                            args=args,\n","                            data_collator=data_collator)\n","\n","print('[INFO] TrainingArguments:')\n","print(training_args)\n","print('\\n')"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Number of train examples = 21628\n","[INFO] Number of batches per epoch (training set) = 2704\n","[INFO] Warmup ratio = 0.1\n","[INFO] Warmup steps = 2704\n","[INFO] Learning rate: 1e-05\n","[INFO] Logging steps: 10\n","[INFO] FP16 training: False\n","\n","[INFO] Number of validation examples = 2404\n","[INFO] Number of batches per epoch (validation set) = 2404\n","[INFO] TrainingArguments:\n","TrainingArguments(output_dir='Models/WangchanBERTa-exp1/Outputs/', overwrite_output_dir=True, do_train=False, do_eval=None, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, warmup_steps=2704, logging_dir='Models/WangchanBERTa-exp1/Logs/', logging_first_step=False, logging_steps=10, save_steps=500, save_total_limit=None, no_cuda=False, seed=0, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name='exp1', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='f1_micro', greater_is_better=True)\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"O8TTQ7VmQGhS","executionInfo":{"status":"ok","timestamp":1638896928361,"user_tz":0,"elapsed":11028994,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"414b6da2-9b86-4247-b29a-b21ad1bbeb13"},"source":["print('\\nBegin model finetuning.')\n","trainer.train()\n","print('Done.\\n')"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Begin model finetuning.\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='27040' max='27040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27040/27040 3:03:48, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Micro</th>\n","      <th>Precision Micro</th>\n","      <th>Recall Micro</th>\n","      <th>F1 Macro</th>\n","      <th>Precision Macro</th>\n","      <th>Recall Macro</th>\n","      <th>Nb Samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.757764</td>\n","      <td>0.719646</td>\n","      <td>0.688852</td>\n","      <td>0.688852</td>\n","      <td>0.688852</td>\n","      <td>0.688852</td>\n","      <td>0.580085</td>\n","      <td>0.628104</td>\n","      <td>0.586775</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.718799</td>\n","      <td>0.673267</td>\n","      <td>0.730449</td>\n","      <td>0.730449</td>\n","      <td>0.730449</td>\n","      <td>0.730449</td>\n","      <td>0.651795</td>\n","      <td>0.688441</td>\n","      <td>0.640732</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.566553</td>\n","      <td>0.685787</td>\n","      <td>0.727121</td>\n","      <td>0.727121</td>\n","      <td>0.727121</td>\n","      <td>0.727121</td>\n","      <td>0.675026</td>\n","      <td>0.685496</td>\n","      <td>0.669162</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.480957</td>\n","      <td>0.715820</td>\n","      <td>0.735857</td>\n","      <td>0.735857</td>\n","      <td>0.735857</td>\n","      <td>0.735857</td>\n","      <td>0.674827</td>\n","      <td>0.700136</td>\n","      <td>0.664326</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.575000</td>\n","      <td>0.739281</td>\n","      <td>0.734193</td>\n","      <td>0.734193</td>\n","      <td>0.734193</td>\n","      <td>0.734193</td>\n","      <td>0.681811</td>\n","      <td>0.700168</td>\n","      <td>0.670077</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.332324</td>\n","      <td>0.854342</td>\n","      <td>0.730865</td>\n","      <td>0.730865</td>\n","      <td>0.730865</td>\n","      <td>0.730865</td>\n","      <td>0.681689</td>\n","      <td>0.695411</td>\n","      <td>0.671919</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.360938</td>\n","      <td>0.995471</td>\n","      <td>0.728369</td>\n","      <td>0.728369</td>\n","      <td>0.728369</td>\n","      <td>0.728369</td>\n","      <td>0.679320</td>\n","      <td>0.697520</td>\n","      <td>0.666292</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.437305</td>\n","      <td>1.100396</td>\n","      <td>0.725458</td>\n","      <td>0.725458</td>\n","      <td>0.725458</td>\n","      <td>0.725458</td>\n","      <td>0.686250</td>\n","      <td>0.688778</td>\n","      <td>0.683860</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.236035</td>\n","      <td>1.192604</td>\n","      <td>0.721714</td>\n","      <td>0.721714</td>\n","      <td>0.721714</td>\n","      <td>0.721714</td>\n","      <td>0.680441</td>\n","      <td>0.684677</td>\n","      <td>0.676589</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.204980</td>\n","      <td>1.252389</td>\n","      <td>0.726705</td>\n","      <td>0.726705</td>\n","      <td>0.726705</td>\n","      <td>0.726705</td>\n","      <td>0.684680</td>\n","      <td>0.689146</td>\n","      <td>0.680740</td>\n","      <td>2404</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at Models/WangchanBERTa-exp1/Outputs/checkpoint-10816 were not used when initializing CustomSequenceClassification: ['baseEmb.position_ids', 'baseEmb.word_embeddings.weight', 'baseEmb.position_embeddings.weight', 'baseEmb.token_type_embeddings.weight', 'baseEmb.LayerNorm.weight', 'baseEmb.LayerNorm.bias', 'newEmb.position_ids', 'newEmb.word_embeddings.weight', 'newEmb.position_embeddings.weight', 'newEmb.token_type_embeddings.weight', 'newEmb.LayerNorm.weight', 'newEmb.LayerNorm.bias']\n","- This IS expected if you are initializing CustomSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CustomSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Done.\n","\n"]}]},{"cell_type":"code","metadata":{"id":"K63mJONBgbiB","executionInfo":{"status":"ok","timestamp":1638896938474,"user_tz":0,"elapsed":10121,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["trainer.save_model(f\"{DIR}/fine-tune-Exp1\")"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIwrxhH2cLsR"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"lRczslIwcNmh","executionInfo":{"status":"ok","timestamp":1638896938476,"user_tz":0,"elapsed":11,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-iWxTbYZKh4","executionInfo":{"status":"ok","timestamp":1638896941807,"user_tz":0,"elapsed":3340,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# assert(torch.equal(model.classifier.dense.weight, trainer.model.classifier.dense.weight))\n","trainer.model = CustomSequenceClassification(model.config, model)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjcp02iSgYgC","executionInfo":{"status":"ok","timestamp":1638896941808,"user_tz":0,"elapsed":23,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["trainer.model.eval();"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lAOts0QgwKba","executionInfo":{"status":"ok","timestamp":1638897097531,"user_tz":0,"elapsed":155744,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"6a6b7709-db22-4fc5-dac5-8b75a84f932d"},"source":["\n","for split_name in dataset_split:\n","  if split_name.startswith(\"train\"):\n","    continue\n","\n","  p, label_ids, result = trainer.predict(test_dataset=dataset_split[split_name])\n","  print(f'Evaluation on {split_name}:')    \n","\n","  for key, value in result.items():\n","      print(f'{key} : {value:.4f}')\n","  \n","  print(\"*\"*40)\n","  print()"],"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1299' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [301/301 02:35]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation on validation:\n","eval_loss : 1.2524\n","eval_accuracy : 0.7267\n","eval_f1_micro : 0.7267\n","eval_precision_micro : 0.7267\n","eval_recall_micro : 0.7267\n","eval_f1_macro : 0.6847\n","eval_precision_macro : 0.6891\n","eval_recall_macro : 0.6807\n","eval_nb_samples : 2404.0000\n","****************************************\n","\n","Evaluation on test:\n","eval_loss : 1.2156\n","eval_accuracy : 0.7316\n","eval_f1_micro : 0.7316\n","eval_precision_micro : 0.7316\n","eval_recall_micro : 0.7316\n","eval_f1_macro : 0.6833\n","eval_precision_macro : 0.6898\n","eval_recall_macro : 0.6783\n","eval_nb_samples : 2671.0000\n","****************************************\n","\n","Evaluation on test-corr:\n","eval_loss : 1.2446\n","eval_accuracy : 0.7114\n","eval_f1_micro : 0.7114\n","eval_precision_micro : 0.7114\n","eval_recall_micro : 0.7114\n","eval_f1_macro : 0.6908\n","eval_precision_macro : 0.6962\n","eval_recall_macro : 0.6885\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-misp:\n","eval_loss : 1.2371\n","eval_accuracy : 0.7205\n","eval_f1_micro : 0.7205\n","eval_precision_micro : 0.7205\n","eval_recall_micro : 0.7205\n","eval_f1_macro : 0.7033\n","eval_precision_macro : 0.7064\n","eval_recall_macro : 0.7022\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-mae:\n","eval_loss : 1.2583\n","eval_accuracy : 0.7125\n","eval_f1_micro : 0.7125\n","eval_precision_micro : 0.7125\n","eval_recall_micro : 0.7125\n","eval_f1_macro : 0.6936\n","eval_precision_macro : 0.6968\n","eval_recall_macro : 0.6933\n","eval_nb_samples : 880.0000\n","****************************************\n","\n","Evaluation on test-all-mae:\n","eval_loss : 1.2226\n","eval_accuracy : 0.7289\n","eval_f1_micro : 0.7289\n","eval_precision_micro : 0.7289\n","eval_recall_micro : 0.7289\n","eval_f1_macro : 0.6798\n","eval_precision_macro : 0.6862\n","eval_recall_macro : 0.6752\n","eval_nb_samples : 2671.0000\n","****************************************\n","\n"]}]},{"cell_type":"code","metadata":{"id":"UZv8Xs1F674m","executionInfo":{"status":"ok","timestamp":1638897097533,"user_tz":0,"elapsed":41,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"bo7F93aYDNUQ","executionInfo":{"status":"ok","timestamp":1638897097533,"user_tz":0,"elapsed":38,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":67,"outputs":[]}]}