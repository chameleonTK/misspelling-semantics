{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine-tune WangchanBERTa [Exp2: MST].ipynb","provenance":[{"file_id":"1VwHo8gTBIwR-EQfMmTCEnzvGpJLTQkCw","timestamp":1635777473931},{"file_id":"10cvKYjXX__tjyByBPQVzyZjm2otyYShy","timestamp":1631707464118},{"file_id":"1gh-cr1UCdC6yAZd1oOxAnMhCUdBFhkB4","timestamp":1630822152939},{"file_id":"1hdFRWS-l9mQmL614VWgsUMw2ln0uuLyh","timestamp":1630690751565},{"file_id":"187rIuGjNJiFqXgLgZg8hbPVspntafDIZ","timestamp":1625408544629},{"file_id":"1PFtJQ_yIxQw_qJXIJhVQ8BdgOFtoVOMN","timestamp":1625391206435},{"file_id":"15eHqe3dQJw63mhVyCoeuhyxrS0eHMagX","timestamp":1624633400803}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fe5bef512d654288bb64dcc94b9b9227":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3458d5f95656466d9943e170445cc554","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_263b7abd394846fba3871d2a39bd795b","IPY_MODEL_85203eea32e7411bbdb9defab8443ed1","IPY_MODEL_9f789a0d8a0d44f98dc72f79fa8680d5"]}},"3458d5f95656466d9943e170445cc554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"263b7abd394846fba3871d2a39bd795b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_24368612c73f4e919e2175bdf53f2a7d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2e65478281d442b835f00bb684aa3eb"}},"85203eea32e7411bbdb9defab8443ed1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ca4344383374944bb80955fb705f2b0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_902deca81b38485c916295548c3359e2"}},"9f789a0d8a0d44f98dc72f79fa8680d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e688bc7dd3fc40b7a0884909c25f0afc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:01&lt;00:00, 5.00MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_386f4eddc8f547c89ab1352349eac169"}},"24368612c73f4e919e2175bdf53f2a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b2e65478281d442b835f00bb684aa3eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ca4344383374944bb80955fb705f2b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"902deca81b38485c916295548c3359e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e688bc7dd3fc40b7a0884909c25f0afc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"386f4eddc8f547c89ab1352349eac169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"783e56242bd84014a025d8fb908bd92e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b1e9316c505419ab90ca1c410a38f5e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2768c933e4a24195a1cfe51d5bc1a885","IPY_MODEL_dda430000e0f42dda29e9e810c9fa534","IPY_MODEL_b21a87ce263a42efa258ecf85b2e5df7"]}},"1b1e9316c505419ab90ca1c410a38f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2768c933e4a24195a1cfe51d5bc1a885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c8f4fcdc9d4e4fff9d6f716bc112db24","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35edd83dac804fe79fa222b21f07f130"}},"dda430000e0f42dda29e9e810c9fa534":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_66061838aaad4ace9cab6c49f92560f8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9096718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9096718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb3b5ae048c0475cb38d733086bac560"}},"b21a87ce263a42efa258ecf85b2e5df7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2a1ceb6254d4e00b0ecc8dc6e33ded8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9.10M/9.10M [00:01&lt;00:00, 8.29MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0bbcec59e96429794e7b0bea015f599"}},"c8f4fcdc9d4e4fff9d6f716bc112db24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35edd83dac804fe79fa222b21f07f130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66061838aaad4ace9cab6c49f92560f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eb3b5ae048c0475cb38d733086bac560":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2a1ceb6254d4e00b0ecc8dc6e33ded8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0bbcec59e96429794e7b0bea015f599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10dafc8e809e481ea20733f0ccb50cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5db09722b55241c1977aecb35599c119","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fff9a667f93441479d0c9a5fc5520309","IPY_MODEL_bdc5e20de7154e27bc6460c5a45154ac","IPY_MODEL_1f2ae58facc7419f93e98d0189a35bd3"]}},"5db09722b55241c1977aecb35599c119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fff9a667f93441479d0c9a5fc5520309":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_366ebdf7a428456e9fe0f940da78c12f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b58273f00bbf4220b42ac498603b88c3"}},"bdc5e20de7154e27bc6460c5a45154ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1120384387a848b89c14a30c475cbf52","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f73c380e1d4450ba792d11668a6e9f8"}},"1f2ae58facc7419f93e98d0189a35bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c9387a175db4a5fbd72f804b7ee8a61","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 8.47kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41a406b8ca0c45fbadd0cecce8ab8bd5"}},"366ebdf7a428456e9fe0f940da78c12f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b58273f00bbf4220b42ac498603b88c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1120384387a848b89c14a30c475cbf52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1f73c380e1d4450ba792d11668a6e9f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c9387a175db4a5fbd72f804b7ee8a61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"41a406b8ca0c45fbadd0cecce8ab8bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12b48496d16d4729a41aafd05208f55b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_18d0e4ee0e58421589f5d3ef2e390a74","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3750259b4ff44cf49e90ef7929e8205c","IPY_MODEL_aeae7b11e0d2407f9547c64ffb6688b8","IPY_MODEL_f02a94cb8b8b4da7a326b36f1166cd87"]}},"18d0e4ee0e58421589f5d3ef2e390a74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3750259b4ff44cf49e90ef7929e8205c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c4a3e3b716141a3acdeb3a2c4327bbb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e9fd1b74e294368a8a13930ae12f672"}},"aeae7b11e0d2407f9547c64ffb6688b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b6c1596fcbf42b09a65019eb202ce96","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":546,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":546,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb6c3fd04f1f4197ba337a9eb69073ac"}},"f02a94cb8b8b4da7a326b36f1166cd87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d1f1bf8a03f4ea4a23017e7ff648921","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 546/546 [00:00&lt;00:00, 9.43kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a141c51e4c2b4406937672e08be05b5c"}},"6c4a3e3b716141a3acdeb3a2c4327bbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e9fd1b74e294368a8a13930ae12f672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b6c1596fcbf42b09a65019eb202ce96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb6c3fd04f1f4197ba337a9eb69073ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d1f1bf8a03f4ea4a23017e7ff648921":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a141c51e4c2b4406937672e08be05b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17f202aa46d943ee9091a8af9379e33a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f7da2ce01e1462588274d73d8fe9bc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61403bf5655e40998de8ef70c4b40ba5","IPY_MODEL_ff75089a54094c6685039a6a8bc4ae9f","IPY_MODEL_331f953f59024a5ab6781f26a546348e"]}},"6f7da2ce01e1462588274d73d8fe9bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61403bf5655e40998de8ef70c4b40ba5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a10ecd01e2254f03b4d4b8ab69145273","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99cc8dd2b2c8469597a7f38e824101fc"}},"ff75089a54094c6685039a6a8bc4ae9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_784540ed20f442a2806129e51ebda4fc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":904693,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":904693,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_caa3adfb8be44bf195f590f861d1985b"}},"331f953f59024a5ab6781f26a546348e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_25e1f84125414760ba6bb240e8dbf9c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 905k/905k [00:00&lt;00:00, 699kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7dfc2d4707564011b7d890c21b1fcc09"}},"a10ecd01e2254f03b4d4b8ab69145273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99cc8dd2b2c8469597a7f38e824101fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"784540ed20f442a2806129e51ebda4fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"caa3adfb8be44bf195f590f861d1985b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25e1f84125414760ba6bb240e8dbf9c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7dfc2d4707564011b7d890c21b1fcc09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84e0586f5b9043dfa3a6eb01ac54d000":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_55b553d553cd41b3abdcbfd67d4d6b69","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_593f6cf5c39040f59e2b92bff5e5af69","IPY_MODEL_4506e25c34e145feba5d20b8ae7087c2","IPY_MODEL_cba2012e0ccb4f3e8625f2ec72901647"]}},"55b553d553cd41b3abdcbfd67d4d6b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"593f6cf5c39040f59e2b92bff5e5af69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d44dcbe4a7f4e26b8b0139a48a704ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8968071c99354baabbea86a4b7afd451"}},"4506e25c34e145feba5d20b8ae7087c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5b0d80615a7b41828ec84593934fd322","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":282,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":282,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9c1fb6179fa446aac9d6b1fd3ff14b8"}},"cba2012e0ccb4f3e8625f2ec72901647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f6b9e2cf82c34cdfba94006c2c6f3300","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 282/282 [00:00&lt;00:00, 6.37kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_838120e7befb4f44bc28732311c49f88"}},"2d44dcbe4a7f4e26b8b0139a48a704ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8968071c99354baabbea86a4b7afd451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b0d80615a7b41828ec84593934fd322":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e9c1fb6179fa446aac9d6b1fd3ff14b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6b9e2cf82c34cdfba94006c2c6f3300":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"838120e7befb4f44bc28732311c49f88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c30100545b9d4bbaabb7f2e5789d53ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_31a7396417234dcba532bb4f7edc74ea","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_37bbf242847d44d7928a932de214afa3","IPY_MODEL_af64ddd1fc924faaa077669851484df7","IPY_MODEL_35b9d35b44964c7496f6ceb081902716"]}},"31a7396417234dcba532bb4f7edc74ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37bbf242847d44d7928a932de214afa3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1784bec33aa348939666b5e707b52664","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e0228b054b3498ca3a192c7961feb54"}},"af64ddd1fc924faaa077669851484df7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e97a52b76a041829ee4c2527702e3dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":423498558,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":423498558,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0ba3a9f45904cab978236bbe092d498"}},"35b9d35b44964c7496f6ceb081902716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22fccd00c57c45b395e654d9cde5aa6b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 423M/423M [00:13&lt;00:00, 31.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b946aeecb7d40ceb6de16beaa7cde74"}},"1784bec33aa348939666b5e707b52664":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e0228b054b3498ca3a192c7961feb54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e97a52b76a041829ee4c2527702e3dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e0ba3a9f45904cab978236bbe092d498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22fccd00c57c45b395e654d9cde5aa6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b946aeecb7d40ceb6de16beaa7cde74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ICAWf9vLw2j","executionInfo":{"status":"ok","timestamp":1638902301034,"user_tz":0,"elapsed":19956,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"926f37ce-f926-4725-984b-661c3655584e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LL80zCUIOxsh","executionInfo":{"status":"ok","timestamp":1638902484210,"user_tz":0,"elapsed":183181,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"f39530c8-199b-47c0-bead-191fb8ca3a94"},"source":["# Install libs\n","!pip -q install torch==1.5.0\n","!pip -q install torchtext==0.6"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 752.0 MB 9.5 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 64 kB 1.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 9.0 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"3KIzREva71h7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQYCxkCFycRm","executionInfo":{"status":"ok","timestamp":1638902595002,"user_tz":0,"elapsed":110809,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"373261f8-d09c-4801-b960-c9e19451c2bd"},"source":["!pip -q install thai2transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.3 MB 6.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 32.5 MB/s \n","\u001b[K     |████████████████████████████████| 170 kB 47.5 MB/s \n","\u001b[K     |████████████████████████████████| 11.0 MB 11.8 MB/s \n","\u001b[K     |████████████████████████████████| 298 kB 46.9 MB/s \n","\u001b[K     |████████████████████████████████| 8.7 MB 21.0 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[K     |████████████████████████████████| 525 kB 43.7 MB/s \n","\u001b[K     |████████████████████████████████| 10.1 MB 39.3 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 34.7 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 42.6 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 49.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 38.8 MB/s \n","\u001b[K     |████████████████████████████████| 132 kB 49.3 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 493 kB/s \n","\u001b[K     |████████████████████████████████| 743 kB 43.6 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 43.0 MB/s \n","\u001b[K     |████████████████████████████████| 160 kB 37.9 MB/s \n","\u001b[K     |████████████████████████████████| 192 kB 51.9 MB/s \n","\u001b[K     |████████████████████████████████| 829 kB 48.4 MB/s \n","\u001b[K     |████████████████████████████████| 332 kB 48.0 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 49.4 MB/s \n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 47.8 MB/s eta 0:00:01tcmalloc: large alloc 1147494400 bytes == 0x55bb9cbac000 @  0x7f820f0fd615 0x55bb986614cc 0x55bb9874147a 0x55bb986642ed 0x55bb98755e1d 0x55bb986d7e99 0x55bb986d29ee 0x55bb98665bda 0x55bb986d7d00 0x55bb986d29ee 0x55bb98665bda 0x55bb986d4737 0x55bb98756c66 0x55bb986d3daf 0x55bb98756c66 0x55bb986d3daf 0x55bb98756c66 0x55bb986d3daf 0x55bb98666039 0x55bb986a9409 0x55bb98664c52 0x55bb986d7c25 0x55bb986d29ee 0x55bb98665bda 0x55bb986d4737 0x55bb986d29ee 0x55bb98665bda 0x55bb986d3915 0x55bb98665afa 0x55bb986d3c0d 0x55bb986d29ee\n","\u001b[K     |████████████████████████████████| 881.9 MB 20 kB/s \n","\u001b[K     |████████████████████████████████| 321 kB 39.7 MB/s \n","\u001b[?25h  Building wheel for thai2transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"WRBpkHFl3AQV","executionInfo":{"status":"ok","timestamp":1638902595003,"user_tz":0,"elapsed":12,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["fin = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\")\n","content = []\n","for line in fin:\n","  content.append(line)\n","fin.close()\n","\n","content[39] = \"    SAVE_STATE_WARNING = ''\\n\"\n","\n","fout = open(\"/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\", \"w\")\n","for line in content:\n","  fout.write(line)\n","fout.close()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TKD9JcvO4xh","executionInfo":{"status":"ok","timestamp":1638902595003,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# from packaging import version\n","# import torch\n","# if version.parse(torch.__version__) <= version.parse(\"1.4.1\"):\n","#     SAVE_STATE_WARNING = \"\"\n","# else:\n","#     from torch.optim.lr_scheduler import SAVE_STATE_WARNING"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"dA0f5_Um2DPf","executionInfo":{"status":"ok","timestamp":1638902595003,"user_tz":0,"elapsed":9,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip install -q pytorch-lightning"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5f9moE7PHpe","executionInfo":{"status":"ok","timestamp":1638902595004,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip -q install git+https://github.com/PyTorchLightning/pytorch-lightning\n","# import pytorch_lightning as pl\n","# print(pl.__version__)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAR-Di_UPKGX","executionInfo":{"status":"ok","timestamp":1638902595005,"user_tz":0,"elapsed":11,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCFx-P4FQUaz"},"source":["# Load Pre-trained Model"]},{"cell_type":"code","metadata":{"id":"Ab28BkQ3hVCN","executionInfo":{"status":"ok","timestamp":1638902595005,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GUiDe3ye6Ks","executionInfo":{"status":"ok","timestamp":1638902595005,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"194d3b23-adcd-4488-d7ed-687cb683af46"},"source":["cd /content/drive/MyDrive/Mispelling/misspelling-semantics/"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Mispelling/misspelling-semantics\n"]}]},{"cell_type":"code","metadata":{"id":"og7jEc7eL9FJ","executionInfo":{"status":"ok","timestamp":1638902595006,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["DIR = \"Models/WangchanBERTa-exp2\""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubHucCA5QW93","executionInfo":{"status":"ok","timestamp":1638902595006,"user_tz":0,"elapsed":7,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["model_idx = 0\n","model_name = \"wangchanberta\"\n","# model_name = \"xlmr\"\n","# model_name = \"mbert\"\n","args_params = f\"{model_name} wisesight_sentiment {DIR}/Outputs/ {DIR}/Logs/ --batch_size 8 --seed {model_idx} --run_name exp1 --num_train_epochs 10\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-BVhvmoQXpk","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["fe5bef512d654288bb64dcc94b9b9227","3458d5f95656466d9943e170445cc554","263b7abd394846fba3871d2a39bd795b","85203eea32e7411bbdb9defab8443ed1","9f789a0d8a0d44f98dc72f79fa8680d5","24368612c73f4e919e2175bdf53f2a7d","b2e65478281d442b835f00bb684aa3eb","7ca4344383374944bb80955fb705f2b0","902deca81b38485c916295548c3359e2","e688bc7dd3fc40b7a0884909c25f0afc","386f4eddc8f547c89ab1352349eac169","783e56242bd84014a025d8fb908bd92e","1b1e9316c505419ab90ca1c410a38f5e","2768c933e4a24195a1cfe51d5bc1a885","dda430000e0f42dda29e9e810c9fa534","b21a87ce263a42efa258ecf85b2e5df7","c8f4fcdc9d4e4fff9d6f716bc112db24","35edd83dac804fe79fa222b21f07f130","66061838aaad4ace9cab6c49f92560f8","eb3b5ae048c0475cb38d733086bac560","a2a1ceb6254d4e00b0ecc8dc6e33ded8","b0bbcec59e96429794e7b0bea015f599","10dafc8e809e481ea20733f0ccb50cc5","5db09722b55241c1977aecb35599c119","fff9a667f93441479d0c9a5fc5520309","bdc5e20de7154e27bc6460c5a45154ac","1f2ae58facc7419f93e98d0189a35bd3","366ebdf7a428456e9fe0f940da78c12f","b58273f00bbf4220b42ac498603b88c3","1120384387a848b89c14a30c475cbf52","1f73c380e1d4450ba792d11668a6e9f8","6c9387a175db4a5fbd72f804b7ee8a61","41a406b8ca0c45fbadd0cecce8ab8bd5"]},"executionInfo":{"status":"ok","timestamp":1638902616847,"user_tz":0,"elapsed":21848,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"304b3a1f-6b19-44fb-b59e-bca5f8a92764"},"source":["import argparse\n","import math\n","import os\n","from functools import partial\n","import urllib.request\n","from tqdm import tqdm\n","from typing import Collection, Callable\n","from pathlib import Path\n","from sklearn import preprocessing\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from transformers import (\n","    AdamW, \n","    get_linear_schedule_with_warmup, \n","    get_constant_schedule, \n","    AutoTokenizer, \n","    AutoModel,\n","    AutoModelForSequenceClassification, \n","    AutoConfig,\n","    Trainer, \n","    TrainingArguments,\n","    CamembertTokenizer,\n","    BertTokenizer,\n","    BertTokenizerFast,\n","    BertConfig,\n","    XLMRobertaTokenizer,\n","    XLMRobertaTokenizerFast,\n","    XLMRobertaConfig,\n","    DataCollatorWithPadding,\n","    default_data_collator\n",")\n","\n","from datasets import load_dataset, list_metrics, load_dataset, Dataset\n","from thai2transformers.datasets import SequenceClassificationDataset\n","from thai2transformers.metrics import classification_metrics, multilabel_classification_metrics\n","from thai2transformers.finetuners import SequenceClassificationFinetuner\n","from thai2transformers.auto import AutoModelForMultiLabelSequenceClassification\n","from thai2transformers.tokenizers import (\n","    ThaiRobertaTokenizer,\n","    ThaiWordsNewmmTokenizer,\n","    ThaiWordsSyllableTokenizer,\n","    FakeSefrCutTokenizer,\n",")\n","from thai2transformers.utils import get_dict_val\n","from thai2transformers.conf import Task\n","from thai2transformers import preprocess\n","\n","CACHE_DIR = f'{str(Path.home())}/.cache/huggingface_datasets'\n","\n","METRICS = {\n","    Task.MULTICLASS_CLS: classification_metrics,\n","    Task.MULTILABEL_CLS: multilabel_classification_metrics\n","}\n","\n","PUBLIC_MODEL = {\n","    # 'mbert': {\n","    #     'name': 'bert-base-multilingual-cased',\n","    #     'tokenizer': BertTokenizerFast.from_pretrained('bert-base-multilingual-cased'),\n","    #     'config': BertConfig.from_pretrained('bert-base-multilingual-cased'),\n","    # },\n","    'xlmr': {\n","        'name': 'xlm-roberta-base',\n","        'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base'),\n","        'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    },\n","    # 'xlmr-large': {\n","    #     'name': 'xlm-roberta-large',\n","    #     'tokenizer': XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-large'),\n","    #     'config': XLMRobertaConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","    # 'thbert': {\n","    #     'name': 'monsoon-nlp/bert-base-thai',\n","    #     'tokenizer': AutoTokenizer.from_pretrained('monsoon-nlp/bert-base-thai'),\n","    #     'config': AutoConfig.from_pretrained('xlm-roberta-base'),\n","    # },\n","}\n","\n","TOKENIZER_CLS = {\n","    'wangchanberta': CamembertTokenizer,\n","    # 'spm': ThaiRobertaTokenizer,\n","    # 'newmm': ThaiWordsNewmmTokenizer,\n","    # 'syllable': ThaiWordsSyllableTokenizer,\n","    # 'sefr_cut': FakeSefrCutTokenizer,\n","}\n","\n","DATASET_METADATA = {\n","    'wisesight_sentiment': {\n","        'huggingface_dataset_name': 'wisesight_sentiment',\n","        'task': Task.MULTICLASS_CLS,\n","        'text_input_col_name': 'texts',\n","        'label_col_name': 'category',\n","        'num_labels': 3,\n","        'split_names': ['train', 'validation', 'test']\n","    }\n","}\n","\n","def init_public_model_tokenizer_for_seq_cls(public_model_name, task, num_labels):\n","    \n","    config = PUBLIC_MODEL[public_model_name]['config']\n","    config.num_labels = num_labels\n","    tokenizer = PUBLIC_MODEL[public_model_name]['tokenizer']\n","    model_name = PUBLIC_MODEL[public_model_name]['name']\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n","                                                                   config=config)\n","    if task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(model_name,\n","                                                                             config=config)\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_model_tokenizer_for_seq_cls(model_dir, tokenizer_cls, tokenizer_dir, task, num_labels):\n","    \n","    config = AutoConfig.from_pretrained(\n","        model_dir,\n","        num_labels=num_labels\n","    );\n","\n","    tokenizer = tokenizer_cls.from_pretrained(\n","        tokenizer_dir,\n","    );\n","\n","    if task == Task.MULTICLASS_CLS:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","    elif task == Task.MULTILABEL_CLS:\n","        model = AutoModelForMultiLabelSequenceClassification.from_pretrained(\n","            model_dir,\n","            config=config,\n","        )\n","\n","    # print(f'\\n[INFO] Model architecture: {model} \\n\\n')\n","    # print(f'\\n[INFO] tokenizer: {tokenizer} \\n\\n')\n","\n","    return model, tokenizer, config\n","\n","def init_trainer(task, model, train_dataset, val_dataset, warmup_steps, args, data_collator=default_data_collator): \n","        \n","    training_args = TrainingArguments(\n","                        num_train_epochs=args.num_train_epochs,\n","                        per_device_train_batch_size=args.batch_size,\n","                        per_device_eval_batch_size=args.batch_size,\n","                        gradient_accumulation_steps=args.gradient_accumulation_steps,\n","                        learning_rate=args.learning_rate,\n","                        warmup_steps=warmup_steps,\n","                        weight_decay=args.weight_decay,\n","                        adam_epsilon=args.adam_epsilon,\n","                        max_grad_norm=args.max_grad_norm,\n","                        #checkpoint\n","                        output_dir=args.output_dir,\n","                        overwrite_output_dir=True,\n","                        #logs\n","                        logging_dir=args.log_dir,\n","                        logging_first_step=False,\n","                        logging_steps=args.logging_steps,\n","                        #eval\n","                        evaluation_strategy='epoch' if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else 'no',\n","                        load_best_model_at_end=True,\n","                        #others\n","                        seed=args.seed,\n","                        fp16=args.fp16,\n","                        fp16_opt_level=args.fp16_opt_level,\n","                        dataloader_drop_last=False,\n","                        no_cuda=args.no_cuda,\n","                        metric_for_best_model=args.metric_for_best_model,\n","                        prediction_loss_only=False,\n","                        run_name=args.run_name\n","                    )\n","    if task == Task.MULTICLASS_CLS:\n","        compute_metrics_fn = METRICS[task]\n","    elif task == Task.MULTILABEL_CLS:\n","        compute_metrics_fn = partial(METRICS[task],n_labels=DATASET_METADATA[args.dataset_name]['num_labels'])\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        compute_metrics=compute_metrics_fn,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        data_collator=data_collator\n","    )\n","    return trainer, training_args\n","\n","# def _process_transformers(\n","#     text: str,\n","#     pre_rules: Collection[Callable] = [\n","#         preprocess.fix_html,\n","#         preprocess.rm_brackets,\n","#         preprocess.replace_newlines,\n","#         preprocess.rm_useless_spaces,\n","#         preprocess.replace_spaces,\n","#         preprocess.replace_rep_after,\n","#     ],\n","#     tok_func: Callable = preprocess.word_tokenize,\n","#     post_rules: Collection[Callable] = [preprocess.ungroup_emoji, preprocess.replace_wrep_post],\n","#     lowercase: bool = False\n","# ) -> str:\n","#     if lowercase:\n","#         text = text.lower()\n","#     for rule in pre_rules:\n","#         text = rule(text)\n","#     toks = tok_func(text)\n","#     for rule in post_rules:\n","#         toks = rule(toks)\n","#     return \"\".join(toks)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe5bef512d654288bb64dcc94b9b9227","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"783e56242bd84014a025d8fb908bd92e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10dafc8e809e481ea20733f0ccb50cc5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anv_bUF0QZL2","executionInfo":{"status":"ok","timestamp":1638902616848,"user_tz":0,"elapsed":29,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"6cc2dc75-941c-42bd-dd6b-45e78fa437d3"},"source":["parser = argparse.ArgumentParser()\n","# Required\n","parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","parser.add_argument('output_dir', type=str)\n","parser.add_argument('log_dir', type=str)\n","\n","parser.add_argument('--model_dir', type=str)\n","parser.add_argument('--tokenizer_dir', type=str)\n","parser.add_argument('--prepare_for_tokenization', action='store_true', default=False, help='To replace space with a special token e.g. `<_>`. This may require for some pretrained models.')\n","parser.add_argument('--space_token', type=str, default=' ', help='The special token for space, specify if argumet: prepare_for_tokenization is applied')\n","parser.add_argument('--max_length', type=int, default=None)\n","parser.add_argument('--lowercase', action='store_true', default=False)\n","\n","# Finetuning\n","parser.add_argument('--num_train_epochs', type=int, default=5)\n","parser.add_argument('--learning_rate', type=float, default=1e-05)\n","parser.add_argument('--weight_decay', type=float, default=0.01)\n","parser.add_argument('--warmup_ratio', type=float, default=0.1)\n","parser.add_argument('--batch_size', type=int, default=16)\n","parser.add_argument('--no_cuda', action='store_true', default=False)\n","parser.add_argument('--fp16', action='store_true', default=False)\n","parser.add_argument('--greater_is_better', action='store_true', default=True)\n","parser.add_argument('--metric_for_best_model', type=str, default='f1_micro')\n","parser.add_argument('--logging_steps', type=int, default=10)\n","parser.add_argument('--seed', type=int, default=2020)\n","parser.add_argument('--fp16_opt_level', type=str, default='O1')\n","parser.add_argument('--gradient_accumulation_steps', type=int, default=1)\n","parser.add_argument('--adam_epsilon', type=float, default=1e-08)\n","parser.add_argument('--max_grad_norm', type=float, default=1.0)\n","\n","# wandb\n","parser.add_argument('--run_name', type=str, default=None)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--run_name'], dest='run_name', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help=None, metavar=None)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qCeYWu0tQauI","executionInfo":{"status":"ok","timestamp":1638902616849,"user_tz":0,"elapsed":12,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# parser.add_argument('tokenizer_type_or_public_model_name', type=str, help='The type token model used. Specify the name of tokenizer either `spm`, `newmm`, `syllable`, or `sefr_cut`.')\n","# parser.add_argument('dataset_name', help='Specify the dataset name to finetune. Currently, sequence classification datasets include `wisesight_sentiment`, `generated_reviews_enth-correct_translation`, `generated_reviews_enth-review_star` and`wongnai_reviews`.')\n","# parser.add_argument('output_dir', type=str)\n","# parser.add_argument('log_dir', type=str)\n","args = parser.parse_args(args_params.split())\n","\n","# Set seed\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrh47k-vQc92","executionInfo":{"status":"ok","timestamp":1638902616850,"user_tz":0,"elapsed":13,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"acf73005-3e60-4df4-d720-4a10e27c0959"},"source":["\n","# try:\n","print(f'\\n\\n[INFO] Dataset: {args.dataset_name}')\n","print(f'\\n\\n[INFO] Huggingface\\'s dataset name: {DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"]} ')\n","print(f'[INFO] Task: {DATASET_METADATA[args.dataset_name][\"task\"].value}')\n","print(f'\\n[INFO] space_token: {args.space_token}')\n","print(f'[INFO] prepare_for_tokenization: {args.prepare_for_tokenization}\\n')\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","[INFO] Dataset: wisesight_sentiment\n","\n","\n","[INFO] Huggingface's dataset name: wisesight_sentiment \n","[INFO] Task: multiclass_classification\n","\n","[INFO] space_token:  \n","[INFO] prepare_for_tokenization: False\n","\n"]}]},{"cell_type":"code","metadata":{"id":"SgzmOBvkQoTB","executionInfo":{"status":"ok","timestamp":1638902616850,"user_tz":0,"elapsed":9,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# dataset = load_dataset(DATASET_METADATA[args.dataset_name][\"huggingface_dataset_name\"])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChlS02wkQqRr","executionInfo":{"status":"ok","timestamp":1638902616851,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# labels = {\n","#     \"neg\": 2,\n","#     \"neu\": 1,\n","#     \"pos\": 0,\n","#     \"q\": 3\n","# }\n","# dataset"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8AMunmmXv3V","executionInfo":{"status":"ok","timestamp":1638902616851,"user_tz":0,"elapsed":9,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# dataset[\"train\"][0:5]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267,"referenced_widgets":["12b48496d16d4729a41aafd05208f55b","18d0e4ee0e58421589f5d3ef2e390a74","3750259b4ff44cf49e90ef7929e8205c","aeae7b11e0d2407f9547c64ffb6688b8","f02a94cb8b8b4da7a326b36f1166cd87","6c4a3e3b716141a3acdeb3a2c4327bbb","4e9fd1b74e294368a8a13930ae12f672","3b6c1596fcbf42b09a65019eb202ce96","bb6c3fd04f1f4197ba337a9eb69073ac","9d1f1bf8a03f4ea4a23017e7ff648921","a141c51e4c2b4406937672e08be05b5c","17f202aa46d943ee9091a8af9379e33a","6f7da2ce01e1462588274d73d8fe9bc4","61403bf5655e40998de8ef70c4b40ba5","ff75089a54094c6685039a6a8bc4ae9f","331f953f59024a5ab6781f26a546348e","a10ecd01e2254f03b4d4b8ab69145273","99cc8dd2b2c8469597a7f38e824101fc","784540ed20f442a2806129e51ebda4fc","caa3adfb8be44bf195f590f861d1985b","25e1f84125414760ba6bb240e8dbf9c6","7dfc2d4707564011b7d890c21b1fcc09","84e0586f5b9043dfa3a6eb01ac54d000","55b553d553cd41b3abdcbfd67d4d6b69","593f6cf5c39040f59e2b92bff5e5af69","4506e25c34e145feba5d20b8ae7087c2","cba2012e0ccb4f3e8625f2ec72901647","2d44dcbe4a7f4e26b8b0139a48a704ad","8968071c99354baabbea86a4b7afd451","5b0d80615a7b41828ec84593934fd322","e9c1fb6179fa446aac9d6b1fd3ff14b8","f6b9e2cf82c34cdfba94006c2c6f3300","838120e7befb4f44bc28732311c49f88","c30100545b9d4bbaabb7f2e5789d53ac","31a7396417234dcba532bb4f7edc74ea","37bbf242847d44d7928a932de214afa3","af64ddd1fc924faaa077669851484df7","35b9d35b44964c7496f6ceb081902716","1784bec33aa348939666b5e707b52664","4e0228b054b3498ca3a192c7961feb54","2e97a52b76a041829ee4c2527702e3dc","e0ba3a9f45904cab978236bbe092d498","22fccd00c57c45b395e654d9cde5aa6b","1b946aeecb7d40ceb6de16beaa7cde74"]},"id":"nv7ywhlqWau3","executionInfo":{"status":"ok","timestamp":1638902642090,"user_tz":0,"elapsed":25248,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"5324f7a3-7d63-4c63-9263-6458c93ab17f"},"source":["text_input_col_name = DATASET_METADATA[args.dataset_name]['text_input_col_name']\n","\n","if args.tokenizer_type_or_public_model_name not in list(TOKENIZER_CLS.keys()) \\\n","    and args.tokenizer_type_or_public_model_name not in list(PUBLIC_MODEL.keys()):\n","    raise f\"The tokenizer type or public model name `{args.tokenizer_type_or_public_model_name}`` is not supported\"\n","\n","if args.tokenizer_type_or_public_model_name in list(TOKENIZER_CLS.keys()):\n","    tokenizer_cls = TOKENIZER_CLS[args.tokenizer_type_or_public_model_name]\n","\n","\n","task = DATASET_METADATA[args.dataset_name]['task']\n","if args.tokenizer_type_or_public_model_name in PUBLIC_MODEL.keys():\n","    print(args.tokenizer_type_or_public_model_name)\n","    model, tokenizer, config = init_public_model_tokenizer_for_seq_cls(args.tokenizer_type_or_public_model_name,\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);\n","else:\n","    print(\"WangchanBERTa\")\n","    model, tokenizer, config = init_model_tokenizer_for_seq_cls(\"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        tokenizer_cls,\n","                                                        \"airesearch/wangchanberta-base-att-spm-uncased\",\n","                                                        task=task,\n","                                                        num_labels=DATASET_METADATA[args.dataset_name]['num_labels']);"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["WangchanBERTa\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12b48496d16d4729a41aafd05208f55b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17f202aa46d943ee9091a8af9379e33a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/905k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84e0586f5b9043dfa3a6eb01ac54d000","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/282 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c30100545b9d4bbaabb7f2e5789d53ac","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/423M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"8dcSKA23WpQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638902642090,"user_tz":0,"elapsed":14,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"7ec73e51-4b80-4622-9ec0-3e2a807ae456"},"source":["# if args.tokenizer_type_or_public_model_name == 'wangchanberta':\n","#     tokenizer.additional_special_tokens = ['<s>NOTUSED', '</s>NOTUSED', args.space_token]\n","\n","print('\\n[INFO] Preprocess and tokenizing texts in datasets')\n","max_length = args.max_length if args.max_length else config.max_position_embeddings\n","print(f'[INFO] max_length = {max_length} \\n')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Preprocess and tokenizing texts in datasets\n","[INFO] max_length = 512 \n","\n"]}]},{"cell_type":"code","metadata":{"id":"AfYFfObgad6q","executionInfo":{"status":"ok","timestamp":1638902642091,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# !pip -q install demoji\n","# import demoji\n","# demoji.download_codes()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqsSdW8KbbFd","executionInfo":{"status":"ok","timestamp":1638902642091,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mTebN_FOhqa"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"rBcBdWSQOjP2","executionInfo":{"status":"ok","timestamp":1638902642091,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import json\n","import pandas as pd\n","\n","def load_jsonl(fname):\n","    fin = open(fname, encoding=\"utf-8\")\n","    data = []\n","    for line in fin:\n","        d = json.loads(line.strip())\n","        data.append(d)\n","\n","    return data\n","\n","def save_jsonl(data, filename):\n","    with open(filename, \"w\", encoding=\"utf-8\") as fo:\n","        for idx, d in enumerate(data):\n","            fo.write(json.dumps(d, ensure_ascii=False))\n","            fo.write(\"\\n\")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1l6r0cWh1I-","executionInfo":{"status":"ok","timestamp":1638902642092,"user_tz":0,"elapsed":11,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpjyO0OwOjSW","executionInfo":{"status":"ok","timestamp":1638902647193,"user_tz":0,"elapsed":5111,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["traindata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_train.jsonl\")\n","validdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_valid.jsonl\")\n","testdata = load_jsonl(f\"{DIR}/../../Datasets/WisesightSentiment/tokenized_test-misp.jsonl\")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTPLMhBQO4u3","executionInfo":{"status":"ok","timestamp":1638902647194,"user_tz":0,"elapsed":18,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"91e2a131-4ce8-4b73-b8d5-f336c212fb10"},"source":["import itertools\n","def filterByMode(data, mode=None):\n","  output = []\n","  for sent in data:\n","    if mode is None:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","    elif mode==\"corr\":\n","      tokenized = [seg[1] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    else:\n","      tokenized = [seg[0] for seg in sent[\"segments\"]]\n","      if len(sent[\"misp_tokens\"])==0:\n","        continue\n","    \n","    tokenized = list(itertools.chain(*tokenized))\n","  \n","    output.append({\n","        \"category\": sent[\"category\"],\n","        \"text\": sent[\"text\"],\n","        \"tokenized\": tokenized,\n","        \"segments\": sent[\"segments\"]\n","    })\n","\n","  return output\n","\n","traindata\n","validdata\n","allTestdata = filterByMode(testdata)\n","corrTestdata = filterByMode(testdata, \"corr\")\n","mispTestdata = filterByMode(testdata, \"misp\")\n","len(allTestdata), len(corrTestdata), len(mispTestdata)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2671, 880, 880)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"xflkz27paVDG","executionInfo":{"status":"ok","timestamp":1638902647194,"user_tz":0,"elapsed":14,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ewn4a1gWPCKC","executionInfo":{"status":"ok","timestamp":1638902647194,"user_tz":0,"elapsed":14,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"4612dbc8-51ae-4ebc-83e7-6475dcc94272"},"source":["for sent in testdata[1:10]:\n","  print(sent)\n","  # break"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'category': 'neu', 'text': 'ครับ #phithanbkk', 'misp_tokens': [], 'tokenized': ['ครับ', ' ', '#phithanbkk'], 'segments': [[['ครับ', ' ', '#phithanbkk'], ['ครับ', ' ', '#phithanbkk']]]}\n","{'category': 'neg', 'text': 'การด่าไปเหมือนได้บรรเทาความเครียดเฉยๆ แต่บีทีเอส (รถไฟฟ้า) มันสำนึกมั้ย ก็ไม่อ่ะ 😕', 'misp_tokens': [{'corr': 'ไหม', 'misp': 'มั้ย', 'int': True, 's': 67, 't': 71}], 'tokenized': ['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก', 'มั้ย', ' ', 'ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face'], 'segments': [[['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก'], ['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก']], [['มั้ย'], ['ไหม']], [['ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face'], ['ก็', 'ไม่', 'อ่ะ', ' ', 'confused', ' ', 'face']]]}\n","{'category': 'neu', 'text': 'Cf clarins 5 ขวด 2850', 'misp_tokens': [], 'tokenized': ['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850'], 'segments': [[['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850'], ['Cf', ' ', 'clarins', ' ', '5', ' ', 'ขวด', ' ', '2850']]]}\n","{'category': 'neu', 'text': 'ทานได้ค่ะ น้ำซุป MK ต้มมาจากหัวผักกาด ซีอิ้วขาว เกลือ แลน้ำตาลค่ะ', 'misp_tokens': [{'corr': 'และ', 'misp': 'แล', 'int': False, 's': 54, 't': 56}], 'tokenized': ['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ', ' ', 'แล', 'น้ำตาล', 'ค่ะ'], 'segments': [[['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ'], ['ทาน', 'ได้', 'ค่ะ', ' ', 'น้ำ', 'ซุป', ' ', 'MK', ' ', 'ต้ม', 'มา', 'จาก', 'หัว', 'ผักกาด', ' ', 'ซีอิ้วขาว', ' ', 'เกลือ']], [['แล'], ['และ']], [['น้ำตาล', 'ค่ะ'], ['น้ำตาล', 'ค่ะ']]]}\n","{'category': 'neu', 'text': 'เคล็ดลับที่ขาดไม่ได้ในการป้องกันผิวจากแสงแดด คือการทาครีมกันแดด สาวๆบ้างคนอาจจะคิดว่ามันไม่ใช่เรื่องสำคัญเท่าไหร่ แต่บอกเลยว่า ผิดมาก เพราะแสงแดดสมัยนี้แรงมาก และมีอนุภาพการทำลายผิวสูงมาก ถ้าไม่อยากให้ผิวเราถูกทำร้ายแบบซ้ำๆซาก ควรทาครีมกันแดดที่ดีมีคุณภาพอย่าง Eucerin Sun Age Repair Serum ปัจจุบันครีมกันแดดมีมากมายให้เราเลือกซื้อก็จริง แต่ก็อย่าลืมเลือกสิ่งที่ดีที่สุดให้ตัวเราอย่าง Eucerin Sun Acne oil Control ค่ะ', 'misp_tokens': [], 'tokenized': ['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ'], 'segments': [[['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ'], ['เคล็ด', 'ลับ', 'ที่', 'ขาด', 'ไม่', 'ได้', 'ใน', 'การ', 'ป้องกัน', 'ผิว', 'จาก', 'แสง', 'แดด', ' ', 'คือ', 'การ', 'ทา', 'ครีม', 'กัน', 'แดด', ' ', 'สาว', 'ๆ', 'บ้าง', 'คน', 'อาจ', 'จะ', 'คิด', 'ว่า', 'มัน', 'ไม่', 'ใช่', 'เรื่อง', 'สำคัญ', 'เท่า', 'ไหร่', ' ', 'แต่', 'บอก', 'เลย', 'ว่า', ' ', 'ผิด', 'มาก', ' ', 'เพราะ', 'แสง', 'แดด', 'สมัย', 'นี้', 'แรง', 'มาก', ' ', 'และ', 'มี', 'อนุภาพ', 'การ', 'ทำลาย', 'ผิว', 'สูง', 'มาก', ' ', 'ถ้า', 'ไม่', 'อยาก', 'ให้', 'ผิว', 'เรา', 'ถูก', 'ทำร้าย', 'แบบ', 'ซ้ำ', 'ๆ', 'ซาก', ' ', 'ควร', 'ทา', 'ครีม', 'กัน', 'แดด', 'ที่', 'ดี', 'มี', 'คุณภาพ', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Age', ' ', 'Repair', ' Serum', ' ', 'ปัจจุบัน', 'ครีม', 'กัน', 'แดด', 'มี', 'มากมาย', 'ให้', 'เรา', 'เลือก', 'ซื้อ', 'ก็', 'จริง', ' ', 'แต่', 'ก็', 'อย่า', 'ลืม', 'เลือก', 'สิ่ง', 'ที่', 'ดี', 'ที่สุด', 'ให้', 'ตัว', 'เรา', 'อย่าง', ' ', 'Eucerin', ' ', 'Sun', ' ', 'Acne', ' ', 'oil', ' ', 'Control', ' ', 'ค่ะ']]]}\n","{'category': 'neu', 'text': \"สำหรับสูตรของผม คือ Jack Daniel's หวานซ่อนเปรี้ยวชื่อ Jack Yellow Life ส่วนประกอบ Jack Daniel's 2 ชอท น้ำเก๊กฮวย น้ำมะนาว ใบมิ้นท์ เกลือเล็กน้อย วิธีปรุง นำ JackDaniel's มาเขย่ากับน้ำเก๊กฮวย เจือด้วยน้ำมะนาวบางๆ ตกแต่งด้วยใบมิ้น เสริฟด้วยแก้วที่ทาเกลือไว้ที่ปากแก้ว รสชาติที่จะได้คือหวาน หอม ซ่อนเปรี้ยว ด้วยคอนเซ็ปว่านี่แหละคือชีวิต จะหวานอย่างเดียวก็จะเลี่ยนไป จะเปรี้ยวเกินไปก็ไม่ใช่เรื่อง จึงควรจะมีทั้งเปรี้ยว ทั้งหวานคละเคล้ากันไปครับ\", 'misp_tokens': [], 'tokenized': ['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ'], 'segments': [[['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ'], ['สำหรับ', 'สูตร', 'ของ', 'ผม', ' ', 'คือ', ' ', 'Jack Daniel', \"'\", 's', ' ', 'หวาน', 'ซ่อน', 'เปรี้ยว', 'ชื่อ', ' ', 'Jack Yellow', ' ', 'Life', ' ', 'ส่วน', 'ประกอบ', ' ', 'Jack Daniel', \"'\", 's', ' ', '2', ' ', 'ชอท', ' ', 'น้ำ', 'เก๊กฮวย', ' ', 'น้ำ', 'มะนาว', ' ', 'ใบ', 'มิ้นท์', ' ', 'เกลือ', 'เล็กน้อย', ' ', 'วิธี', 'ปรุง', ' ', 'นำ', ' ', 'JackDaniel', \"'\", 's', ' ', 'มา', 'เขย่า', 'กับ', 'น้ำ', 'เก๊กฮวย', ' ', 'เจือ', 'ด้วย', 'น้ำ', 'มะนาว', 'บาง', 'ๆ', ' ', 'ตกแต่ง', 'ด้วย', 'ใบมิ้น', ' ', 'เสริฟ', 'ด้วย', 'แก้ว', 'ที่', 'ทาเกลือ', 'ไว้', 'ที่', 'ปากแก้ว', ' ', 'รสชาติ', 'ที่', 'จะ', 'ได้', 'คือ', 'หวาน', ' ', 'หอม', ' ', 'ซ่อน', 'เปรี้ยว', ' ', 'ด้วย', 'คอนเซ็ป', 'ว่า', 'นี่', 'แหละ', 'คือ', 'ชีวิต', ' ', 'จะ', 'หวาน', 'อย่าง', 'เดียว', 'ก็', 'จะ', 'เลี่ยน', 'ไป', ' ', 'จะ', 'เปรี้ยว', 'เกิน', 'ไป', 'ก็', 'ไม่', 'ใช่', 'เรื่อง', ' ', 'จึง', 'ควร', 'จะ', 'มี', 'ทั้ง', 'เปรี้ยว', ' ', 'ทั้งหวาน', 'คละเคล้า', 'กัน', 'ไป', 'ครับ']]]}\n","{'category': 'neg', 'text': 'เจ้ว่าการ์นิเย่แอบแรงนิสหน่อย เคยใช้โยเกิร์ตไม๊ พรุ้งนี้ลองพอกหน้าดูทำให้หน้าสบายขึ้น นุ่มขึ้น หายไวไวน๊าาาา', 'misp_tokens': [{'corr': 'นะ', 'misp': 'น๊าาาา', 'int': True, 's': 102, 't': 108}, {'corr': 'นิดหน่อย', 'misp': 'นิสหน่อย', 'int': True, 's': 21, 't': 29}, {'corr': 'ไหม', 'misp': 'ไม๊', 'int': True, 's': 44, 't': 47}], 'tokenized': ['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง', 'นิสหน่อย', ' ', 'เคย', 'ใช้', 'โยเกิร์ต', 'ไม๊', ' ', 'พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไว', 'ไวน๊าาาา'], 'segments': [[['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง'], ['เจ้ว่า', 'การ์นิเย่', 'แอบ', 'แรง']], [['นิสหน่อย'], ['นิดหน่อย']], [['เคย', 'ใช้', 'โยเกิร์ต'], ['เคย', 'ใช้', 'โยเกิร์ต']], [['ไม๊'], ['ไหม']], [['พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไวไว'], ['พรุ้ง', 'นี้', 'ลอง', 'พอก', 'หน้า', 'ดู', 'ทำ', 'ให้', 'หน้า', 'สบาย', 'ขึ้น', ' ', 'นุ่ม', 'ขึ้น', ' ', 'หาย', 'ไวไว']], [['น๊าาาา'], ['นะ']], [[], []]]}\n","{'category': 'neu', 'text': 'เอๅจริงๆถ้ๅมันเปิดให้ใช้และถูกกฎหมๅยจริวคงกลัวจะเก็บภๅษียังไงรึป่ๅว', 'misp_tokens': [{'corr': 'เอา', 'misp': 'เอๅ', 'int': False, 's': 0, 't': 3}, {'corr': 'ถ้า', 'misp': 'ถ้ๅ', 'int': False, 's': 8, 't': 11}, {'corr': 'กฎหมาย', 'misp': 'กฎหมๅย', 'int': False, 's': 30, 't': 36}, {'corr': 'จริง', 'misp': 'จริว', 'int': False, 's': 36, 't': 40}, {'corr': 'ฤๅษี', 'misp': 'ภๅษี', 'int': False, 's': 52, 't': 56}, {'corr': 'เปล่า', 'misp': 'ป่ๅว', 'int': False, 's': 63, 't': 67}], 'tokenized': ['เอๅจริง', 'ๆ', 'ถ้ๅ', 'มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก', 'กฎหมๅย', 'จริว', 'คง', 'กลัว', 'จะ', 'เก็บ', 'ภๅษี', 'ยัง', 'ไง', 'รึป่ๅว'], 'segments': [[[], []], [['เอๅ'], ['เอา']], [['จริง', 'ๆ'], ['จริง', 'ๆ']], [['ถ้ๅ'], ['ถ้า']], [['มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก'], ['มัน', 'เปิด', 'ให้', 'ใช้', 'และ', 'ถูก']], [['กฎหมๅย'], ['กฎหมาย']], [[], []], [['จริว'], ['จริง']], [['คง', 'กลัว', 'จะ', 'เก็บ'], ['คง', 'กลัว', 'จะ', 'เก็บ']], [['ภๅษี'], ['ฤๅษี']], [['ยัง', 'ไง', 'รึ'], ['ยัง', 'ไง', 'รึ']], [['ป่ๅว'], ['เปล่า']], [[], []]]}\n","{'category': 'neg', 'text': 'อิผ้าอนามัยเหิ้ย ติดทุกอย่าง ยกเว้นกางเกงใน', 'misp_tokens': [{'corr': 'อี', 'misp': 'อิ', 'int': True, 's': 0, 't': 2}, {'corr': 'เหี้ย', 'misp': 'เหิ้ย', 'int': False, 's': 11, 't': 16}], 'tokenized': ['อิผ้า', 'อนามัย', 'เหิ้ย', ' ', 'ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน'], 'segments': [[[], []], [['อิ'], ['อี']], [['ผ้า', 'อนามัย'], ['ผ้า', 'อนามัย']], [['เหิ้ย'], ['เหี้ย']], [['ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน'], ['ติด', 'ทุก', 'อย่าง', ' ', 'ยกเว้น', 'กางเกง', 'ใน']]]}\n"]}]},{"cell_type":"code","metadata":{"id":"NRWpDhQaitQc","executionInfo":{"status":"ok","timestamp":1638902647195,"user_tz":0,"elapsed":11,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"yceBl7D2jGyv","executionInfo":{"status":"ok","timestamp":1638902647195,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLTGbmXyf0gp","executionInfo":{"status":"ok","timestamp":1638902647195,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["import glob\n","from torch.utils.data import Dataset as TorchDataset\n","from datasets import Dataset\n","# from thai2transformers.datasets import SequenceClassificationDataset\n","\n","class SequenceClassificationDataset(TorchDataset):\n","    def __init__(\n","        self,\n","        tokenizer,\n","        data_dir,\n","        task=Task.MULTICLASS_CLS,\n","        max_length=128,\n","        ext=\".csv\",\n","        bs=10000,\n","        preprocessor=None,\n","        input_ids=[],\n","        misp_ids=[],\n","        attention_masks=[],\n","        labels=[],\n","        label_encoder=None\n","    ):\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        self.bs = bs\n","        self.preprocessor = preprocessor\n","        self.input_ids = input_ids\n","        self.misp_ids = misp_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","        self.task = task\n","        self.label_encoder = label_encoder\n","        # self._build()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, i):\n","        return {\n","            \"input_ids\": torch.tensor(self.input_ids[i], dtype=torch.long),\n","            \"misp_ids\": torch.tensor(self.misp_ids[i], dtype=torch.long),\n","            \"attention_mask\": torch.tensor(self.attention_masks[i], dtype=torch.long),\n","            \"label\": torch.tensor(self.labels[i], dtype=torch.long),\n","        }\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Zxb64qIt674","executionInfo":{"status":"ok","timestamp":1638902647195,"user_tz":0,"elapsed":10,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vNqwl9Faiy65"},"source":["### Add additional tokens"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxf0j93vi25y","executionInfo":{"status":"ok","timestamp":1638902647648,"user_tz":0,"elapsed":463,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"55caaa3b-1fce-4ac8-d950-77ff724eb752"},"source":["tokenizer.add_tokens([\"<rep>\", \"<int>\", \"<misp>\", \"<lol>\"])\n","model.resize_token_embeddings(len(tokenizer)) "],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(25009, 768)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"XpkGqWoXj-4a","executionInfo":{"status":"ok","timestamp":1638902649117,"user_tz":0,"elapsed":1471,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["MD = load_jsonl(f\"{DIR}/../../train_mispelling_dection.jsonl\")[0]"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDMaHQ9hkB5n","executionInfo":{"status":"ok","timestamp":1638902649119,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxC53Pw1zQ-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638902677886,"user_tz":0,"elapsed":28773,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"70fe125d-70be-4554-9070-e78093b9553e"},"source":["from tqdm import tqdm \n","import itertools\n","from itertools import groupby\n","from collections import defaultdict\n","\n","LABELS = {\n","    \"neg\": 2,\n","    \"neu\": 1,\n","    \"pos\": 0,\n","    \"q\": 1 # used to be 3\n","}\n","\n","class CustomLabelEncoder():\n","    def __init__(self):\n","        pass\n","\n","    def transform(self, labels):\n","        return [LABELS[l] for l in labels]\n","    \n","\n","def remove_starting_marker(t, unk):\n","    if len(t) > 0:\n","      if t[0]=='▁':\n","        t = t[1:]\n","      elif t[0].startswith('▁'):        \n","        if tokenizer.convert_tokens_to_ids([t[0][1:]])[0] != unk:\n","          t[0] = t[0][1:]\n","    return t\n","\n","def norm_word(word, haha=False, notoken=False):\n","    groups = [list(s) for _, s in groupby(word)]\n","    ch = []\n","    extraToken = \"\"\n","    for g in groups:\n","        if len(g)>=3:\n","            if g[0]==\"5\" and haha:\n","              ch.append(\"555\")  \n","              extraToken = \"<lol>\"\n","            else:\n","              extraToken = \"<rep>\"\n","              ch.append(g[0])  \n","        else:\n","            ch += g\n","\n","    word = \"\".join(ch)+extraToken\n","    if notoken:\n","      word = \"\".join(ch)\n","    \n","    return word\n","\n","\n","def preprocessing(d, preSegmented=False, mode=None):\n","    max_length = 400\n","    custom_label_encoder = CustomLabelEncoder()\n","    labels = get_dict_val(d, \"category\")\n","\n","    labels = custom_label_encoder.transform(labels)\n","\n","    input_ids = []\n","    misp_ids = []\n","    attention_masks = []\n","    unk = tokenizer.convert_tokens_to_ids([\"<unk>\"])[0]\n","\n","    cnt = defaultdict(int)\n","    sents = []\n","    if not preSegmented:\n","      texts = get_dict_val(d, \"tokenized\")\n","      for tokens in tqdm(texts):\n","        tokens = [(t, t) for t in tokens]\n","        sents.append(tokens)\n","        \n","    else:\n","      texts = get_dict_val(d, \"segments\")\n","      for segments in tqdm(texts):\n","        s = [list(zip(seg[0], seg[1])) for seg in segments]\n","        tokens = list(itertools.chain(*s))\n","        sents.append(tokens)\n","\n","    for tokens in sents:\n","      # if mode is None, ignore corr\n","      cnt[\"tokens\"] += len(tokens)\n","      misptokens = [t[0] for t in tokens]\n","      corrtokens = [t[0] for t in tokens]\n","      \n","      if mode==\"corr\":\n","        misptokens = [t[1] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      elif mode==\"mae\":\n","        misptokens = [t[0] for t in tokens]\n","        corrtokens = [t[1] for t in tokens]\n","      \n","      \n","      midx = tokenizer.convert_tokens_to_ids(misptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(corrtokens)\n","      assert(len(midx)==len(cidx))\n","\n","      newmisptokens = []\n","      newcorrtokens = []\n","      for i in range(len(midx)):\n","          if midx[i]==unk:\n","              t = norm_word(misptokens[i], True, notoken=True)\n","              t = tokenizer.tokenize(t)\n","              t = remove_starting_marker(t, unk)\n","\n","              if misptokens[i]==corrtokens[i]:\n","                newmisptokens += t\n","                newcorrtokens += t\n","              else:\n","                newmisptokens += t\n","                tx = norm_word(corrtokens[i], True, notoken=True)\n","                tx = tokenizer.tokenize(tx)\n","                tx = remove_starting_marker(tx, unk)\n","\n","                if len(tx) > 0:\n","                  newcorrtokens += [tx[0] for j in range(len(t))]\n","                else:\n","                  newcorrtokens += t\n","          else:\n","              t = norm_word(misptokens[i], True, notoken=True)\n","              tx = norm_word(corrtokens[i], True, notoken=True)\n","\n","              newmisptokens.append(t)\n","              newcorrtokens.append(tx)\n","          \n","          norm = norm_word(misptokens[i])\n","          if \"<rep>\" in norm:\n","            n = norm_word(misptokens[i], True)\n","            if \"<rep>\" in n:\n","              newmisptokens.append(\"<rep>\")\n","              newcorrtokens.append(\"<rep>\")\n","              cnt[\"<rep>\"] += 1\n","            elif \"<lol>\" in n:\n","              newmisptokens.append(\"<lol>\")\n","              newcorrtokens.append(\"<lol>\")\n","              cnt[\"<lol>\"] += 1\n","\n","          if norm in MD:\n","            corr, mint = MD[norm]\n","            if mint:\n","              newmisptokens.append(\"<int>\")\n","              newcorrtokens.append(\"<int>\")\n","              cnt[\"<int>\"] += 1\n","            else:\n","              newmisptokens.append(\"<msp>\")\n","              newcorrtokens.append(\"<msp>\")\n","              cnt[\"<misp>\"] += 1\n","\n","      \n","            \n","      \n","      assert(len(newmisptokens)==len(newcorrtokens))\n","      cnt[\"extra\"] += (len(newmisptokens) - len(misptokens))\n","              \n","      # words = newwords\n","      newmisptokens = ['<s>'] + newmisptokens[0:max_length-2] + ['</s>']\n","      newcorrtokens = ['<s>'] + newcorrtokens[0:max_length-2] + ['</s>']\n","    \n","      midx = tokenizer.convert_tokens_to_ids(newmisptokens)\n","      cidx = tokenizer.convert_tokens_to_ids(newcorrtokens)\n","\n","      mask = [1 for i in midx]\n","        \n","      input_ids.append(midx)\n","      misp_ids.append(cidx)\n","      attention_masks.append(mask)\n","\n","    #   if len(input_ids) > 10:\n","    #     break\n","    \n","    # labels = labels[0:10]\n","\n","    for k in cnt:\n","      print(\"Number of\", k, cnt[k])\n","    return SequenceClassificationDataset(\n","        tokenizer=tokenizer,\n","        data_dir=None,\n","        max_length=max_length,\n","        input_ids=input_ids,\n","        misp_ids=misp_ids,\n","        attention_masks=attention_masks,\n","        labels=labels,\n","        task=task\n","    )\n","\n","raw_datasets = {\n","    \"train\": traindata,\n","    \"validation\": validdata,\n","    \"test\": allTestdata,\n","    \"test-corr\": corrTestdata,\n","    \"test-misp\": mispTestdata,\n","    \"test-mae\": mispTestdata,\n","    \"test-all-mae\": allTestdata,\n","}\n","\n","dataset_split = {}\n","for split_name in raw_datasets:\n","    print(\"Tokenizing:\", split_name)\n","    d = pd.DataFrame(raw_datasets[split_name])\n","    d = Dataset.from_pandas(d)\n","    preSegmented = split_name.startswith(\"test\")\n","    mode = None\n","    if \"corr\" in split_name:\n","      mode = \"corr\"\n","    elif \"misp\" in split_name:\n","      mode = \"misp\"\n","    elif \"mae\" in split_name:\n","      mode = \"mae\"\n","\n","    dataset_split[split_name] = preprocessing(d, preSegmented=preSegmented, mode=mode)\n","    # break"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing: train\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 21628/21628 [00:00<00:00, 144406.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 608957\n","Number of <misp> 3713\n","Number of extra 25553\n","Number of <int> 4043\n","Number of <rep> 4480\n","Number of <lol> 1636\n","Tokenizing: validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2404/2404 [00:00<00:00, 170216.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 67236\n","Number of <rep> 523\n","Number of <int> 441\n","Number of extra 2819\n","Number of <lol> 177\n","Number of <misp> 404\n","Tokenizing: test\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2671/2671 [00:00<00:00, 106245.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 74865\n","Number of <misp> 402\n","Number of extra 4227\n","Number of <int> 646\n","Number of <rep> 600\n","Number of <lol> 221\n","Tokenizing: test-corr\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 127972.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of extra 556\n","Number of <misp> 124\n","Number of <int> 96\n","Number of <rep> 82\n","Number of <lol> 73\n","Tokenizing: test-misp\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 117836.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of <misp> 157\n","Number of extra 1664\n","Number of <int> 485\n","Number of <rep> 324\n","Number of <lol> 72\n","Tokenizing: test-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 880/880 [00:00<00:00, 129996.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 22224\n","Number of <misp> 157\n","Number of extra 1664\n","Number of <int> 485\n","Number of <rep> 324\n","Number of <lol> 72\n","Tokenizing: test-all-mae\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2671/2671 [00:00<00:00, 90516.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of tokens 74865\n","Number of <misp> 402\n","Number of extra 4227\n","Number of <int> 646\n","Number of <rep> 600\n","Number of <lol> 221\n"]}]},{"cell_type":"code","metadata":{"id":"zTo1InxM7QlH","executionInfo":{"status":"ok","timestamp":1638902677886,"user_tz":0,"elapsed":8,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":[""],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pVpOylu-CrqE"},"source":["## Custom Classes for Our Experiments"]},{"cell_type":"code","metadata":{"id":"wHqjltTIEdzZ","executionInfo":{"status":"ok","timestamp":1638902678350,"user_tz":0,"elapsed":26,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_roberta import RobertaEmbeddings"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q5iZsOgEd2P","executionInfo":{"status":"ok","timestamp":1638902678352,"user_tz":0,"elapsed":26,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from torch import nn\n","\n","class CustomRobertaEmbeddings(RobertaEmbeddings):\n","\n","    def __init__(self, ref, config):\n","        super().__init__(config)\n","        self.word_embeddings = ref.word_embeddings\n","\n","    def forward(self, input_ids, misp_ids, token_type_ids=None, position_ids=None, inputs_embeds=None):\n","\n","        input_shape = input_ids.size()\n","        seq_length = input_shape[1]\n","\n","        inputs_embeds = self.word_embeddings(input_ids)\n","        misp_embeds = self.word_embeddings(misp_ids)\n","\n","        embeddings = ((inputs_embeds + misp_embeds)*0.5)\n","        return embeddings\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"WL_oBhOdHTjt","executionInfo":{"status":"ok","timestamp":1638902678353,"user_tz":0,"elapsed":26,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_roberta import RobertaModel"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew6s3Y1f1vCa","executionInfo":{"status":"ok","timestamp":1638902678354,"user_tz":0,"elapsed":26,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from transformers.modeling_camembert import CamembertForSequenceClassification\n","from transformers.modeling_roberta import RobertaForSequenceClassification\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","\n","class CustomSequenceClassification(CamembertForSequenceClassification):\n","    authorized_missing_keys = [r\"position_ids\"]\n","\n","    def __init__(self, config, refmodel=None):\n","        super().__init__(config)\n","        if refmodel is not None:\n","          config = refmodel.config\n","          # self.refmodel = refmodel\n","          self.num_labels = config.num_labels\n","\n","          self.roberta = refmodel.roberta\n","          self.classifier = refmodel.classifier\n","\n","          self.baseEmb = refmodel.roberta.embeddings\n","          self.newEmb = CustomRobertaEmbeddings(self.baseEmb, config)\n","\n","    def forward(self, *args, **kwargs):\n","        # del kwargs[\"misp_ids\"]\n","        # return self.refmodel(**kwargs)\n","\n","        return_dict = self.config.use_return_dict\n","\n","        inputs_embeds = self.newEmb(kwargs[\"input_ids\"], kwargs[\"misp_ids\"])\n","        \n","        # doc: https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaModel.forward\n","        outputs = self.roberta(\n","            input_ids=None,\n","            attention_mask=kwargs[\"attention_mask\"],\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        labels = kwargs[\"labels\"]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"lznRUPu1YJSA","executionInfo":{"status":"ok","timestamp":1638902678356,"user_tz":0,"elapsed":27,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["# cusmodel = CustomSequenceClassification(model.config, model)\n","# trainer, training_args = init_trainer(task=task,\n","#                             model=cusmodel,\n","#                             train_dataset=dataset_split['train'],\n","#                             val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","#                             warmup_steps=warmup_steps,\n","#                             args=args,\n","#                             data_collator=data_collator)\n","\n","# p, label_ids, result = trainer.predict(test_dataset=dataset_split['test'])\n","\n","# print(f'Evaluation on test set (dataset: {args.dataset_name})')    \n","\n","# for key, value in result.items():\n","#     print(f'{key} : {value:.4f}')\n","\n","# # Evaluation on test set (dataset: wisesight_sentiment)\n","# # eval_loss : 1.0284\n","# # eval_accuracy : 0.3000\n","# # eval_f1_micro : 0.3000\n","# # eval_precision_micro : 0.3000\n","# # eval_recall_micro : 0.3000\n","# # eval_f1_macro : 0.1667\n","# # eval_precision_macro : 0.1667\n","# # eval_recall_macro : 0.1667\n","# # eval_nb_samples : 10.0000"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDP2AEpDCqXh","executionInfo":{"status":"ok","timestamp":1638902678357,"user_tz":0,"elapsed":27,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}}},"source":["from dataclasses import dataclass\n","from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n","from transformers import PreTrainedTokenizerBase\n","\n","@dataclass\n","class CustomDataCollatorWithPadding:\n","  tokenizer: PreTrainedTokenizerBase\n","  padding: Union[bool, str] = True\n","  max_length: Optional[int] = None\n","  pad_to_multiple_of: Optional[int] = None\n","  return_tensors: str = \"pt\"\n","\n","  def __call__(self, features):\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"input_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","\n","    batch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    _tmpfeat = []\n","    for f in features:\n","      _tmpfeat.append({\n","          \"input_ids\": f[\"misp_ids\"],\n","          \"attention_mask\": f[\"attention_mask\"],\n","          \"label\": f[\"label\"],\n","      })\n","      \n","    mispbatch = self.tokenizer.pad(\n","        _tmpfeat,\n","        padding=self.padding,\n","        max_length=self.max_length,\n","        pad_to_multiple_of=self.pad_to_multiple_of,\n","        # return_tensors=self.return_tensors,\n","    )\n","\n","    # print(mispbatch[\"input_ids\"])\n","    # print(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][0]))\n","    # print(tokenizer.convert_ids_to_tokens(mispbatch[\"input_ids\"][0]))\n","    batch[\"misp_ids\"] = mispbatch[\"input_ids\"]\n","    assert(batch[\"misp_ids\"].shape==batch[\"input_ids\"].shape)\n","    # assert()\n","    if \"label\" in batch:\n","        batch[\"labels\"] = batch[\"label\"]\n","        del batch[\"label\"]\n","    if \"label_ids\" in batch:\n","        batch[\"labels\"] = batch[\"label_ids\"]\n","        del batch[\"label_ids\"]\n","    return batch"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_D7scYkC0Jg"},"source":["# Model Training "]},{"cell_type":"code","metadata":{"id":"Dx6AsnFmeQlM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638902684421,"user_tz":0,"elapsed":6090,"user":{"displayName":"Pakawat Nakwijit","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01430675152978466058"}},"outputId":"cd1c23f5-afd8-4103-ca63-35a3fc5e8032"},"source":["warmup_steps = math.ceil(len(dataset_split['train']) / args.batch_size * args.warmup_ratio * args.num_train_epochs)\n","\n","print(f'\\n[INFO] Number of train examples = {len(raw_datasets[\"train\"])}')\n","print(f'[INFO] Number of batches per epoch (training set) = {math.ceil(len(dataset_split[\"train\"]) / args.batch_size)}')\n","\n","print(f'[INFO] Warmup ratio = {args.warmup_ratio}')\n","print(f'[INFO] Warmup steps = {warmup_steps}')\n","print(f'[INFO] Learning rate: {args.learning_rate}')\n","print(f'[INFO] Logging steps: {args.logging_steps}')\n","print(f'[INFO] FP16 training: {args.fp16}\\n')\n","\n","# if 'validation' in DATASET_METADATA[args.dataset_name]['split_names']:\n","print(f'[INFO] Number of validation examples = {len(raw_datasets[\"validation\"])}')\n","print(f'[INFO] Number of batches per epoch (validation set) = {math.ceil(len(dataset_split[\"validation\"]))}')\n","\n","data_collator = CustomDataCollatorWithPadding(tokenizer,\n","                                        padding=True,\n","                                        pad_to_multiple_of=8 if args.fp16 else None)\n","\n","cusmodel = CustomSequenceClassification(model.config, model)\n","trainer, training_args = init_trainer(task=task,\n","                            model=cusmodel,\n","                            train_dataset=dataset_split['train'],\n","                            val_dataset=dataset_split['validation'] if 'validation' in DATASET_METADATA[args.dataset_name]['split_names'] else None,\n","                            warmup_steps=warmup_steps,\n","                            args=args,\n","                            data_collator=data_collator)\n","\n","print('[INFO] TrainingArguments:')\n","print(training_args)\n","print('\\n')"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] Number of train examples = 21628\n","[INFO] Number of batches per epoch (training set) = 2704\n","[INFO] Warmup ratio = 0.1\n","[INFO] Warmup steps = 2704\n","[INFO] Learning rate: 1e-05\n","[INFO] Logging steps: 10\n","[INFO] FP16 training: False\n","\n","[INFO] Number of validation examples = 2404\n","[INFO] Number of batches per epoch (validation set) = 2404\n","[INFO] TrainingArguments:\n","TrainingArguments(output_dir='Models/WangchanBERTa-exp2/Outputs/', overwrite_output_dir=True, do_train=False, do_eval=None, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, warmup_steps=2704, logging_dir='Models/WangchanBERTa-exp2/Logs/', logging_first_step=False, logging_steps=10, save_steps=500, save_total_limit=None, no_cuda=False, seed=0, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name='exp1', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='f1_micro', greater_is_better=True)\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"O8TTQ7VmQGhS","outputId":"dd9d49b8-3395-4bf3-d7e4-f2e7f1b30b36"},"source":["print('\\nBegin model finetuning.')\n","trainer.train()\n","print('Done.\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Begin model finetuning.\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='15087' max='27040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15087/27040 1:38:36 < 1:18:07, 2.55 it/s, Epoch 5.58/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Micro</th>\n","      <th>Precision Micro</th>\n","      <th>Recall Micro</th>\n","      <th>F1 Macro</th>\n","      <th>Precision Macro</th>\n","      <th>Recall Macro</th>\n","      <th>Nb Samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.769214</td>\n","      <td>0.729812</td>\n","      <td>0.687188</td>\n","      <td>0.687188</td>\n","      <td>0.687188</td>\n","      <td>0.687188</td>\n","      <td>0.585256</td>\n","      <td>0.624538</td>\n","      <td>0.588006</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.687939</td>\n","      <td>0.692171</td>\n","      <td>0.712978</td>\n","      <td>0.712978</td>\n","      <td>0.712978</td>\n","      <td>0.712978</td>\n","      <td>0.645933</td>\n","      <td>0.672079</td>\n","      <td>0.636792</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.634619</td>\n","      <td>0.657828</td>\n","      <td>0.735025</td>\n","      <td>0.735025</td>\n","      <td>0.735025</td>\n","      <td>0.735025</td>\n","      <td>0.682485</td>\n","      <td>0.695026</td>\n","      <td>0.676673</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.542285</td>\n","      <td>0.704776</td>\n","      <td>0.737521</td>\n","      <td>0.737521</td>\n","      <td>0.737521</td>\n","      <td>0.737521</td>\n","      <td>0.682171</td>\n","      <td>0.704211</td>\n","      <td>0.670148</td>\n","      <td>2404</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.609180</td>\n","      <td>0.724451</td>\n","      <td>0.740433</td>\n","      <td>0.740433</td>\n","      <td>0.740433</td>\n","      <td>0.740433</td>\n","      <td>0.685512</td>\n","      <td>0.704652</td>\n","      <td>0.674488</td>\n","      <td>2404</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"K63mJONBgbiB"},"source":["trainer.save_model(f\"{DIR}/fine-tune-Exp2\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIwrxhH2cLsR"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"lRczslIwcNmh"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-iWxTbYZKh4"},"source":["assert(torch.equal(model.classifier.dense.weight, trainer.model.classifier.dense.weight))\n","trainer.model = CustomSequenceClassification(model.config, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjcp02iSgYgC"},"source":["trainer.model.eval();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAOts0QgwKba"},"source":["\n","for split_name in dataset_split:\n","  if split_name.startswith(\"train\"):\n","    continue\n","\n","  p, label_ids, result = trainer.predict(test_dataset=dataset_split[split_name])\n","  print(f'Evaluation on {split_name}:')    \n","\n","  for key, value in result.items():\n","      print(f'{key} : {value:.4f}')\n","  \n","  print(\"*\"*40)\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZv8Xs1F674m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bo7F93aYDNUQ"},"source":[""],"execution_count":null,"outputs":[]}]}