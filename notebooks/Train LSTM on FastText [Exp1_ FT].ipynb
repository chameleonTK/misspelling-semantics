{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train LSTM on FastText [Exp1: FT].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c857e040977b4e66a54cb63642e03b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f83e50f0f88e4b89b57e74fc0f2bac70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a56b8d1834cf4554bba6199ca1f5b91c",
              "IPY_MODEL_1a1fb13be2164e34bac3e2c2f8ae0e26",
              "IPY_MODEL_02ab71884e434472b765aa7481583a82"
            ]
          }
        },
        "f83e50f0f88e4b89b57e74fc0f2bac70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a56b8d1834cf4554bba6199ca1f5b91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f75f909cab24d00b366fd7b54fd17a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bf55b01be1c45b9aa0879f8ede0c03a"
          }
        },
        "1a1fb13be2164e34bac3e2c2f8ae0e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aeffa2e5fe124536a962352cef73b18f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 44697,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 44697,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_585441cab9fb48d1bc66c6a643f497cd"
          }
        },
        "02ab71884e434472b765aa7481583a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3c6264650f141b8a1164df27680a39f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44697/44697 [00:02&lt;00:00, 24612.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd2b1266ba1241faa038fc2e36f77202"
          }
        },
        "9f75f909cab24d00b366fd7b54fd17a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bf55b01be1c45b9aa0879f8ede0c03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aeffa2e5fe124536a962352cef73b18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "585441cab9fb48d1bc66c6a643f497cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3c6264650f141b8a1164df27680a39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd2b1266ba1241faa038fc2e36f77202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c638a98b2dde41d58efb4a0dce0118df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ca3ba6ec68b41cc86129e49587589e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c3e8d3b201b4fb6a5c1af0a78795d30",
              "IPY_MODEL_2203a36374e949cbaf0ba2c60f404cef",
              "IPY_MODEL_c10f45a8307b4602acabd8b3e0bd0308"
            ]
          }
        },
        "6ca3ba6ec68b41cc86129e49587589e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c3e8d3b201b4fb6a5c1af0a78795d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1df80ebd62874ebe82e2eea7b6e6aef6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92058ecb95524fbdbcce1d362ad6f8fe"
          }
        },
        "2203a36374e949cbaf0ba2c60f404cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79780c0d0724424b80de0c4de1f1055c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16900,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16900,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c456ae649f34faa82253c74e82c33cc"
          }
        },
        "c10f45a8307b4602acabd8b3e0bd0308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64d6a7eee3664062bc6dd8dbd22a82c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16900/16900 [26:38&lt;00:00,  1.29s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a6663e2ef9346459b5500c8455ae14d"
          }
        },
        "1df80ebd62874ebe82e2eea7b6e6aef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92058ecb95524fbdbcce1d362ad6f8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79780c0d0724424b80de0c4de1f1055c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c456ae649f34faa82253c74e82c33cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64d6a7eee3664062bc6dd8dbd22a82c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a6663e2ef9346459b5500c8455ae14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3afa313cfd4b46d69428b181908ea984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f527ef92e1a424d8e7a39978a7e1528",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b5dc29a07f940e0b817b7f36e909c2f",
              "IPY_MODEL_1d1faddecb5c442fa1578df785c34fe9",
              "IPY_MODEL_7f0c612525ce4e2caf2a35a204e43aeb"
            ]
          }
        },
        "8f527ef92e1a424d8e7a39978a7e1528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b5dc29a07f940e0b817b7f36e909c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5735fadbd6c9492c9cfc708a217b19e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_393f0934bcf24e25b5748908bda28e2c"
          }
        },
        "1d1faddecb5c442fa1578df785c34fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43894d1b2fa14e0b8f136ab999b8d45f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16900,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16900,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ef59b06c1274b0594303f165eca353d"
          }
        },
        "7f0c612525ce4e2caf2a35a204e43aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a01e382c194d4b3da7e2d80b9947f187",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16900/16900 [27:25&lt;00:00,  1.33s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6a2dc3961074395a9748f4794e2bd7f"
          }
        },
        "5735fadbd6c9492c9cfc708a217b19e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "393f0934bcf24e25b5748908bda28e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43894d1b2fa14e0b8f136ab999b8d45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ef59b06c1274b0594303f165eca353d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a01e382c194d4b3da7e2d80b9947f187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6a2dc3961074395a9748f4794e2bd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm5ID9-w8lPF",
        "outputId": "e091deea-daf1-4403-c1a5-412c4ff4dc03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn_3IlRA8yGI",
        "outputId": "cc766661-df9c-47c9-cf67-636febc0b8a3"
      },
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72RbIPGQ83em",
        "outputId": "fc9206c3-8fe7-469e-da45-6694cfe17372"
      },
      "source": [
        "!pip install fastText"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastText\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fastText) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastText) (1.19.5)\n",
            "Building wheels for collected packages: fastText\n",
            "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastText: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3121271 sha256=34dee338d0509444b432302480baf47d02c49e8b84d5110ceb7aefdf42626246\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fastText\n",
            "Installing collected packages: pybind11, fastText\n",
            "Successfully installed fastText-0.9.2 pybind11-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvFY4jen9FeH"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh7kO1ITXstw"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwg5qj2hXuXY"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_jsonl(fname):\n",
        "    fin = open(fname, encoding=\"utf-8\")\n",
        "    data = []\n",
        "    for line in fin:\n",
        "        d = json.loads(line.strip())\n",
        "        data.append(d)\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_jsonl(data, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as fo:\n",
        "        for idx, d in enumerate(data):\n",
        "            fo.write(json.dumps(d, ensure_ascii=False))\n",
        "            fo.write(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TDqQCb6XuZ9"
      },
      "source": [
        "DIR = \"Mispelling/misspelling-semantics/Datasets/\"\n",
        "traindata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_train.jsonl\")\n",
        "validdata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_valid.jsonl\")\n",
        "testdata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_test-misp.jsonl\")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyOZj9z3Xucz"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHwGnDPRZ4hw",
        "outputId": "ed3ea2ca-0fcc-47e0-d33a-6f2d9b11f4e2"
      },
      "source": [
        "import itertools\n",
        "def filterByMode(data, mode=None):\n",
        "  output = []\n",
        "  for sent in data:\n",
        "    if mode is None:\n",
        "      tokenized = [seg[0] for seg in sent[\"segments\"]]\n",
        "    elif mode==\"corr\":\n",
        "      tokenized = [seg[1] for seg in sent[\"segments\"]]\n",
        "      if len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "    else:\n",
        "      tokenized = [seg[0] for seg in sent[\"segments\"]]\n",
        "      if len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "    \n",
        "    tokenized = list(itertools.chain(*tokenized))\n",
        "  \n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": tokenized,\n",
        "        \"segments\": sent[\"segments\"]\n",
        "    })\n",
        "\n",
        "  return output\n",
        "\n",
        "traindata\n",
        "validdata\n",
        "allTestdata = filterByMode(testdata)\n",
        "corrTestdata = filterByMode(testdata, \"corr\")\n",
        "mispTestdata = filterByMode(testdata, \"misp\")\n",
        "len(allTestdata), len(corrTestdata), len(mispTestdata)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2671, 880, 880)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb3VQndoXufR"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn_-ONCtXuiL"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_xmhIYTFx_V"
      },
      "source": [
        "# Create LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgmoytS4FzJU"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import os\n",
        "\n",
        "seed = 0\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)    \n",
        "np.random.seed(seed)\n",
        "np.random.RandomState(seed)\n",
        "\n",
        "torch.manual_seed(seed) \n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) #seed all gpus    \n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.enabled = False  \n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THSE3QKF2am",
        "outputId": "ffb43e36-d0d8-447d-aa83-812d557a67cb"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAy_zT-OF9o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6243f4-51cc-40e1-e97b-578aa4d6a958"
      },
      "source": [
        "!pip install -q pythainlp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 11.0 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 50.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtrQwukcF4R1"
      },
      "source": [
        "import pythainlp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6N_idH_GCx3"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = ArgumentParser(description='LSTM')\n",
        "#     parser.add_argument('mode', type=str, help = 'tokenizing mode ')\n",
        "    parser.add_argument('--epochs', type=int, default=50, help = 'epochs')\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--d_embed', type=int, default=100)\n",
        "    parser.add_argument('--lr', type=float, default=.001)\n",
        "    parser.add_argument('--dev_every', type=int, default=100)\n",
        "    parser.add_argument('--dp_ratio', type=int, default=0.2)\n",
        "    parser.add_argument('--save_path', type=str, default='results', help='path to save the model')\n",
        "    \n",
        "    try:\n",
        "        args = parser.parse_args([])\n",
        "    except:\n",
        "        parser.print_help()\n",
        "        sys.exit(1)\n",
        "\n",
        "    return args"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjR17JHGC1B"
      },
      "source": [
        "               \n",
        "args = get_args()\n",
        "args.epochs = 50\n",
        "args.batch_size = 64\n",
        "args.dev_every = 50"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFN-roz-F803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6090c43f-a6f2-4465-ea3e-f82dbf775eb7"
      },
      "source": [
        "wv = fasttext.load_model(f\"{DIR}/../Models/cc.th.300.bin\")\n",
        "# wv = fasttext.load_model(f\"Mispelling/Models/fasttext_orcl.bin\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4enmKUubyCyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24e7ec63-c041-4773-e6c8-a1f62ca7f4fa"
      },
      "source": [
        "\"DONE\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DONE'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju3fwxglivDc"
      },
      "source": [
        "### Build Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYyZnlN-jt9Y"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsp-eb2Jju8K"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhO-MElGkNEy"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRShhllxAP-v"
      },
      "source": [
        "#### Baseline Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxRdZ1PyjzQF"
      },
      "source": [
        "LABELS = {\n",
        "    \"neg\": 2,\n",
        "    \"neu\": 1,\n",
        "    \"pos\": 0,\n",
        "    \"q\": 1 # used to be 3\n",
        "}\n",
        "\n",
        "def removeQuestion(label):    \n",
        "  return LABELS[label]\n",
        "\n",
        "# TEXT = data.Field(sequential=True, lower=False)\n",
        "CATEGORY = data.Field(sequential=False, use_vocab=False, preprocessing=removeQuestion)\n",
        "TOKEN = data.Field(sequential=True, lower=False)\n",
        "\n",
        "raw_datasets = {\n",
        "    \"train\": traindata,\n",
        "    \"validation\": validdata,\n",
        "    \"test\": allTestdata,\n",
        "    \"test-corr\": corrTestdata,\n",
        "    \"test-misp\": mispTestdata\n",
        "}\n",
        "\n",
        "raw_fields = [\n",
        "    # ('text', TEXT), \n",
        "    ('category', CATEGORY),\n",
        "    ('tokenized', TOKEN)\n",
        "]\n",
        "\n",
        "fields = {}\n",
        "for f in raw_fields:\n",
        "  fields[f[0]] = f\n",
        "\n",
        "datasets = {}\n",
        "for k in raw_datasets:  \n",
        "  examples = [data.Example.fromdict(d, fields=fields) for d in raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=raw_fields)\n",
        "  datasets[k] = d\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhKqE2ZQAYck"
      },
      "source": [
        "#### MAE Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EoG-XP7GO2E"
      },
      "source": [
        "# "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ7zViqs_qRV",
        "outputId": "393ccee9-ca72-4902-81f1-5803fdee4800"
      },
      "source": [
        "MC = load_jsonl(f\"{DIR}/../test_mispelling_correction.jsonl\")[0]\n",
        "def createMAEDataset(data, pre_segmented=False, mode=None, mst=False):\n",
        "  output = []\n",
        "  cnt, mstcnt = 0, 0\n",
        "\n",
        "  segIdx = 0\n",
        "  if mode==\"corr\":\n",
        "    segIdx = 1  # ignore misspelling with MC\n",
        "\n",
        "  for sent in data:\n",
        "    newtokens = []\n",
        "    misptokens = []\n",
        "    if (mode==\"misp\" or mode==\"corr\") and len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "\n",
        "    if pre_segmented:\n",
        "      for seg in sent[\"segments\"]:\n",
        "        for token in zip(seg[0], seg[1]):\n",
        "          newtokens.append(token[segIdx])\n",
        "          misptokens.append(token[1])\n",
        "          if mst:\n",
        "            msttokens = additionalToken(token[segIdx])\n",
        "            newtokens += msttokens\n",
        "            misptokens += msttokens\n",
        "\n",
        "          if token[0]!=token[1]:\n",
        "            mstcnt += 1\n",
        "          \n",
        "    else:\n",
        "      \n",
        "      for token in sent[\"tokenized\"]:\n",
        "        w = norm_word(token)\n",
        "        detectedMsp = (len(w) >= 4) and (w in MC)\n",
        "        if detectedMsp:\n",
        "            corr, mint = MC[w]\n",
        "            misptokens.append(corr)\n",
        "            if mode==\"corr\":\n",
        "              token = corr\n",
        "            mstcnt += 1\n",
        "        else:\n",
        "          misptokens.append(token)\n",
        "        newtokens.append(token)\n",
        "\n",
        "        if detectedMsp and mst:\n",
        "          msttokens = additionalToken(token)\n",
        "          newtokens += msttokens\n",
        "          misptokens += msttokens\n",
        "\n",
        "\n",
        "    cnt += len(newtokens)\n",
        "\n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": newtokens,\n",
        "        \"misp\": misptokens\n",
        "    })\n",
        "\n",
        "  print(f\"#Misp Tokens: {mstcnt} tokens; {(mstcnt)*100/cnt:.2f}%\")\n",
        "  return output\n",
        "\n",
        "mae_raw_datasets = {\n",
        "    \"test\": createMAEDataset(testdata, pre_segmented=True),\n",
        "    \"test-corr\": createMAEDataset(testdata, pre_segmented=True, mode=\"corr\"),\n",
        "    \"test-misp\": createMAEDataset(testdata, pre_segmented=True, mode=\"misp\"),\n",
        "}\n",
        "\n",
        "mae_raw_fields = [\n",
        "    ('category', CATEGORY),\n",
        "    ('tokenized', TOKEN),\n",
        "    ('misp', TOKEN),\n",
        "]\n",
        "\n",
        "mae_fields = {}\n",
        "for f in mae_raw_fields:\n",
        "  mae_fields[f[0]] = f\n",
        "\n",
        "print()\n",
        "MAEdatasets = {}\n",
        "for k in mae_raw_datasets:  \n",
        "  print(f\"Processed: {k}\")\n",
        "  examples = [data.Example.fromdict(d, fields=mae_fields) for d in mae_raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=mae_raw_fields)\n",
        "  MAEdatasets[k] = d\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Misp Tokens: 1213 tokens; 1.67%\n",
            "#Misp Tokens: 1213 tokens; 5.60%\n",
            "#Misp Tokens: 1213 tokens; 5.60%\n",
            "\n",
            "Processed: test\n",
            "Processed: test-corr\n",
            "Processed: test-misp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emulYYp-AbER"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGje3d7QAcnN"
      },
      "source": [
        "#### MST Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC1nGGMfAgcH"
      },
      "source": [
        "from itertools import groupby\n",
        "MD = load_jsonl(f\"{DIR}/../train_mispelling_dection.jsonl\")[0]\n",
        "\n",
        "def norm_word(word):\n",
        "    groups = [list(s) for _, s in groupby(word)]\n",
        "    ch = []\n",
        "    extraToken = \"\"\n",
        "    for g in groups:\n",
        "        if len(g)>=3:\n",
        "            if g[0]==\"5\":\n",
        "              extraToken = \"<lol>\"\n",
        "            else:\n",
        "              extraToken = \"<rep>\"\n",
        "            ch.append(g[0])  \n",
        "        else:\n",
        "            ch += g\n",
        "    word = \"\".join(ch)+extraToken\n",
        "    return word\n",
        "\n",
        "def additionalToken(word):\n",
        "  tokens = []\n",
        "  w = norm_word(word)\n",
        "  if \"<lol>\" in w:\n",
        "    tokens.append(\"<lol>\")\n",
        "  elif \"<rep>\" in w:\n",
        "    tokens.append(\"<rep>\")\n",
        "  elif w in MD:\n",
        "      corr, mint = MD[w]\n",
        "      if mint:\n",
        "        tokens.append(\"<int>\")\n",
        "      else:\n",
        "        tokens.append(\"<msp>\")\n",
        "  return tokens\n",
        "\n",
        "def addMSTTokens(data, pre_segmented=False):\n",
        "  output = []\n",
        "  cnt, mstcnt = 0, 0\n",
        "  for sent in data:\n",
        "    newtokens = []\n",
        "    if pre_segmented:\n",
        "      for seg in sent[\"segments\"]:\n",
        "        for token in zip(seg[0], seg[1]):\n",
        "          newtokens.append(token[0])\n",
        "          if token[0]==token[1]:\n",
        "            continue\n",
        "          \n",
        "          newtokens += additionalToken(token[0])\n",
        "    else:\n",
        "      for token in sent[\"tokenized\"]:\n",
        "        newtokens.append(token)\n",
        "        # if len(w) < 4:\n",
        "        #   continue\n",
        "        newtokens += additionalToken(token[0])\n",
        "\n",
        "    cnt += len(sent[\"tokenized\"])\n",
        "    mstcnt += len(newtokens)\n",
        "\n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": newtokens,\n",
        "    })\n",
        "\n",
        "  print(f\"#New MST Tokens: {mstcnt - cnt} tokens; {(mstcnt - cnt)*100/cnt:.2f}%\")\n",
        "  return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtP3z6LAghg",
        "outputId": "6446c35e-d5a6-406c-f360-88f6e40a95b2"
      },
      "source": [
        "MSTdatasets = {}\n",
        "for k in raw_datasets:\n",
        "  print(f\"Processed: {k}\")\n",
        "  raw = addMSTTokens(raw_datasets[k], pre_segmented=k.startswith(\"test\"))  #only pre-segmented in test set\n",
        "  examples = [data.Example.fromdict(d, fields=fields) for d in raw]\n",
        "  d = data.Dataset(examples, fields=raw_fields)\n",
        "  MSTdatasets[k] = d\n",
        "  print(\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: train\n",
            "#New MST Tokens: 19356 tokens; 3.18%\n",
            "\n",
            "Processed: validation\n",
            "#New MST Tokens: 2147 tokens; 3.19%\n",
            "\n",
            "Processed: test\n",
            "#New MST Tokens: 616 tokens; 0.85%\n",
            "\n",
            "Processed: test-corr\n",
            "#New MST Tokens: 616 tokens; 2.84%\n",
            "\n",
            "Processed: test-misp\n",
            "#New MST Tokens: 616 tokens; 2.84%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602D1D4zIlb4"
      },
      "source": [
        "# Both"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRT0CD47InJQ"
      },
      "source": [
        "#### MAE+MST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX8pevvm_qgI",
        "outputId": "1515b139-5efd-44d7-f944-fb89c51eb9fc"
      },
      "source": [
        "both_raw_datasets = {\n",
        "    \"test\": createMAEDataset(testdata, pre_segmented=True, mst=True),\n",
        "    \"test-corr\": createMAEDataset(testdata, pre_segmented=True, mode=\"corr\", mst=True),\n",
        "    \"test-misp\": createMAEDataset(testdata, pre_segmented=True, mode=\"misp\", mst=True),\n",
        "}\n",
        "print()\n",
        "BOTHdataset = {}\n",
        "for k in both_raw_datasets:  \n",
        "  print(f\"Processed: {k}\")\n",
        "  examples = [data.Example.fromdict(d, fields=mae_fields) for d in both_raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=mae_raw_fields)\n",
        "  BOTHdataset[k] = d\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Misp Tokens: 1213 tokens; 1.63%\n",
            "#Misp Tokens: 1213 tokens; 5.50%\n",
            "#Misp Tokens: 1213 tokens; 5.37%\n",
            "\n",
            "Processed: test\n",
            "Processed: test-corr\n",
            "Processed: test-misp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JchrrW2I_lp"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EZ0-SC9I_tV"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60NoKoMOt9fN"
      },
      "source": [
        "W2V_WINDOW = 5 \n",
        "W2V_MIN_COUNT = 0\n",
        "\n",
        "# TEXT.build_vocab(datasets[\"train\"], min_freq=W2V_MIN_COUNT, )\n",
        "TOKEN.build_vocab(datasets[\"train\"], datasets[\"validation\"], datasets[\"test\"], datasets[\"test-corr\"], MSTdatasets[\"test\"], min_freq=W2V_MIN_COUNT, )\n",
        "CATEGORY.build_vocab(datasets[\"train\"])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3V6AoPpDxgN",
        "outputId": "69b66bfe-590b-45a1-9c53-73327a604eb2"
      },
      "source": [
        "\"#Token\",len(TOKEN.vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('#Token', 44697)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NjPc0lJscK_",
        "outputId": "62fd9b9c-d11d-447d-c0aa-e5c021cf26cb"
      },
      "source": [
        "CATEGORY.vocab.stoi"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f58c88912d0>>,\n",
              "            {0: 3, 1: 1, 2: 2, '<unk>': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2DamUhtGgIZ"
      },
      "source": [
        "import fasttext\n",
        "\n",
        "# ref: https://medium.com/@rohit_agrawal/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd\n",
        "def set_wv_vectors(field, vectors, debug=False):\n",
        "    W2V_SIZE = vectors.get_dimension()\n",
        "    \n",
        "    words = vectors.get_words()\n",
        "    vocab_size = len(words)\n",
        "    word2vec_vectors = []\n",
        "    for token, idx in tqdm(field.vocab.stoi.items()):\n",
        "        if idx==0:\n",
        "            word2vec_vectors.append(torch.zeros(W2V_SIZE))\n",
        "            continue\n",
        "            \n",
        "        word2vec_vectors.append(torch.FloatTensor(vectors[token]))\n",
        "\n",
        "    field.vocab.set_vectors(field.vocab.stoi, word2vec_vectors, W2V_SIZE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c857e040977b4e66a54cb63642e03b8f",
            "f83e50f0f88e4b89b57e74fc0f2bac70",
            "a56b8d1834cf4554bba6199ca1f5b91c",
            "1a1fb13be2164e34bac3e2c2f8ae0e26",
            "02ab71884e434472b765aa7481583a82",
            "9f75f909cab24d00b366fd7b54fd17a4",
            "4bf55b01be1c45b9aa0879f8ede0c03a",
            "aeffa2e5fe124536a962352cef73b18f",
            "585441cab9fb48d1bc66c6a643f497cd",
            "e3c6264650f141b8a1164df27680a39f",
            "bd2b1266ba1241faa038fc2e36f77202"
          ]
        },
        "id": "rh-KH7HCH_Ku",
        "outputId": "6ccd0c64-c6bb-4347-f929-f898b1540550"
      },
      "source": [
        "set_wv_vectors(TOKEN, wv)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c857e040977b4e66a54cb63642e03b8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/44697 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_GDSnh3zoob"
      },
      "source": [
        "del wv"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVZ8o5AAztg0",
        "outputId": "e532b0ca-336a-4578-fe39-1dade91e073a"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdiLcxWgH_2O"
      },
      "source": [
        "train_iter, validation_iter, test_iter = data.BucketIterator.splits(\n",
        "    (datasets[\"train\"], datasets[\"validation\"], datasets[\"test\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "    \n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuk1Ym5KIZ1o"
      },
      "source": [
        "def evaluate(loader, model, return_pred=False):\n",
        "    model.eval()\n",
        "    loader.sort = False\n",
        "    loader.sort_within_batch = False\n",
        "    loader.init_epoch()\n",
        "\n",
        "    # calculate accuracy on validation set\n",
        "    n_correct, n = 0, 0\n",
        "    losses = []\n",
        "    answers = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            answer = model(batch)\n",
        "            answers.append((answer, batch.category))\n",
        "            n_correct += (torch.max(answer, 1)[1].view(batch.category.size()) == batch.category).sum().item()\n",
        "            n += answer.shape[0]\n",
        "            loss = criterion(answer, batch.category)\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "    acc = 100. * n_correct / n\n",
        "    loss = np.mean(losses)\n",
        "    \n",
        "    if not return_pred:\n",
        "        return acc, loss\n",
        "    \n",
        "    \n",
        "    predict = torch.cat([a for a,_ in answers])\n",
        "    labels = torch.cat([a for _,a in answers])\n",
        "    return acc, loss, predict, labels"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq-WgDqKIbug"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_out, d_ff=256, dropout = 0.1):\n",
        "        super().__init__() \n",
        "        # We set d_ff as a default to 256\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_out)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_embed=10000,\n",
        "                 d_embed=300,\n",
        "                 d_hidden=256,\n",
        "                 d_out=2,\n",
        "                 dp=0.2,\n",
        "                 embed_weight=None,\n",
        "                 eow_idx=2):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.embed = nn.Embedding(n_embed, d_embed)\n",
        "        \n",
        "        if embed_weight is not None:\n",
        "            # embed_weight = inputs.vocab.vectors\n",
        "            self.embed.weight.data.copy_(embed_weight)\n",
        "            self.embed.weight.requires_grad = False\n",
        "       \n",
        "        # self.norm = Norm(d_embed)\n",
        "        self.bilstm = torch.nn.LSTM(input_size=d_embed, hidden_size=d_hidden, num_layers=1, bidirectional=True, dropout=dp)\n",
        "        self.ff = FeedForward(2*d_hidden, d_out, d_hidden)\n",
        "        \n",
        "        self.dropout =  nn.Dropout(dp)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        tokens = batch.tokenized  \n",
        "        # misp = batch.misp  \n",
        "        label = batch.category\n",
        "\n",
        "        w = self.embed(tokens)\n",
        "        # m = self.embed(misp)\n",
        "        # w = (w + m)/2\n",
        "        o, (h, c) = self.bilstm(w)\n",
        "        \n",
        "        x = torch.cat((h[0,:,:], h[1,:,:]), dim=1)\n",
        "        # x = self.norm(x)\n",
        "        x = self.ff(self.dropout(x))\n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK7xQ_lGIoIJ"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKIEB_RqIr6p"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WePEx8ANKkTG"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saeTtAPkItPZ"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def train_model(train_iter, validation_iter):\n",
        "    n_embed = len(TOKEN.vocab)\n",
        "    d_out = len(CATEGORY.vocab)\n",
        "\n",
        "    model = Classifier(d_embed=args.d_embed, d_hidden=args.d_embed, d_out=d_out, dp=0.2, embed_weight=TOKEN.vocab.vectors, n_embed=n_embed)\n",
        "    model.to(device)\n",
        "\n",
        "    opt = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    acc, val_loss = evaluate(validation_iter, model)\n",
        "    best_acc = acc\n",
        "\n",
        "#     print('epoch |   %        |  loss  |  avg   |val loss|   acc   |  best  | time | save |')\n",
        "#     print('val   |            |        |        | {:.4f} | {:.4f} | {:.4f} |      |      |'.format(val_loss, acc, best_acc))\n",
        "\n",
        "    iterations = 0\n",
        "    last_val_iter = 0\n",
        "    train_loss = 0\n",
        "    start = time.time()\n",
        "    \n",
        "    train_stat = []\n",
        "    with tqdm(total=args.epochs*len(train_iter)) as pbar:\n",
        "    \n",
        "      for epoch in range(args.epochs):\n",
        "          train_iter.init_epoch()\n",
        "          n_correct, n_total, train_loss = 0, 0, 0\n",
        "          last_val_iter = 0\n",
        "  #         print(epoch, end=' ')\n",
        "          for batch_idx, batch in enumerate(train_iter):\n",
        "              # switch model to training mode, clear gradient accumulators\n",
        "              model.train();\n",
        "              opt.zero_grad()\n",
        "\n",
        "              iterations += 1\n",
        "\n",
        "              # forward pass\n",
        "              answer = model(batch)\n",
        "              loss = criterion(answer, batch.category)\n",
        "\n",
        "              loss.backward();\n",
        "              opt.step()\n",
        "\n",
        "              train_loss += loss.item()\n",
        "  #             print('\\r {:4d} | {:4d}/{} | {:.4f} | {:.4f} |'.format(\n",
        "  #                 epoch, args.batch_size * (batch_idx + 1), len(train), loss.item(),\n",
        "  #                         train_loss / (iterations - last_val_iter)), end='')\n",
        "              \n",
        "              stat = {\n",
        "                  \"epoch\": epoch,\n",
        "                  \"step\": iterations,\n",
        "                  \"train_loss\": loss.item(),\n",
        "                  \"avg_loss\": train_loss / (iterations - last_val_iter)\n",
        "              }\n",
        "\n",
        "              if iterations > 0 and iterations % args.dev_every == 0:\n",
        "                  acc, val_loss = evaluate(validation_iter, model)\n",
        "                  _save_ckp = '*'\n",
        "                  if acc > best_acc:\n",
        "                      best_acc = acc\n",
        "                      # torch.save(model.state_dict(), args.save_path)\n",
        "\n",
        "\n",
        "  #                 print(\n",
        "  #                     ' {:.4f} | {:.4f} | {:.4f} | {:.2f} | {:4s} |'.format(\n",
        "  #                         val_loss, acc, best_acc, (time.time() - start) / 60,\n",
        "  #                         _save_ckp))\n",
        "\n",
        "                  train_loss = 0\n",
        "                  last_val_iter = iterations\n",
        "                  stat[\"val_loss\"] = val_loss\n",
        "                  stat[\"acc\"] = acc\n",
        "                  stat[\"best_acc\"] = best_acc\n",
        "                  stat[\"time\"] = (time.time() - start)\n",
        "          \n",
        "              \n",
        "              train_stat.append(stat)\n",
        "              pbar.update(1)\n",
        "    \n",
        "    acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "    print(acc, test_loss)\n",
        "\n",
        "    output = []\n",
        "    # _predict = predict.cpu().numpy()\n",
        "    # _labels = labels.cpu().numpy()\n",
        "    # for idx, t in enumerate(test):\n",
        "    #     output.append({\n",
        "    #         \"text\": t.text,\n",
        "    #         \"label\": t.category,\n",
        "    #         # \"tokens\": json.dumps(t.tokens, ensure_ascii=False),\n",
        "    #         \"predict\": json.dumps(_predict[idx].tolist(), ensure_ascii=False),\n",
        "    # #         \"_label\": _labels[idx]\n",
        "    #     })\n",
        "\n",
        "    output = pd.DataFrame(output)\n",
        "    # output.to_csv(f\"Mispelling/Outputs/{expname}_{tokenType}.csv\", index=False)\n",
        "    \n",
        "    train_stat = pd.DataFrame(train_stat)\n",
        "    # train_stat.to_csv(f\"Mispelling/Outputs/{expname}_{tokenType}_train_stat.csv\", index=False)\n",
        "    return model, output, train_stat"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eaml5FS0-hj",
        "outputId": "6b9f8fa5-b295-4a6d-cdde-4b3edcd94322"
      },
      "source": [
        "args"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(batch_size=64, d_embed=100, dev_every=50, dp_ratio=0.2, epochs=50, lr=0.001, save_path='results')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vt7ry4RIyoI",
        "outputId": "73c455f8-88bf-4ab4-a67d-bc3bd9b355c8"
      },
      "source": [
        "n_embed = len(TOKEN.vocab)\n",
        "d_out = len(CATEGORY.vocab)\n",
        "print(n_embed, d_out)\n",
        "\n",
        "args.epochs = 50\n",
        "args.d_embed = 300"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44697 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "c638a98b2dde41d58efb4a0dce0118df",
            "6ca3ba6ec68b41cc86129e49587589e6",
            "7c3e8d3b201b4fb6a5c1af0a78795d30",
            "2203a36374e949cbaf0ba2c60f404cef",
            "c10f45a8307b4602acabd8b3e0bd0308",
            "1df80ebd62874ebe82e2eea7b6e6aef6",
            "92058ecb95524fbdbcce1d362ad6f8fe",
            "79780c0d0724424b80de0c4de1f1055c",
            "5c456ae649f34faa82253c74e82c33cc",
            "64d6a7eee3664062bc6dd8dbd22a82c4",
            "0a6663e2ef9346459b5500c8455ae14d"
          ]
        },
        "id": "ZxdThFchKMyF",
        "outputId": "7a1c4340-41e0-4b46-fbc8-b41a3fd56208"
      },
      "source": [
        "model, output, train_stat = train_model(train_iter, validation_iter)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c638a98b2dde41d58efb4a0dce0118df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/16900 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.534256832646946 3.580515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f13DRfD4K1yV"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (datasets[\"test\"], datasets[\"test-corr\"], datasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9UkWWDLBe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488a8c95-c4ad-457e-cfee-7abcb0c24afe"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  63.534256832646946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49snI5qSLdHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9598ae61-996f-45a0-8744-a1e470de3302"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  58.63636363636363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6kV1HOucoRy",
        "outputId": "60d161c4-53ad-499a-d7ae-a4c88a1d272f"
      },
      "source": [
        "for sents in zip(datasets[\"test-corr\"], datasets[\"test-misp\"]):\n",
        "  print(sents[0].tokenized)\n",
        "  print(sents[1].tokenized)\n",
        "  break"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก', 'ไหม', ' ', 'ก็', 'ไม่', 'อ่ะ', ' ', '😕']\n",
            "['การ', 'ด่า', 'ไป', 'เหมือน', 'ได้', 'บรรเทา', 'ความ', 'เครียด', 'เฉย', 'ๆ', ' ', 'แต่', 'บีทีเอส', ' ', '(', 'รถ', 'ไฟฟ้า', ')', ' ', 'มัน', 'สำนึก', 'มั้ย', ' ', 'ก็', 'ไม่', 'อ่ะ', ' ', '😕']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9x-EBxZLjqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c8b4c8-aa08-4b7c-b91c-b391980efb6e"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  57.84090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rht2EwJUMKLF"
      },
      "source": [
        "# Misspelling Average Embedding [MAE]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtsB-3e56LBC"
      },
      "source": [
        "class MAEClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, refModel):\n",
        "        super(MAEClassifier, self).__init__()\n",
        "\n",
        "        self.ref = refModel\n",
        "\n",
        "    def forward(self, batch):\n",
        "        tokens = batch.tokenized  \n",
        "        misp = batch.misp  \n",
        "        label = batch.category\n",
        "\n",
        "        w = self.ref.embed(tokens)\n",
        "        m = self.ref.embed(misp)\n",
        "        w = (w + m)/2\n",
        "        o, (h, c) = self.ref.bilstm(w)\n",
        "        \n",
        "        x = torch.cat((h[0,:,:], h[1,:,:]), dim=1)\n",
        "        x = self.ref.ff(self.ref.dropout(x))\n",
        "        return x\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-AXByR6vn-"
      },
      "source": [
        "maeModel = MAEClassifier(model)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG37lIhiY915"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (MAEdatasets[\"test\"], MAEdatasets[\"test-corr\"], MAEdatasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dyhIklJ-JBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e2ae69-d39f-40cc-dc96-677f3d5e8da0"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.05840509172594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsCHmlNI9Rrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a611389c-5122-4d71-fafd-bea17b64c55c"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  58.63636363636363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTLhd_rg7JD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b78a67-3f97-4f89-e562-10864d5939cd"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  59.31818181818182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmvc0FLy-31u"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-duHBg7KPw"
      },
      "source": [
        "# Misspelling Semantics Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnxm-uTMhPp"
      },
      "source": [
        "train_iter, validation_iter, test_iter = data.BucketIterator.splits(\n",
        "    (MSTdatasets[\"train\"], MSTdatasets[\"validation\"], MSTdatasets[\"test\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "    \n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KupwYMDGMlaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "3afa313cfd4b46d69428b181908ea984",
            "8f527ef92e1a424d8e7a39978a7e1528",
            "4b5dc29a07f940e0b817b7f36e909c2f",
            "1d1faddecb5c442fa1578df785c34fe9",
            "7f0c612525ce4e2caf2a35a204e43aeb",
            "5735fadbd6c9492c9cfc708a217b19e1",
            "393f0934bcf24e25b5748908bda28e2c",
            "43894d1b2fa14e0b8f136ab999b8d45f",
            "3ef59b06c1274b0594303f165eca353d",
            "a01e382c194d4b3da7e2d80b9947f187",
            "d6a2dc3961074395a9748f4794e2bd7f"
          ]
        },
        "outputId": "f1ac5f3e-b462-45f2-cf68-8fe2a0b090cf"
      },
      "source": [
        "model, output, train_stat = train_model(train_iter, validation_iter)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3afa313cfd4b46d69428b181908ea984",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/16900 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.748034444028455 3.6352968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w21LsLcpMzLj"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (MSTdatasets[\"test\"], MSTdatasets[\"test-corr\"], MSTdatasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC4PcCCUM3rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d8dca3-6fbe-43d4-dac0-d3bf7b8be226"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  62.748034444028455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYrihwMHM3xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9de002-9296-4a01-a8ac-11bddba00017"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  57.27272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs5TzBqIM32V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d910a0-2a6d-44ac-84cd-341a31377650"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  57.27272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_n6AVQwNBnl"
      },
      "source": [
        "# Both "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL1MlACQNIbX"
      },
      "source": [
        "maeModel = MAEClassifier(model)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ScQ1eQNDZ3"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (BOTHdataset[\"test\"], BOTHdataset[\"test-corr\"], BOTHdataset[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCk7RriINPQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bb2c63-0cc7-4f3d-fc95-a1e9e0bc6b68"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  63.23474354174466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SprVk1BiNPTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734999c9-07c4-48ee-de15-726f46c6225d"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  57.95454545454545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq4bBDNNNPWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd78f30a-230b-4913-e49a-7a3fb68ec60d"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  57.84090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlghTTsNXSB"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}