{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train LSTM on FastText [Exp4: VEC-corr].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "535e02fc4db04baea6e5ef8233abee73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71ce8fb4f0b24dbd86c6b3834c63ab2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21c080f90a754b23a0f20887e1b54f0f",
              "IPY_MODEL_6d96eb02ceb545ce84de3416c7d48a6a",
              "IPY_MODEL_997c96280e244ef680044a1b3b6e108d"
            ]
          }
        },
        "71ce8fb4f0b24dbd86c6b3834c63ab2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21c080f90a754b23a0f20887e1b54f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_092117d554384b8baf7f42db08a181ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0b56866ea8b4b39b1dd13baa9e9e6f5"
          }
        },
        "6d96eb02ceb545ce84de3416c7d48a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0edd904650334f2792490d8f5a5ef2d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 44697,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 44697,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38783d6611204193bdf554d52e47b9e5"
          }
        },
        "997c96280e244ef680044a1b3b6e108d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ffd148ef9f641a4ac5d8a9dfcd39579",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44697/44697 [00:01&lt;00:00, 28154.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_935f34206ca4415b8efdf6a9a4a4a748"
          }
        },
        "092117d554384b8baf7f42db08a181ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0b56866ea8b4b39b1dd13baa9e9e6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0edd904650334f2792490d8f5a5ef2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38783d6611204193bdf554d52e47b9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ffd148ef9f641a4ac5d8a9dfcd39579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "935f34206ca4415b8efdf6a9a4a4a748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a8f228e684c447cabcd24f3d32ec568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00aae215d5a84f149c4e1fdafc381b83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b77ee7dcd5840b0b364a84ba1a1ee86",
              "IPY_MODEL_01698c9ae879420595d273b74c7a241c",
              "IPY_MODEL_9919fcfecafc4becaea15b19a1d4eea4"
            ]
          }
        },
        "00aae215d5a84f149c4e1fdafc381b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b77ee7dcd5840b0b364a84ba1a1ee86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b6dcfa5d0524a6c85b14fb60cea1fe0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93e8cd602e264b7f88daa684e1dde451"
          }
        },
        "01698c9ae879420595d273b74c7a241c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ed178d30c8c4f748c57deef3de57efe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 33800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 33800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19af109587714a499acc705d87e9d823"
          }
        },
        "9919fcfecafc4becaea15b19a1d4eea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_375205c2adf54fac90c36e8b097f49f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 33800/33800 [1:24:30&lt;00:00,  1.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe4203152ba94305bf51f860a55ad064"
          }
        },
        "1b6dcfa5d0524a6c85b14fb60cea1fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93e8cd602e264b7f88daa684e1dde451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed178d30c8c4f748c57deef3de57efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19af109587714a499acc705d87e9d823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "375205c2adf54fac90c36e8b097f49f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe4203152ba94305bf51f860a55ad064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74d0f29670fd4d62afc4ae2c1378f567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_785625d13ec2435c95261f4fb8c273c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7accaece5254862a7b31ee23cd1bf85",
              "IPY_MODEL_d1e8a721612f44c7b00af42dd2cc8206",
              "IPY_MODEL_17dd5c75daec404386feb8a614e533b7"
            ]
          }
        },
        "785625d13ec2435c95261f4fb8c273c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7accaece5254862a7b31ee23cd1bf85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ba2f8f160674c018cfa9892858993dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b39c45cbe3604bf989e62edbb4d76ab3"
          }
        },
        "d1e8a721612f44c7b00af42dd2cc8206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4eb851a7d5444938649aac0ebc2b254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 33800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 33800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b3d4aa6e8ca46b498715972f89d0eb8"
          }
        },
        "17dd5c75daec404386feb8a614e533b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_393f62b2c7b74a84b0241b043a5ed2f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 33800/33800 [1:24:30&lt;00:00,  2.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c3502e2d2c24c4c9d0abe5b2c9b6769"
          }
        },
        "9ba2f8f160674c018cfa9892858993dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b39c45cbe3604bf989e62edbb4d76ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4eb851a7d5444938649aac0ebc2b254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b3d4aa6e8ca46b498715972f89d0eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "393f62b2c7b74a84b0241b043a5ed2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c3502e2d2c24c4c9d0abe5b2c9b6769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm5ID9-w8lPF",
        "outputId": "a54cff0d-7b3c-4154-a673-7333ba7b409b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn_3IlRA8yGI",
        "outputId": "d8ef510d-8616-43fd-8384-fb4f0518185a"
      },
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72RbIPGQ83em",
        "outputId": "08706e9b-9958-4b02-ef46-db4a53a74acf"
      },
      "source": [
        "!pip install fastText"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastText\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fastText) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastText) (1.19.5)\n",
            "Building wheels for collected packages: fastText\n",
            "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastText: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3121344 sha256=70f57c197a21faee4543e894440b138b72cb64af0cff9ffccd6971e7339063cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fastText\n",
            "Installing collected packages: pybind11, fastText\n",
            "Successfully installed fastText-0.9.2 pybind11-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvFY4jen9FeH"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh7kO1ITXstw"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwg5qj2hXuXY"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_jsonl(fname):\n",
        "    fin = open(fname, encoding=\"utf-8\")\n",
        "    data = []\n",
        "    for line in fin:\n",
        "        d = json.loads(line.strip())\n",
        "        data.append(d)\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_jsonl(data, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as fo:\n",
        "        for idx, d in enumerate(data):\n",
        "            fo.write(json.dumps(d, ensure_ascii=False))\n",
        "            fo.write(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TDqQCb6XuZ9"
      },
      "source": [
        "DIR = \"Mispelling/misspelling-semantics/Datasets/\"\n",
        "traindata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_train.jsonl\")\n",
        "validdata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_valid.jsonl\")\n",
        "testdata = load_jsonl(f\"{DIR}/WisesightSentiment/tokenized_test-misp.jsonl\")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyOZj9z3Xucz"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHwGnDPRZ4hw",
        "outputId": "71cd8c56-2a08-490b-cba1-4274a542402a"
      },
      "source": [
        "import itertools\n",
        "def filterByMode(data, mode=None):\n",
        "  output = []\n",
        "  for sent in data:\n",
        "    if mode is None:\n",
        "      tokenized = [seg[0] for seg in sent[\"segments\"]]\n",
        "    elif mode==\"corr\":\n",
        "      tokenized = [seg[1] for seg in sent[\"segments\"]]\n",
        "      if len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "    else:\n",
        "      tokenized = [seg[0] for seg in sent[\"segments\"]]\n",
        "      if len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "    \n",
        "    tokenized = list(itertools.chain(*tokenized))\n",
        "  \n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": tokenized,\n",
        "        \"segments\": sent[\"segments\"]\n",
        "    })\n",
        "\n",
        "  return output\n",
        "\n",
        "traindata\n",
        "validdata\n",
        "allTestdata = filterByMode(testdata)\n",
        "corrTestdata = filterByMode(testdata, \"corr\")\n",
        "mispTestdata = filterByMode(testdata, \"misp\")\n",
        "len(allTestdata), len(corrTestdata), len(mispTestdata)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2671, 880, 880)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb3VQndoXufR"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn_-ONCtXuiL"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_xmhIYTFx_V"
      },
      "source": [
        "# Create LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgmoytS4FzJU"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import os\n",
        "\n",
        "seed = 0\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)    \n",
        "np.random.seed(seed)\n",
        "np.random.RandomState(seed)\n",
        "\n",
        "torch.manual_seed(seed) \n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) #seed all gpus    \n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.enabled = False  \n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THSE3QKF2am",
        "outputId": "2d3c7bdb-a52b-487f-f07f-0ba30b220551"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAy_zT-OF9o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3888b5-ebe6-42ec-be9b-7d39ec8db7ac"
      },
      "source": [
        "!pip install -q pythainlp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 11.0 MB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 45.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtrQwukcF4R1"
      },
      "source": [
        "import pythainlp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6N_idH_GCx3"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = ArgumentParser(description='LSTM')\n",
        "#     parser.add_argument('mode', type=str, help = 'tokenizing mode ')\n",
        "    parser.add_argument('--epochs', type=int, default=50, help = 'epochs')\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--d_embed', type=int, default=100)\n",
        "    parser.add_argument('--lr', type=float, default=.001)\n",
        "    parser.add_argument('--dev_every', type=int, default=100)\n",
        "    parser.add_argument('--dp_ratio', type=int, default=0.2)\n",
        "    parser.add_argument('--save_path', type=str, default='results', help='path to save the model')\n",
        "    \n",
        "    try:\n",
        "        args = parser.parse_args([])\n",
        "    except:\n",
        "        parser.print_help()\n",
        "        sys.exit(1)\n",
        "\n",
        "    return args"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjR17JHGC1B"
      },
      "source": [
        "               \n",
        "args = get_args()\n",
        "args.epochs = 100\n",
        "args.batch_size = 64\n",
        "args.dev_every = 50"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqHRlh7vKHGh"
      },
      "source": [
        "# ls Mispelling/misspelling-semantics/Datasets/../Models\n",
        "\n",
        "# cc.th.300.bin    \n",
        "\n",
        "\n",
        "# fasttext_MST_VISTEC-TP-TH-2021.bin\n",
        "#  \n",
        "# fasttext_MST_wisesight_train.bin\n",
        "# fasttext_wisesight_train.bin"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFN-roz-F803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22961b4f-28c0-4c73-e0bd-af033b719c79"
      },
      "source": [
        "wv = fasttext.load_model(f\"{DIR}/../Models/fasttext_corr_VISTEC-TP-TH-2021.bin\")\n",
        "# wv = fasttext.load_model(f\"Mispelling/Models/fasttext_orcl.bin\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4enmKUubyCyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69743125-22ff-4f9b-8cdd-bc9bdb829576"
      },
      "source": [
        "\"DONE\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DONE'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju3fwxglivDc"
      },
      "source": [
        "### Build Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYyZnlN-jt9Y"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsp-eb2Jju8K"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhO-MElGkNEy"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRShhllxAP-v"
      },
      "source": [
        "#### Baseline Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxRdZ1PyjzQF"
      },
      "source": [
        "LABELS = {\n",
        "    \"neg\": 2,\n",
        "    \"neu\": 1,\n",
        "    \"pos\": 0,\n",
        "    \"q\": 1 # used to be 3\n",
        "}\n",
        "\n",
        "def removeQuestion(label):    \n",
        "  return LABELS[label]\n",
        "\n",
        "# TEXT = data.Field(sequential=True, lower=False)\n",
        "CATEGORY = data.Field(sequential=False, use_vocab=False, preprocessing=removeQuestion)\n",
        "TOKEN = data.Field(sequential=True, lower=False)\n",
        "\n",
        "raw_datasets = {\n",
        "    \"train\": traindata,\n",
        "    \"validation\": validdata,\n",
        "    \"test\": allTestdata,\n",
        "    \"test-corr\": corrTestdata,\n",
        "    \"test-misp\": mispTestdata\n",
        "}\n",
        "\n",
        "raw_fields = [\n",
        "    # ('text', TEXT), \n",
        "    ('category', CATEGORY),\n",
        "    ('tokenized', TOKEN)\n",
        "]\n",
        "\n",
        "fields = {}\n",
        "for f in raw_fields:\n",
        "  fields[f[0]] = f\n",
        "\n",
        "datasets = {}\n",
        "for k in raw_datasets:  \n",
        "  examples = [data.Example.fromdict(d, fields=fields) for d in raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=raw_fields)\n",
        "  datasets[k] = d\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhKqE2ZQAYck"
      },
      "source": [
        "#### MAE Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EoG-XP7GO2E"
      },
      "source": [
        "# "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ7zViqs_qRV",
        "outputId": "fbdba96e-b6e6-444f-e6ab-5ab113b715d0"
      },
      "source": [
        "MC = load_jsonl(f\"{DIR}/../test_mispelling_correction.jsonl\")[0]\n",
        "def createMAEDataset(data, pre_segmented=False, mode=None, mst=False):\n",
        "  output = []\n",
        "  cnt, mstcnt = 0, 0\n",
        "\n",
        "  segIdx = 0\n",
        "  if mode==\"corr\":\n",
        "    segIdx = 1  # ignore misspelling with MC\n",
        "\n",
        "  for sent in data:\n",
        "    newtokens = []\n",
        "    misptokens = []\n",
        "    if (mode==\"misp\" or mode==\"corr\") and len(sent[\"misp_tokens\"])==0:\n",
        "        continue\n",
        "\n",
        "    if pre_segmented:\n",
        "      for seg in sent[\"segments\"]:\n",
        "        for token in zip(seg[0], seg[1]):\n",
        "          newtokens.append(token[segIdx])\n",
        "          misptokens.append(token[1])\n",
        "          if mst:\n",
        "            msttokens = additionalToken(token[segIdx])\n",
        "            newtokens += msttokens\n",
        "            misptokens += msttokens\n",
        "\n",
        "          if token[0]!=token[1]:\n",
        "            mstcnt += 1\n",
        "          \n",
        "    else:\n",
        "      \n",
        "      for token in sent[\"tokenized\"]:\n",
        "        w = norm_word(token)\n",
        "        detectedMsp = (len(w) >= 4) and (w in MC)\n",
        "        if detectedMsp:\n",
        "            corr, mint = MC[w]\n",
        "            misptokens.append(corr)\n",
        "            if mode==\"corr\":\n",
        "              token = corr\n",
        "            mstcnt += 1\n",
        "        else:\n",
        "          misptokens.append(token)\n",
        "        newtokens.append(token)\n",
        "\n",
        "        if detectedMsp and mst:\n",
        "          msttokens = additionalToken(token)\n",
        "          newtokens += msttokens\n",
        "          misptokens += msttokens\n",
        "\n",
        "\n",
        "    cnt += len(newtokens)\n",
        "\n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": newtokens,\n",
        "        \"misp\": misptokens\n",
        "    })\n",
        "\n",
        "  print(f\"#Misp Tokens: {mstcnt} tokens; {(mstcnt)*100/cnt:.2f}%\")\n",
        "  return output\n",
        "\n",
        "mae_raw_datasets = {\n",
        "    \"test\": createMAEDataset(testdata, pre_segmented=True),\n",
        "    \"test-corr\": createMAEDataset(testdata, pre_segmented=True, mode=\"corr\"),\n",
        "    \"test-misp\": createMAEDataset(testdata, pre_segmented=True, mode=\"misp\"),\n",
        "}\n",
        "\n",
        "mae_raw_fields = [\n",
        "    ('category', CATEGORY),\n",
        "    ('tokenized', TOKEN),\n",
        "    ('misp', TOKEN),\n",
        "]\n",
        "\n",
        "mae_fields = {}\n",
        "for f in mae_raw_fields:\n",
        "  mae_fields[f[0]] = f\n",
        "\n",
        "print()\n",
        "MAEdatasets = {}\n",
        "for k in mae_raw_datasets:  \n",
        "  print(f\"Processed: {k}\")\n",
        "  examples = [data.Example.fromdict(d, fields=mae_fields) for d in mae_raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=mae_raw_fields)\n",
        "  MAEdatasets[k] = d\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Misp Tokens: 1213 tokens; 1.67%\n",
            "#Misp Tokens: 1213 tokens; 5.60%\n",
            "#Misp Tokens: 1213 tokens; 5.60%\n",
            "\n",
            "Processed: test\n",
            "Processed: test-corr\n",
            "Processed: test-misp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emulYYp-AbER"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGje3d7QAcnN"
      },
      "source": [
        "#### MST Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC1nGGMfAgcH"
      },
      "source": [
        "from itertools import groupby\n",
        "MD = load_jsonl(f\"{DIR}/../train_mispelling_dection.jsonl\")[0]\n",
        "\n",
        "def norm_word(word):\n",
        "    groups = [list(s) for _, s in groupby(word)]\n",
        "    ch = []\n",
        "    extraToken = \"\"\n",
        "    for g in groups:\n",
        "        if len(g)>=3:\n",
        "            if g[0]==\"5\":\n",
        "              extraToken = \"<lol>\"\n",
        "            else:\n",
        "              extraToken = \"<rep>\"\n",
        "            ch.append(g[0])  \n",
        "        else:\n",
        "            ch += g\n",
        "    word = \"\".join(ch)+extraToken\n",
        "    return word\n",
        "\n",
        "def additionalToken(word):\n",
        "  tokens = []\n",
        "  w = norm_word(word)\n",
        "  if \"<lol>\" in w:\n",
        "    tokens.append(\"<lol>\")\n",
        "  elif \"<rep>\" in w:\n",
        "    tokens.append(\"<rep>\")\n",
        "  elif w in MD:\n",
        "      corr, mint = MD[w]\n",
        "      if mint:\n",
        "        tokens.append(\"<int>\")\n",
        "      else:\n",
        "        tokens.append(\"<msp>\")\n",
        "  return tokens\n",
        "\n",
        "def addMSTTokens(data, pre_segmented=False):\n",
        "  output = []\n",
        "  cnt, mstcnt = 0, 0\n",
        "  for sent in data:\n",
        "    newtokens = []\n",
        "    if pre_segmented:\n",
        "      for seg in sent[\"segments\"]:\n",
        "        for token in zip(seg[0], seg[1]):\n",
        "          newtokens.append(token[0])\n",
        "          if token[0]==token[1]:\n",
        "            continue\n",
        "          \n",
        "          newtokens += additionalToken(token[0])\n",
        "    else:\n",
        "      for token in sent[\"tokenized\"]:\n",
        "        newtokens.append(token)\n",
        "        # if len(w) < 4:\n",
        "        #   continue\n",
        "        newtokens += additionalToken(token[0])\n",
        "\n",
        "    cnt += len(sent[\"tokenized\"])\n",
        "    mstcnt += len(newtokens)\n",
        "\n",
        "    output.append({\n",
        "        \"category\": sent[\"category\"],\n",
        "        \"text\": sent[\"text\"],\n",
        "        \"tokenized\": newtokens,\n",
        "    })\n",
        "\n",
        "  print(f\"#New MST Tokens: {mstcnt - cnt} tokens; {(mstcnt - cnt)*100/cnt:.2f}%\")\n",
        "  return output"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtP3z6LAghg",
        "outputId": "547c4d8d-7ec0-41ff-fd1e-1f58935cbb82"
      },
      "source": [
        "MSTdatasets = {}\n",
        "for k in raw_datasets:\n",
        "  print(f\"Processed: {k}\")\n",
        "  raw = addMSTTokens(raw_datasets[k], pre_segmented=k.startswith(\"test\"))  #only pre-segmented in test set\n",
        "  examples = [data.Example.fromdict(d, fields=fields) for d in raw]\n",
        "  d = data.Dataset(examples, fields=raw_fields)\n",
        "  MSTdatasets[k] = d\n",
        "  print(\"\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: train\n",
            "#New MST Tokens: 19356 tokens; 3.18%\n",
            "\n",
            "Processed: validation\n",
            "#New MST Tokens: 2147 tokens; 3.19%\n",
            "\n",
            "Processed: test\n",
            "#New MST Tokens: 616 tokens; 0.85%\n",
            "\n",
            "Processed: test-corr\n",
            "#New MST Tokens: 616 tokens; 2.84%\n",
            "\n",
            "Processed: test-misp\n",
            "#New MST Tokens: 616 tokens; 2.84%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602D1D4zIlb4"
      },
      "source": [
        "# Both"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRT0CD47InJQ"
      },
      "source": [
        "#### MAE+MST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX8pevvm_qgI",
        "outputId": "415d6c1c-fada-4408-a9b7-36411c1705e6"
      },
      "source": [
        "both_raw_datasets = {\n",
        "    \"test\": createMAEDataset(testdata, pre_segmented=True, mst=True),\n",
        "    \"test-corr\": createMAEDataset(testdata, pre_segmented=True, mode=\"corr\", mst=True),\n",
        "    \"test-misp\": createMAEDataset(testdata, pre_segmented=True, mode=\"misp\", mst=True),\n",
        "}\n",
        "print()\n",
        "BOTHdataset = {}\n",
        "for k in both_raw_datasets:  \n",
        "  print(f\"Processed: {k}\")\n",
        "  examples = [data.Example.fromdict(d, fields=mae_fields) for d in both_raw_datasets[k]]\n",
        "  d = data.Dataset(examples, fields=mae_raw_fields)\n",
        "  BOTHdataset[k] = d\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Misp Tokens: 1213 tokens; 1.63%\n",
            "#Misp Tokens: 1213 tokens; 5.50%\n",
            "#Misp Tokens: 1213 tokens; 5.37%\n",
            "\n",
            "Processed: test\n",
            "Processed: test-corr\n",
            "Processed: test-misp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JchrrW2I_lp"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EZ0-SC9I_tV"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60NoKoMOt9fN"
      },
      "source": [
        "W2V_WINDOW = 5 \n",
        "W2V_MIN_COUNT = 0\n",
        "\n",
        "# TEXT.build_vocab(datasets[\"train\"], min_freq=W2V_MIN_COUNT, )\n",
        "TOKEN.build_vocab(datasets[\"train\"], datasets[\"validation\"], datasets[\"test\"], datasets[\"test-corr\"], MSTdatasets[\"test\"], min_freq=W2V_MIN_COUNT, )\n",
        "CATEGORY.build_vocab(datasets[\"train\"])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3V6AoPpDxgN",
        "outputId": "08f05c35-d813-4910-b186-1fb8826e733b"
      },
      "source": [
        "\"#Token\",len(TOKEN.vocab)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('#Token', 44697)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NjPc0lJscK_",
        "outputId": "96c9b3ca-c3f9-4afd-c974-383d73773afb"
      },
      "source": [
        "CATEGORY.vocab.stoi"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f7fb5048ed0>>,\n",
              "            {0: 3, 1: 1, 2: 2, '<unk>': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2DamUhtGgIZ"
      },
      "source": [
        "import fasttext\n",
        "\n",
        "# ref: https://medium.com/@rohit_agrawal/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd\n",
        "def set_wv_vectors(field, vectors, debug=False):\n",
        "    W2V_SIZE = vectors.get_dimension()\n",
        "    \n",
        "    words = vectors.get_words()\n",
        "    vocab_size = len(words)\n",
        "    word2vec_vectors = []\n",
        "    for token, idx in tqdm(field.vocab.stoi.items()):\n",
        "        if idx==0:\n",
        "            word2vec_vectors.append(torch.zeros(W2V_SIZE))\n",
        "            continue\n",
        "            \n",
        "        word2vec_vectors.append(torch.FloatTensor(vectors[token]))\n",
        "\n",
        "    field.vocab.set_vectors(field.vocab.stoi, word2vec_vectors, W2V_SIZE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "535e02fc4db04baea6e5ef8233abee73",
            "71ce8fb4f0b24dbd86c6b3834c63ab2f",
            "21c080f90a754b23a0f20887e1b54f0f",
            "6d96eb02ceb545ce84de3416c7d48a6a",
            "997c96280e244ef680044a1b3b6e108d",
            "092117d554384b8baf7f42db08a181ee",
            "d0b56866ea8b4b39b1dd13baa9e9e6f5",
            "0edd904650334f2792490d8f5a5ef2d1",
            "38783d6611204193bdf554d52e47b9e5",
            "6ffd148ef9f641a4ac5d8a9dfcd39579",
            "935f34206ca4415b8efdf6a9a4a4a748"
          ]
        },
        "id": "rh-KH7HCH_Ku",
        "outputId": "267514ce-ba17-4b45-db61-422c8e739d9b"
      },
      "source": [
        "set_wv_vectors(TOKEN, wv)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "535e02fc4db04baea6e5ef8233abee73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/44697 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_GDSnh3zoob"
      },
      "source": [
        "del wv"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVZ8o5AAztg0",
        "outputId": "f9915244-b333-4333-9f44-2c908abdf412"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdiLcxWgH_2O"
      },
      "source": [
        "train_iter, validation_iter, test_iter = data.BucketIterator.splits(\n",
        "    (datasets[\"train\"], datasets[\"validation\"], datasets[\"test\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "    \n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuk1Ym5KIZ1o"
      },
      "source": [
        "def evaluate(loader, model, return_pred=False):\n",
        "    model.eval()\n",
        "    loader.sort = False\n",
        "    loader.sort_within_batch = False\n",
        "    loader.init_epoch()\n",
        "\n",
        "    # calculate accuracy on validation set\n",
        "    n_correct, n = 0, 0\n",
        "    losses = []\n",
        "    answers = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            answer = model(batch)\n",
        "            answers.append((answer, batch.category))\n",
        "            n_correct += (torch.max(answer, 1)[1].view(batch.category.size()) == batch.category).sum().item()\n",
        "            n += answer.shape[0]\n",
        "            loss = criterion(answer, batch.category)\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "    acc = 100. * n_correct / n\n",
        "    loss = np.mean(losses)\n",
        "    \n",
        "    if not return_pred:\n",
        "        return acc, loss\n",
        "    \n",
        "    \n",
        "    predict = torch.cat([a for a,_ in answers])\n",
        "    labels = torch.cat([a for _,a in answers])\n",
        "    return acc, loss, predict, labels"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq-WgDqKIbug"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_out, d_ff=256, dropout = 0.1):\n",
        "        super().__init__() \n",
        "        # We set d_ff as a default to 256\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_out)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_embed=10000,\n",
        "                 d_embed=300,\n",
        "                 d_hidden=256,\n",
        "                 d_out=2,\n",
        "                 dp=0.2,\n",
        "                 embed_weight=None,\n",
        "                 eow_idx=2):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.embed = nn.Embedding(n_embed, d_embed)\n",
        "        \n",
        "        if embed_weight is not None:\n",
        "            # embed_weight = inputs.vocab.vectors\n",
        "            self.embed.weight.data.copy_(embed_weight)\n",
        "            self.embed.weight.requires_grad = False\n",
        "       \n",
        "        # self.norm = Norm(d_embed)\n",
        "        self.bilstm = torch.nn.LSTM(input_size=d_embed, hidden_size=d_hidden, num_layers=1, bidirectional=True, dropout=dp)\n",
        "        self.ff = FeedForward(2*d_hidden, d_out, d_hidden)\n",
        "        \n",
        "        self.dropout =  nn.Dropout(dp)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        tokens = batch.tokenized  \n",
        "        # misp = batch.misp  \n",
        "        label = batch.category\n",
        "\n",
        "        w = self.embed(tokens)\n",
        "        # m = self.embed(misp)\n",
        "        # w = (w + m)/2\n",
        "        o, (h, c) = self.bilstm(w)\n",
        "        \n",
        "        x = torch.cat((h[0,:,:], h[1,:,:]), dim=1)\n",
        "        # x = self.norm(x)\n",
        "        x = self.ff(self.dropout(x))\n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK7xQ_lGIoIJ"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKIEB_RqIr6p"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WePEx8ANKkTG"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saeTtAPkItPZ"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import copy\n",
        "\n",
        "def train_model(train_iter, validation_iter):\n",
        "    n_embed = len(TOKEN.vocab)\n",
        "    d_out = len(CATEGORY.vocab)\n",
        "\n",
        "    model = Classifier(d_embed=args.d_embed, d_hidden=args.d_embed, d_out=d_out, dp=0.2, embed_weight=TOKEN.vocab.vectors, n_embed=n_embed)\n",
        "    model.to(device)\n",
        "\n",
        "    opt = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    acc, val_loss = evaluate(validation_iter, model)\n",
        "    best_acc = acc\n",
        "\n",
        "#     print('epoch |   %        |  loss  |  avg   |val loss|   acc   |  best  | time | save |')\n",
        "#     print('val   |            |        |        | {:.4f} | {:.4f} | {:.4f} |      |      |'.format(val_loss, acc, best_acc))\n",
        "\n",
        "    iterations = 0\n",
        "    last_val_iter = 0\n",
        "    train_loss = 0\n",
        "    start = time.time()\n",
        "    \n",
        "    train_stat = []\n",
        "    best_model = model\n",
        "    with tqdm(total=args.epochs*len(train_iter)) as pbar:\n",
        "    \n",
        "      for epoch in range(args.epochs):\n",
        "          train_iter.init_epoch()\n",
        "          n_correct, n_total, train_loss = 0, 0, 0\n",
        "          last_val_iter = 0\n",
        "  #         print(epoch, end=' ')\n",
        "          for batch_idx, batch in enumerate(train_iter):\n",
        "              # switch model to training mode, clear gradient accumulators\n",
        "              model.train();\n",
        "              opt.zero_grad()\n",
        "\n",
        "              iterations += 1\n",
        "\n",
        "              # forward pass\n",
        "              answer = model(batch)\n",
        "              loss = criterion(answer, batch.category)\n",
        "\n",
        "              loss.backward();\n",
        "              opt.step()\n",
        "\n",
        "              train_loss += loss.item()\n",
        "  #             print('\\r {:4d} | {:4d}/{} | {:.4f} | {:.4f} |'.format(\n",
        "  #                 epoch, args.batch_size * (batch_idx + 1), len(train), loss.item(),\n",
        "  #                         train_loss / (iterations - last_val_iter)), end='')\n",
        "              \n",
        "              stat = {\n",
        "                  \"epoch\": epoch,\n",
        "                  \"step\": iterations,\n",
        "                  \"train_loss\": loss.item(),\n",
        "                  \"avg_loss\": train_loss / (iterations - last_val_iter)\n",
        "              }\n",
        "\n",
        "              if iterations > 0 and iterations % 10 == 0:\n",
        "                  acc, val_loss = evaluate(validation_iter, model)\n",
        "                  _save_ckp = '*'\n",
        "                  if acc > best_acc:\n",
        "                      best_acc = acc\n",
        "                      # torch.save(model.state_dict(), args.save_path)\n",
        "                      best_model = copy.deepcopy(model)\n",
        "\n",
        "\n",
        "  #                 print(\n",
        "  #                     ' {:.4f} | {:.4f} | {:.4f} | {:.2f} | {:4s} |'.format(\n",
        "  #                         val_loss, acc, best_acc, (time.time() - start) / 60,\n",
        "  #                         _save_ckp))\n",
        "\n",
        "                  train_loss = 0\n",
        "                  last_val_iter = iterations\n",
        "                  stat[\"val_loss\"] = val_loss\n",
        "                  stat[\"acc\"] = acc\n",
        "                  stat[\"best_acc\"] = best_acc\n",
        "                  stat[\"time\"] = (time.time() - start)\n",
        "          \n",
        "              \n",
        "              train_stat.append(stat)\n",
        "              pbar.update(1)\n",
        "    \n",
        "    model = best_model\n",
        "    acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "    print(acc, test_loss)\n",
        "\n",
        "    output = []\n",
        "    # _predict = predict.cpu().numpy()\n",
        "    # _labels = labels.cpu().numpy()\n",
        "    # for idx, t in enumerate(test):\n",
        "    #     output.append({\n",
        "    #         \"text\": t.text,\n",
        "    #         \"label\": t.category,\n",
        "    #         # \"tokens\": json.dumps(t.tokens, ensure_ascii=False),\n",
        "    #         \"predict\": json.dumps(_predict[idx].tolist(), ensure_ascii=False),\n",
        "    # #         \"_label\": _labels[idx]\n",
        "    #     })\n",
        "\n",
        "    output = pd.DataFrame(output)\n",
        "    # output.to_csv(f\"Mispelling/Outputs/{expname}_{tokenType}.csv\", index=False)\n",
        "    \n",
        "    train_stat = pd.DataFrame(train_stat)\n",
        "    # train_stat.to_csv(f\"Mispelling/Outputs/{expname}_{tokenType}_train_stat.csv\", index=False)\n",
        "    return model, output, train_stat"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eaml5FS0-hj",
        "outputId": "de76a62a-13ae-44e1-f48e-a942f2509479"
      },
      "source": [
        "args"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(batch_size=64, d_embed=100, dev_every=50, dp_ratio=0.2, epochs=100, lr=0.001, save_path='results')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vt7ry4RIyoI",
        "outputId": "d11d9b93-29c7-4b8a-bfa9-250527ba9441"
      },
      "source": [
        "n_embed = len(TOKEN.vocab)\n",
        "d_out = len(CATEGORY.vocab)\n",
        "print(n_embed, d_out)\n",
        "\n",
        "args.epochs = 100\n",
        "args.d_embed = 100"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44697 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "6a8f228e684c447cabcd24f3d32ec568",
            "00aae215d5a84f149c4e1fdafc381b83",
            "4b77ee7dcd5840b0b364a84ba1a1ee86",
            "01698c9ae879420595d273b74c7a241c",
            "9919fcfecafc4becaea15b19a1d4eea4",
            "1b6dcfa5d0524a6c85b14fb60cea1fe0",
            "93e8cd602e264b7f88daa684e1dde451",
            "4ed178d30c8c4f748c57deef3de57efe",
            "19af109587714a499acc705d87e9d823",
            "375205c2adf54fac90c36e8b097f49f2",
            "fe4203152ba94305bf51f860a55ad064"
          ]
        },
        "id": "ZxdThFchKMyF",
        "outputId": "7ed22c8c-8d68-4e43-b5cf-fe89125be091"
      },
      "source": [
        "model, output, train_stat = train_model(train_iter, validation_iter)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a8f228e684c447cabcd24f3d32ec568",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/33800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.17671284163235 0.92149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f13DRfD4K1yV"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (datasets[\"test\"], datasets[\"test-corr\"], datasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9UkWWDLBe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a09bb96-73da-45c7-a45f-d537c97b6a62"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  68.17671284163235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49snI5qSLdHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd74c33c-6819-46a7-8616-199c8d94b515"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.0909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9x-EBxZLjqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a20741-6ba6-4ca4-fcc3-4e2ad9a2b050"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.0909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rht2EwJUMKLF"
      },
      "source": [
        "# Misspelling Average Embedding [MAE]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtsB-3e56LBC"
      },
      "source": [
        "class MAEClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, refModel):\n",
        "        super(MAEClassifier, self).__init__()\n",
        "\n",
        "        self.ref = refModel\n",
        "\n",
        "    def forward(self, batch):\n",
        "        tokens = batch.tokenized  \n",
        "        misp = batch.misp  \n",
        "        label = batch.category\n",
        "\n",
        "        w = self.ref.embed(tokens)\n",
        "        m = self.ref.embed(misp)\n",
        "        w = (w + m)/2\n",
        "        o, (h, c) = self.ref.bilstm(w)\n",
        "        \n",
        "        x = torch.cat((h[0,:,:], h[1,:,:]), dim=1)\n",
        "        x = self.ref.ff(self.ref.dropout(x))\n",
        "        return x\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-AXByR6vn-"
      },
      "source": [
        "maeModel = MAEClassifier(model)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG37lIhiY915"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (MAEdatasets[\"test\"], MAEdatasets[\"test-corr\"], MAEdatasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dyhIklJ-JBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfda3e5d-9b62-4102-fd22-08523064898c"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  68.36390864844627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsCHmlNI9Rrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850df877-20b5-48fd-99f7-aae6aa9653b4"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.0909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTLhd_rg7JD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46761c24-5606-42ea-c3e5-2ea2cd36b145"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.77272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmvc0FLy-31u"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-duHBg7KPw"
      },
      "source": [
        "# Misspelling Semantics Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnxm-uTMhPp"
      },
      "source": [
        "train_iter, validation_iter, test_iter = data.BucketIterator.splits(\n",
        "    (MSTdatasets[\"train\"], MSTdatasets[\"validation\"], MSTdatasets[\"test\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "    \n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KupwYMDGMlaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "74d0f29670fd4d62afc4ae2c1378f567",
            "785625d13ec2435c95261f4fb8c273c8",
            "e7accaece5254862a7b31ee23cd1bf85",
            "d1e8a721612f44c7b00af42dd2cc8206",
            "17dd5c75daec404386feb8a614e533b7",
            "9ba2f8f160674c018cfa9892858993dc",
            "b39c45cbe3604bf989e62edbb4d76ab3",
            "f4eb851a7d5444938649aac0ebc2b254",
            "5b3d4aa6e8ca46b498715972f89d0eb8",
            "393f62b2c7b74a84b0241b043a5ed2f0",
            "7c3502e2d2c24c4c9d0abe5b2c9b6769"
          ]
        },
        "outputId": "716cd2a1-8258-4469-93d7-4f9173d55545"
      },
      "source": [
        "model, output, train_stat = train_model(train_iter, validation_iter)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74d0f29670fd4d62afc4ae2c1378f567",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/33800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69.03781355297642 0.9380351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w21LsLcpMzLj"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (MSTdatasets[\"test\"], MSTdatasets[\"test-corr\"], MSTdatasets[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC4PcCCUM3rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3063e9-1a1b-4ca3-a307-e72b4cff1442"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  69.03781355297642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYrihwMHM3xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c700e855-4fde-484c-dd33-52a568d2b515"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.43181818181819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs5TzBqIM32V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b574cc56-9598-42e3-b884-74b1acd0e3dd"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, model, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.43181818181819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_n6AVQwNBnl"
      },
      "source": [
        "# Both "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL1MlACQNIbX"
      },
      "source": [
        "maeModel = MAEClassifier(model)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ScQ1eQNDZ3"
      },
      "source": [
        "test_iter, corr_iter, misp_iter = data.BucketIterator.splits(\n",
        "    (BOTHdataset[\"test\"], BOTHdataset[\"test-corr\"], BOTHdataset[\"test-misp\"]), \n",
        "\n",
        "    batch_size=args.batch_size, \n",
        "\n",
        "    # Sort all examples in data using `sort_key`.\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.tokenized),\n",
        "    sort_within_batch=False,\n",
        "    shuffle=True,\n",
        "    \n",
        "    device=device)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCk7RriINPQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a86bd68-c024-434b-a184-21a16050dbf5"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(test_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  69.22500935979033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SprVk1BiNPTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c084ce-ad2e-4675-bffe-adcfb2b10432"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(corr_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.77272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq4bBDNNNPWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dde461-93b3-410c-b07f-c4a3341587f2"
      },
      "source": [
        "acc, test_loss, predict, labels = evaluate(misp_iter, maeModel, return_pred=True)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  65.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlghTTsNXSB"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}